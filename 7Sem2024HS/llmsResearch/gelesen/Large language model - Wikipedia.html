<!DOCTYPE html>
<html class="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-0 vector-feature-appearance-disabled vector-feature-appearance-pinned-clientpref-0 vector-feature-night-mode-disabled skin-theme-clientpref-day vector-toc-available vector-animations-ready ve-available" lang="en" dir="ltr" data-darkreader-mode="dynamic" data-darkreader-scheme="dark"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><style class="darkreader darkreader--fallback" media="screen"></style><style class="darkreader darkreader--text" media="screen"></style><style class="darkreader darkreader--invert" media="screen">.jfk-bubble.gtx-bubble, .captcheck_answer_label > input + img, span#closed_text > img[src^="https://www.gstatic.com/images/branding/googlelogo"], span[data-href^="https://www.hcaptcha.com/"] > #icon, ::-webkit-calendar-picker-indicator, img.Wirisformula, .mwe-math-fallback-image-inline, .mwe-math-fallback-image-display, .mw-ext-score, .mw-logo-wordmark, .mw-logo-tagline, .mw-wiki-logo, .central-textlogo__image, .svg-Wikimedia-logo_black, header .branding-box > a > span > img, .main-footer-menuToggle, div.post-content.footer-content > h2 > img, .mw-hiero-outer.mw-hiero-table, #p-logo-text, body > .oo-ui-windowManager .vega .marks, .minerva-footer-logo img, .music-symbol img, .tool.tool-button[src$="background-image:"], .mw-kartographer-map, .mw-kartographer-mapDialog-map, img[alt="audio speaker icon"], img[src*="Wiktionary-logo"], .locmap .pl, .locmap .pr, .mf-icon-expand, .toc-title-icon {
    filter: invert(100%) hue-rotate(180deg) contrast(90%) !important;
}</style><style class="darkreader darkreader--inline" media="screen">[data-darkreader-inline-bgcolor] {
  background-color: var(--darkreader-inline-bgcolor) !important;
}
[data-darkreader-inline-bgimage] {
  background-image: var(--darkreader-inline-bgimage) !important;
}
[data-darkreader-inline-border] {
  border-color: var(--darkreader-inline-border) !important;
}
[data-darkreader-inline-border-bottom] {
  border-bottom-color: var(--darkreader-inline-border-bottom) !important;
}
[data-darkreader-inline-border-left] {
  border-left-color: var(--darkreader-inline-border-left) !important;
}
[data-darkreader-inline-border-right] {
  border-right-color: var(--darkreader-inline-border-right) !important;
}
[data-darkreader-inline-border-top] {
  border-top-color: var(--darkreader-inline-border-top) !important;
}
[data-darkreader-inline-boxshadow] {
  box-shadow: var(--darkreader-inline-boxshadow) !important;
}
[data-darkreader-inline-color] {
  color: var(--darkreader-inline-color) !important;
}
[data-darkreader-inline-fill] {
  fill: var(--darkreader-inline-fill) !important;
}
[data-darkreader-inline-stroke] {
  stroke: var(--darkreader-inline-stroke) !important;
}
[data-darkreader-inline-outline] {
  outline-color: var(--darkreader-inline-outline) !important;
}
[data-darkreader-inline-stopcolor] {
  stop-color: var(--darkreader-inline-stopcolor) !important;
}
[data-darkreader-inline-bg] {
  background: var(--darkreader-inline-bg) !important;
}
[data-darkreader-inline-invert] {
    filter: invert(100%) hue-rotate(180deg);
}</style><style class="darkreader darkreader--variables" media="screen">:root {
   --darkreader-neutral-background: #131516;
   --darkreader-neutral-text: #d8d4cf;
   --darkreader-selection-background: #004daa;
   --darkreader-selection-text: #e8e6e3;
}</style><style class="darkreader darkreader--root-vars" media="screen"></style><style class="darkreader darkreader--user-agent" media="screen">@layer {
html {
    background-color: #181a1b !important;
}
html {
    color-scheme: dark !important;
}
iframe {
    color-scheme: initial;
}
html, body {
    background-color: #181a1b;
}
html, body {
    border-color: #736b5e;
    color: #e8e6e3;
}
a {
    color: #3391ff;
}
table {
    border-color: #545b5e;
}
mark {
    color: #e8e6e3;
}
::placeholder {
    color: #b2aba1;
}
input:-webkit-autofill,
textarea:-webkit-autofill,
select:-webkit-autofill {
    background-color: #404400 !important;
    color: #e8e6e3 !important;
}
::-webkit-scrollbar {
    background-color: #202324;
    color: #aba499;
}
::-webkit-scrollbar-thumb {
    background-color: #454a4d;
}
::-webkit-scrollbar-thumb:hover {
    background-color: #575e62;
}
::-webkit-scrollbar-thumb:active {
    background-color: #484e51;
}
::-webkit-scrollbar-corner {
    background-color: #181a1b;
}
* {
    scrollbar-color: #454a4d #202324;
}
::selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}
::-moz-selection {
    background-color: #004daa !important;
    color: #e8e6e3 !important;
}
}</style>
<meta charset="UTF-8">
<title>Large language model - Wikipedia</title>
<script>(function(){var className="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-0 vector-feature-appearance-disabled vector-feature-appearance-pinned-clientpref-0 vector-feature-night-mode-disabled skin-theme-clientpref-day vector-toc-available";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\w+$|[^\w-]+/g,'')+'-clientpref-\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":
["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"e1371472-7c92-4cb1-8331-89d1d1767b56","wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Large_language_model","wgTitle":"Large language model","wgCurRevisionId":1222500509,"wgRevisionId":1222500509,"wgArticleId":73248112,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1: long volume value","Articles with short description","Short description is different from Wikidata","Articles containing potentially dated statements from March 2024","All articles containing potentially dated statements","Articles containing potentially dated statements from 2024","Articles containing potentially dated statements from January 2024","All articles with unsourced statements",
"Articles with unsourced statements from February 2024","Large language models","Deep learning","Natural language processing"],"wgPageViewLanguage":"en","wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Large_language_model","wgRelevantArticleId":73248112,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgNoticeProject":"wikipedia","wgCiteReferencePreviews":false,"wgFlaggedRevsParams":{"tags":{"status":{"levels":1}}},"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":6,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"watchlist":true,"tagline":false,"nearby":true},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":100000,"wgULSCurrentAutonym":"English","wgCentralAuthMobileDomain":false,"wgEditSubmitButtonLabelPublish":true,"wgULSPosition":"interlanguage"
,"wgULSisCompactLinksEnabled":false,"wgVector2022LanguageInHeader":true,"wgULSisLanguageSelectorEmpty":false,"wgWikibaseItemId":"Q115305900","wgCheckUserClientHintsHeadersJsApi":["architecture","bitness","brands","fullVersionList","mobile","model","platform","platformVersion"],"GEHomepageSuggestedEditsEnableTopics":true,"wgGETopicsMatchModeEnabled":false,"wgGEStructuredTaskRejectionReasonTextInputEnabled":false,"wgGELevelingUpEnabledForUser":false};RLSTATE={"skins.vector.user.styles":"ready","ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","skins.vector.user":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","skins.vector.search.codex.styles":"ready","skins.vector.styles":"ready","skins.vector.icons":"ready","jquery.tablesorter.styles":"ready","jquery.makeCollapsible.styles":"ready","ext.wikimediamessages.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":
"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","mediawiki.page.media","ext.scribunto.logs","site","mediawiki.page.ready","jquery.tablesorter","jquery.makeCollapsible","mediawiki.toc","skins.vector.js","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.gadget.ReferenceTooltips","ext.gadget.switcher","ext.urlShortener.toolbar","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.echo.centralauth","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.cx.uls.quick.actions","wikibase.client.vector-2022","ext.checkUser.clientHints","ext.growthExperiments.SuggestedEditSession"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return["user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
}];});});</script>
<link rel="stylesheet" href="Large%20language%20model%20-%20Wikipedia_files/load_002.css"><style class="darkreader darkreader--sync" media="screen"></style>
<script async="" src="Large%20language%20model%20-%20Wikipedia_files/load.es"></script>
<style>
.cdx-icon{color:#202122;display:inline-flex;align-items:center;justify-content:center;vertical-align:text-bottom}.cdx-icon svg{fill:currentcolor;width:100%;height:100%}.cdx-icon--x-small{min-width:12px;min-height:12px;width:.75rem;height:.75rem}.cdx-icon--small{min-width:16px;min-height:16px;width:1rem;height:1rem}.cdx-icon--medium{min-width:20px;min-height:20px;width:1.25rem;height:1.25rem}.cdx-icon--flipped svg{transform:scaleX(-1)}.cdx-thumbnail{display:inline-flex}.cdx-thumbnail__placeholder,.cdx-thumbnail__image{background-position:center;background-repeat:no-repeat;background-size:cover;flex-shrink:0;box-sizing:border-box;min-width:40px;min-height:40px;width:2.5rem;height:2.5rem;border:1px solid #c8ccd1;border-radius:2px}.cdx-thumbnail__image{display:inline-block}.cdx-thumbnail__image-enter-active{transition-property:opacity;transition-duration:.1s}.cdx-thumbnail__image-enter-from{opacity:0}.cdx-thumbnail__placeholder{background-color:#f8f9fa;display:inline-flex;align-items:center;justify-content:center}.cdx-thumbnail__placeholder__icon{min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not (((-webkit-mask-image:none) or (mask-image:none))){.cdx-thumbnail__placeholder__icon{background-position:center;background-repeat:no-repeat;background-size:max(1.25rem,20px)}}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-thumbnail__placeholder__icon{-webkit-mask-size:max(1.25rem,20px);mask-size:max(1.25rem,20px);-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center}}@supports not (((-webkit-mask-image:none) or (mask-image:none))){.cdx-thumbnail__placeholder__icon{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M19 3H1v14h18zM3 14l3.5-4.5 2.5 3L12.5 8l4.5 6z\"/><path d=\"M19 5H1V3h18zm0 12H1v-2h18z\"/></svg>");filter:invert(0);opacity:.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .cdx-thumbnail__placeholder__icon,.cdx-button--weight-primary.cdx-button--action-progressive .cdx-thumbnail__placeholder__icon,.cdx-button--weight-primary.cdx-button--action-destructive .cdx-thumbnail__placeholder__icon{filter:invert(1)}}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-thumbnail__placeholder__icon{-webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M19 3H1v14h18zM3 14l3.5-4.5 2.5 3L12.5 8l4.5 6z\"/><path d=\"M19 5H1V3h18zm0 12H1v-2h18z\"/></svg>");mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M19 3H1v14h18zM3 14l3.5-4.5 2.5 3L12.5 8l4.5 6z\"/><path d=\"M19 5H1V3h18zm0 12H1v-2h18z\"/></svg>");background-color:#72777d}}.cdx-thumbnail__placeholder__icon--vue.cdx-icon{color:#72777d}.cdx-search-result-title{display:inline-block;max-width:100%;font-weight:700}.cdx-search-result-title__match{font-weight:400}.cdx-menu-item{list-style:none;position:relative;padding:8px 12px;line-height:1.6;transition-property:background-color,color,border-color,box-shadow;transition-duration:.1s}.cdx-menu-item__content{display:flex;align-items:center;line-height:1.4285714;word-wrap:break-word;-webkit-hyphens:auto;-ms-hyphens:auto;hyphens:auto}.cdx-menu-item__content,.cdx-menu-item__content:hover{text-decoration:none}.cdx-menu-item--has-description .cdx-menu-item__content{align-items:flex-start}.cdx-menu-item__text{max-width:100%}.cdx-menu-item__text__description{display:block}.cdx-menu-item__thumbnail.cdx-thumbnail{margin-right:8px}.cdx-menu-item__icon.cdx-icon{color:inherit;margin-right:8px}.cdx-menu-item--bold-label .cdx-menu-item__text__label{font-weight:700}.cdx-menu-item--hide-description-overflow .cdx-menu-item__text{overflow:hidden}.cdx-menu-item--hide-description-overflow .cdx-menu-item__text__description{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.cdx-menu-item--enabled,.cdx-menu-item--enabled .cdx-menu-item__content{color:#202122}.cdx-menu-item--enabled .cdx-menu-item__text__supporting-text,.cdx-menu-item--enabled .cdx-menu-item__text__description{color:#54595d}.cdx-menu-item--enabled.cdx-menu-item--highlighted{background-color:#eaecf0;cursor:pointer}.cdx-menu-item--enabled.cdx-menu-item--active{background-color:#eaf3ff;color:#36c}.cdx-menu-item--enabled.cdx-menu-item--active .cdx-menu-item__content,.cdx-menu-item--enabled.cdx-menu-item--active .cdx-menu-item__text__description{color:#36c}.cdx-menu-item--enabled.cdx-menu-item--selected{background-color:#eaf3ff}.cdx-menu-item--enabled.cdx-menu-item--selected.cdx-menu-item--highlighted,.cdx-menu-item--enabled.cdx-menu-item--selected.cdx-menu-item--highlighted .cdx-menu-item__content,.cdx-menu-item--enabled.cdx-menu-item--selected.cdx-menu-item--highlighted .cdx-menu-item__text__description{color:#36c}.cdx-menu-item--disabled{color:#72777d;cursor:default}.cdx-menu-item--disabled .cdx-menu-item__text__description{color:#72777d}.cdx-progress-bar{box-sizing:border-box;overflow-x:hidden}.cdx-progress-bar__bar{width:33.33%;height:100%}.cdx-progress-bar:not(.cdx-progress-bar--inline){position:relative;z-index:1;height:1rem;max-width:none;border:1px solid #a2a9b1;border-radius:9999px;box-shadow:0 2px 2px rgba(0,0,0,.2)}.cdx-progress-bar--inline{width:100%;height:.25rem}.cdx-progress-bar:not(.cdx-progress-bar--disabled) .cdx-progress-bar__bar{background-color:#36c;animation-name:cdx-animation-progress-bar__bar;animation-duration:1.6s;animation-timing-function:linear;animation-iteration-count:infinite}.cdx-progress-bar:not(.cdx-progress-bar--disabled).cdx-progress-bar--block{background-color:#fff}.cdx-progress-bar--disabled .cdx-progress-bar__bar{background-color:#c8ccd1}.cdx-progress-bar--disabled:not(.cdx-progress-bar--inline){background-color:#eaecf0}@keyframes cdx-animation-progress-bar__bar{0%{transform:translate(-100%)}to{transform:translate(300%)}}.cdx-menu{background-color:#fff;display:flex;flex-direction:column;position:absolute;left:0;z-index:50;box-sizing:border-box;width:100%;border:1px solid #a2a9b1;border-radius:2px;box-shadow:0 2px 2px rgba(0,0,0,.2)}.cdx-menu__progress-bar.cdx-progress-bar{position:absolute;top:0}.cdx-menu__listbox{margin:0;padding:0;overflow-y:auto}.cdx-menu--has-footer .cdx-menu-item:last-of-type{position:absolute;bottom:0;box-sizing:border-box;width:100%}.cdx-menu--has-footer .cdx-menu-item:last-of-type:not(:first-of-type){border-top:1px solid #c8ccd1}.cdx-button{display:inline-flex;align-items:center;justify-content:center;gap:4px;box-sizing:border-box;min-width:32px;min-height:32px;max-width:28rem;margin:0;border-width:1px;border-style:solid;border-radius:2px;padding-right:11px;padding-left:11px;font-family:inherit;font-size:inherit;font-weight:700;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;text-transform:none;transition-property:background-color,color,border-color,box-shadow;transition-duration:.1s}.cdx-button--size-large{min-width:44px;min-height:44px;padding-right:15px;padding-left:15px}.cdx-button--icon-only{padding-right:5px;padding-left:5px}.cdx-button--icon-only.cdx-button--size-large{padding-right:11px;padding-left:11px}.cdx-button::-moz-focus-inner{border:0;padding:0}.cdx-button .cdx-button__icon,.cdx-button .cdx-icon{vertical-align:middle}.cdx-button .cdx-icon{color:inherit}.cdx-button--fake-button,.cdx-button--fake-button:hover,.cdx-button--fake-button:focus{text-decoration:none}.cdx-button:enabled,.cdx-button.cdx-button--fake-button--enabled{background-color:#f8f9fa;color:#202122;border-color:#a2a9b1}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled .cdx-button__icon{background-color:#202122}}.cdx-button:enabled:hover,.cdx-button.cdx-button--fake-button--enabled:hover{background-color:#fff;color:#404244;cursor:pointer}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled:hover .cdx-button__icon{background-color:#404244}}.cdx-button:enabled:active,.cdx-button.cdx-button--fake-button--enabled:active,.cdx-button:enabled.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--is-active{background-color:#eaecf0;color:#000;border-color:#72777d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled:active .cdx-button__icon,.cdx-button:enabled.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--is-active .cdx-button__icon{background-color:#000}}.cdx-button:enabled:focus,.cdx-button.cdx-button--fake-button--enabled:focus{outline:1px solid transparent}.cdx-button:enabled:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c}.cdx-button:enabled.cdx-button--action-progressive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive{color:#36c}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-progressive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive .cdx-button__icon{background-color:#36c}}.cdx-button:enabled.cdx-button--action-progressive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:hover{color:#447ff5;border-color:#447ff5}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-progressive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:hover .cdx-button__icon{background-color:#447ff5}}.cdx-button:enabled.cdx-button--action-progressive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:active,.cdx-button:enabled.cdx-button--action-progressive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive.cdx-button--is-active{background-color:#eaf3ff;color:#2a4b8d;border-color:#2a4b8d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon{background-color:#2a4b8d}}.cdx-button:enabled.cdx-button--action-destructive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive{color:#d73333}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-destructive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive .cdx-button__icon{background-color:#d73333}}.cdx-button:enabled.cdx-button--action-destructive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:hover{color:#ff4242;border-color:#ff4242}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-destructive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:hover .cdx-button__icon{background-color:#ff4242}}.cdx-button:enabled.cdx-button--action-destructive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:active,.cdx-button:enabled.cdx-button--action-destructive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive.cdx-button--is-active{background-color:#fee7e6;color:#b32424;border-color:#b32424}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon{background-color:#b32424}}.cdx-button:enabled.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive{background-color:#36c;color:#fff;border-color:#36c}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover{background-color:#447ff5;border-color:#447ff5}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:active,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active{background-color:#2a4b8d;border-color:#2a4b8d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c,inset 0 0 0 2px #fff}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive{background-color:#d73333;color:#fff;border-color:#d73333}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover{background-color:#ff4242;border-color:#ff4242}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:active,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active{background-color:#b32424;border-color:#b32424}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c,inset 0 0 0 2px #fff}.cdx-button:enabled.cdx-button--weight-quiet,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet{background-color:transparent;border-color:transparent}.cdx-button:enabled.cdx-button--weight-quiet:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet:hover{background-color:rgba(0,24,73,.027)}.cdx-button:enabled.cdx-button--weight-quiet:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet:active,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--is-active{background-color:rgba(0,24,73,.082);color:#000;border-color:#72777d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--is-active .cdx-button__icon{background-color:#000}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive{color:#36c}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive .cdx-button__icon{background-color:#36c}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover{background-color:#eaf3ff;color:#447ff5}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover .cdx-button__icon{background-color:#447ff5}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active{background-color:#2a4b8d;color:#fff;border-color:#2a4b8d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive{color:#d73333}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive .cdx-button__icon{background-color:#d73333}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover{background-color:#fee7e6;color:#ff4242}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover .cdx-button__icon{background-color:#ff4242}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active{background-color:#b32424;color:#fff;border-color:#b32424}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c}.cdx-button:disabled,.cdx-button.cdx-button--fake-button--disabled{background-color:#c8ccd1;color:#fff;border-color:transparent}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:disabled .cdx-button__icon,.cdx-button.cdx-button--fake-button--disabled .cdx-button__icon{background-color:#fff}}.cdx-button:disabled.cdx-button--weight-quiet,.cdx-button.cdx-button--fake-button--disabled.cdx-button--weight-quiet{background-color:transparent;color:#72777d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:disabled.cdx-button--weight-quiet .cdx-button__icon,.cdx-button.cdx-button--fake-button--disabled.cdx-button--weight-quiet .cdx-button__icon{background-color:#72777d}}.cdx-text-input{position:relative;box-sizing:border-box;min-width:256px;border-radius:2px;overflow:hidden}.cdx-text-input .cdx-text-input__start-icon{position:absolute;top:50%;min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;transition-property:color;transition-duration:.1s;left:9px;transform:translateY(-50%)}.cdx-text-input__icon.cdx-text-input__end-icon{min-width:16px;min-height:16px;width:1rem;height:1rem}@supports not (((-webkit-mask-image:none) or (mask-image:none))){.cdx-text-input__icon.cdx-text-input__end-icon{background-position:center;background-repeat:no-repeat;background-size:max(1rem,16px)}}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-text-input__icon.cdx-text-input__end-icon{-webkit-mask-size:max(1rem,16px);mask-size:max(1rem,16px);-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center}}.cdx-text-input__clear-icon.cdx-icon,.cdx-text-input .cdx-text-input__end-icon{position:absolute;top:50%;min-width:16px;min-height:16px;width:1rem;height:1rem;transition-property:color;transition-duration:.1s;right:9px;transform:translateY(-50%)}.cdx-text-input__clear-icon.cdx-icon:hover{cursor:pointer}.cdx-text-input__end-icon.cdx-icon+.cdx-text-input__clear-icon.cdx-icon{right:calc(17px + 1rem)}.cdx-text-input__input{display:block;box-sizing:border-box;min-height:32px;width:100%;margin:0;border-width:1px;border-style:solid;border-radius:0;padding:4px 8px;font-family:inherit;font-size:inherit;line-height:1.375}.cdx-text-input__input:enabled{background-color:#fff;color:#202122;border-color:#a2a9b1;box-shadow:inset 0 0 0 1px transparent;transition-property:background-color,color,border-color,box-shadow;transition-duration:.25s}.cdx-text-input__input:enabled~.cdx-text-input__icon-vue{color:#72777d}.cdx-text-input__input:enabled~.cdx-text-input__icon{opacity:.51}.cdx-text-input__input:enabled:hover{border-color:#72777d}.cdx-text-input__input:enabled:focus~.cdx-text-input__icon-vue,.cdx-text-input__input:enabled.cdx-text-input__input--has-value~.cdx-text-input__icon-vue{color:#202122}.cdx-text-input__input:enabled:focus~.cdx-text-input__icon,.cdx-text-input__input:enabled.cdx-text-input__input--has-value~.cdx-text-input__icon{opacity:1}.cdx-text-input__input:enabled:focus{border-color:#36c;box-shadow:inset 0 0 0 1px #36c;outline:1px solid transparent}.cdx-text-input__input:enabled:read-only{background-color:#f8f9fa}.cdx-text-input__input:disabled{background-color:#eaecf0;color:#72777d;-webkit-text-fill-color:#72777d;border-color:#c8ccd1}.cdx-text-input__input:disabled~.cdx-text-input__icon-vue{color:#72777d;pointer-events:none}.cdx-text-input__input:disabled~.cdx-text-input__icon{opacity:.51}.cdx-text-input__input::placeholder{color:#72777d;opacity:1}.cdx-text-input__input::-ms-clear{display:none}.cdx-text-input__input[type=search]{-webkit-appearance:none;-moz-appearance:textfield}.cdx-text-input__input[type=search]::-webkit-search-decoration,.cdx-text-input__input[type=search]::-webkit-search-cancel-button{display:none}.cdx-text-input--has-start-icon .cdx-text-input__input{padding-left:calc(16px + 1.25rem)}.cdx-text-input--has-end-icon .cdx-text-input__input,.cdx-text-input--clearable .cdx-text-input__input{padding-right:calc(16px + 1rem)}.cdx-text-input--has-end-icon.cdx-text-input--clearable .cdx-text-input__input{padding-right:calc(24px + 2rem)}.cdx-text-input--status-error .cdx-text-input__input:enabled{border-color:#b32424}.cdx-text-input--status-error .cdx-text-input__input:enabled:focus{border-color:#36c}.cdx-search-input--has-end-button{background-color:#fff;display:flex;border:1px solid #a2a9b1;border-radius:2px}.cdx-search-input--has-end-button .cdx-search-input__input-wrapper{flex-grow:1;margin:-1px}.cdx-search-input--has-end-button .cdx-search-input__input-wrapper .cdx-text-input{border-top-right-radius:0;border-bottom-right-radius:0}.cdx-search-input__end-button.cdx-button{flex-shrink:0;margin:-1px -1px -1px 0;border-top-left-radius:0;border-bottom-left-radius:0}.cdx-search-input__end-button.cdx-button:hover,.cdx-search-input__end-button.cdx-button:focus{z-index:1}.cdx-search-input__input-wrapper{position:relative}.cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon{min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not (((-webkit-mask-image:none) or (mask-image:none))){.cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon{background-position:center;background-repeat:no-repeat;background-size:max(1.25rem,20px)}}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon{-webkit-mask-size:max(1.25rem,20px);mask-size:max(1.25rem,20px);-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center}}@supports not (((-webkit-mask-image:none) or (mask-image:none))){.cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M12.2 13.6a7 7 0 111.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1010 0A5 5 0 003 8\"/></svg>");filter:invert(0);opacity:.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon,.cdx-button--weight-primary.cdx-button--action-progressive .cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon,.cdx-button--weight-primary.cdx-button--action-destructive .cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon{filter:invert(1)}}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-search-input .cdx-text-input__icon.cdx-text-input__start-icon{-webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M12.2 13.6a7 7 0 111.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1010 0A5 5 0 003 8\"/></svg>");mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M12.2 13.6a7 7 0 111.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1010 0A5 5 0 003 8\"/></svg>");background-color:#202122}}.cdx-typeahead-search__menu.cdx-menu{border-top-left-radius:0;border-top-right-radius:0}.cdx-typeahead-search .cdx-menu-item{padding:0}.cdx-typeahead-search .cdx-menu-item__content{padding:8px 12px}.cdx-typeahead-search__search-footer.cdx-menu-item{box-sizing:border-box;min-height:56px}.cdx-typeahead-search__search-footer.cdx-menu-item:visited{color:#202122}.cdx-typeahead-search__search-footer.cdx-menu-item:hover{text-decoration:none;cursor:pointer}.cdx-typeahead-search__search-footer__icon.cdx-icon{color:#54595d}.cdx-typeahead-search__search-footer__active.cdx-menu-item .cdx-typeahead-search__search-footer__icon.cdx-icon,.cdx-typeahead-search__search-footer__active.cdx-menu-item .cdx-typeahead-search__search-footer__text{color:#36c}.cdx-typeahead-search .cdx-typeahead-search__menu-message--has-thumbnail{padding-left:20px}.cdx-typeahead-search--expanded .cdx-typeahead-search__input.cdx-search-input .cdx-text-input{border-bottom-left-radius:0;border-bottom-right-radius:0}.cdx-typeahead-search .cdx-text-input--has-start-icon .cdx-text-input__input{padding-left:36px}.cdx-typeahead-search--show-thumbnail.cdx-typeahead-search--auto-expand-width:not(.cdx-typeahead-search--expanded){margin-left:24px}.cdx-typeahead-search--show-thumbnail:not(.cdx-typeahead-search--auto-expand-width),.cdx-typeahead-search--show-thumbnail.cdx-typeahead-search--auto-expand-width.cdx-typeahead-search--expanded{margin-left:0}.cdx-typeahead-search--show-thumbnail:not(.cdx-typeahead-search--auto-expand-width) .cdx-text-input__input,.cdx-typeahead-search--show-thumbnail.cdx-typeahead-search--auto-expand-width.cdx-typeahead-search--expanded .cdx-text-input__input{padding-left:60px}.cdx-typeahead-search--show-thumbnail:not(.cdx-typeahead-search--auto-expand-width) .cdx-text-input__start-icon,.cdx-typeahead-search--show-thumbnail.cdx-typeahead-search--auto-expand-width.cdx-typeahead-search--expanded .cdx-text-input__start-icon{position:absolute;top:50%;min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;transition-property:color;transition-duration:.1s;left:22px;transform:translateY(-50%)}.cdx-typeahead-search--show-thumbnail .cdx-typeahead-search__search-footer__icon{flex-shrink:0;min-width:40px;width:2.5rem}.cdx-typeahead-search .cdx-menu-item:first-child .cdx-typeahead-search__search-footer{border-top:unset}
.mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{  font-size:13px;  -moz-tab-size:4; tab-size:4; }.mw-editfont-monospace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textInputWidget{font-size:inherit}.mw-editfont-monospace.oo-ui-textInputWidget > .oo-ui-inputWidget-input,.mw-editfont-sans-serif.oo-ui-textInputWidget > .oo-ui-inputWidget-input,.mw-editfont-serif.oo-ui-textInputWidget > .oo-ui-inputWidget-input{  font-size:13px}.mw-editfont-monospace.oo-ui-textInputWidget > input.oo-ui-inputWidget-input,.mw-editfont-sans-serif.oo-ui-textInputWidget > input.oo-ui-inputWidget-input,.mw-editfont-serif.oo-ui-textInputWidget > input.oo-ui-inputWidget-input{min-height:32px}
.oo-ui-icon-add,.mw-ui-icon-add:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E add %3C/title%3E%3Cpath d=%22M11 9V4H9v5H4v2h5v5h2v-5h5V9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-add,.mw-ui-icon-add-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E add %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M11 9V4H9v5H4v2h5v5h2v-5h5V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-add,.mw-ui-icon-add-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E add %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M11 9V4H9v5H4v2h5v5h2v-5h5V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-browser,.mw-ui-icon-browser:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E browser %3C/title%3E%3Cpath d=%22M2 2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm2 1.5A1.5 1.5 0 1 1 2.5 5 1.5 1.5 0 0 1 4 3.5M18 16H2V8h16z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-browser,.mw-ui-icon-browser-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E browser %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M2 2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm2 1.5A1.5 1.5 0 1 1 2.5 5 1.5 1.5 0 0 1 4 3.5M18 16H2V8h16z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-browser,.mw-ui-icon-browser-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E browser %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M2 2a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zm2 1.5A1.5 1.5 0 1 1 2.5 5 1.5 1.5 0 0 1 4 3.5M18 16H2V8h16z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-cancel,.mw-ui-icon-cancel:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0M2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10m14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-cancel,.mw-ui-icon-cancel-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0M2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10m14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-cancel,.mw-ui-icon-cancel-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0M2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10m14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-cancel,.mw-ui-icon-cancel-destructive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E cancel %3C/title%3E%3Cg fill=%22%23d73333%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0M2 10a8 8 0 0 1 1.69-4.9L14.9 16.31A8 8 0 0 1 2 10m14.31 4.9L5.1 3.69A8 8 0 0 1 16.31 14.9%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-check,.mw-ui-icon-check:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-check,.mw-ui-icon-check-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-check,.mw-ui-icon-check-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-check,.mw-ui-icon-check-destructive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%23d73333%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-success.oo-ui-icon-check,.mw-ui-icon-check-success:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check %3C/title%3E%3Cg fill=%22%2314866d%22%3E%3Cpath d=%22M7 14.2 2.8 10l-1.4 1.4L7 17 19 5l-1.4-1.4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-checkAll,.mw-ui-icon-checkAll:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check all %3C/title%3E%3Cpath d=%22m.29 12.71 1.42-1.42 2.22 2.22 8.3-10.14 1.54 1.26-9.7 11.86zM12 10h5v2h-5zm-3 4h5v2H9zm6-8h5v2h-5z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-checkAll,.mw-ui-icon-checkAll-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check all %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22m.29 12.71 1.42-1.42 2.22 2.22 8.3-10.14 1.54 1.26-9.7 11.86zM12 10h5v2h-5zm-3 4h5v2H9zm6-8h5v2h-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-checkAll,.mw-ui-icon-checkAll-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E check all %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22m.29 12.71 1.42-1.42 2.22 2.22 8.3-10.14 1.54 1.26-9.7 11.86zM12 10h5v2h-5zm-3 4h5v2H9zm6-8h5v2h-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-clear,.mw-ui-icon-clear:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clear %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m5.66 14.24-1.41 1.41L10 11.41l-4.24 4.25-1.42-1.42L8.59 10 4.34 5.76l1.42-1.42L10 8.59l4.24-4.24 1.41 1.41L11.41 10z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-clear,.mw-ui-icon-clear-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clear %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m5.66 14.24-1.41 1.41L10 11.41l-4.24 4.25-1.42-1.42L8.59 10 4.34 5.76l1.42-1.42L10 8.59l4.24-4.24 1.41 1.41L11.41 10z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-clear,.mw-ui-icon-clear-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clear %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m5.66 14.24-1.41 1.41L10 11.41l-4.24 4.25-1.42-1.42L8.59 10 4.34 5.76l1.42-1.42L10 8.59l4.24-4.24 1.41 1.41L11.41 10z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-clock,.mw-ui-icon-clock:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clock %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m2.5 14.5L9 11V4h2v6l3 3z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-clock,.mw-ui-icon-clock-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clock %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m2.5 14.5L9 11V4h2v6l3 3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-clock,.mw-ui-icon-clock-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E clock %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m2.5 14.5L9 11V4h2v6l3 3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-close,.mw-ui-icon-close:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E close %3C/title%3E%3Cpath d=%22m4.3 2.9 12.8 12.8-1.4 1.4L2.9 4.3z%22/%3E%3Cpath d=%22M17.1 4.3 4.3 17.1l-1.4-1.4L15.7 2.9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-close,.mw-ui-icon-close-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E close %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22m4.3 2.9 12.8 12.8-1.4 1.4L2.9 4.3z%22/%3E%3Cpath d=%22M17.1 4.3 4.3 17.1l-1.4-1.4L15.7 2.9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-close,.mw-ui-icon-close-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E close %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22m4.3 2.9 12.8 12.8-1.4 1.4L2.9 4.3z%22/%3E%3Cpath d=%22M17.1 4.3 4.3 17.1l-1.4-1.4L15.7 2.9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-ellipsis,.mw-ui-icon-ellipsis:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E ellipsis %3C/title%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%223%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2217%22 cy=%2210%22 r=%222%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-ellipsis,.mw-ui-icon-ellipsis-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E ellipsis %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%223%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2217%22 cy=%2210%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-ellipsis,.mw-ui-icon-ellipsis-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E ellipsis %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%223%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2217%22 cy=%2210%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-verticalEllipsis,.mw-ui-icon-verticalEllipsis:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E vertical ellipsis %3C/title%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2210%22 cy=%223%22 r=%222%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-verticalEllipsis,.mw-ui-icon-verticalEllipsis-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E vertical ellipsis %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2210%22 cy=%223%22 r=%222%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-verticalEllipsis,.mw-ui-icon-verticalEllipsis-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E vertical ellipsis %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%222%22/%3E%3Ccircle cx=%2210%22 cy=%223%22 r=%222%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-feedback,.mw-ui-icon-feedback:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E feedback %3C/title%3E%3Cpath d=%22M19 16 2 12a3.83 3.83 0 0 1-1-2.5A3.83 3.83 0 0 1 2 7l17-4z%22/%3E%3Crect width=%224%22 height=%228%22 x=%224%22 y=%229%22 rx=%222%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-feedback,.mw-ui-icon-feedback-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E feedback %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M19 16 2 12a3.83 3.83 0 0 1-1-2.5A3.83 3.83 0 0 1 2 7l17-4z%22/%3E%3Crect width=%224%22 height=%228%22 x=%224%22 y=%229%22 rx=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-feedback,.mw-ui-icon-feedback-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E feedback %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M19 16 2 12a3.83 3.83 0 0 1-1-2.5A3.83 3.83 0 0 1 2 7l17-4z%22/%3E%3Crect width=%224%22 height=%228%22 x=%224%22 y=%229%22 rx=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-funnel,.mw-ui-icon-funnel:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-funnel,.mw-ui-icon-funnel-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-funnel,.mw-ui-icon-funnel-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-funnel,.mw-ui-icon-funnel-destructive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E funnel %3C/title%3E%3Cg fill=%22%23d73333%22%3E%3Cpath d=%22M10 13 1 1h18z%22/%3E%3Cpath d=%22M8 9v8l4 2V9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-hand,.mw-ui-icon-hand:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-hand,.mw-ui-icon-hand-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-hand,.mw-ui-icon-hand-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-hand,.mw-ui-icon-hand-destructive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E hand %3C/title%3E%3Cg fill=%22%23d73333%22%3E%3Cpath d=%22M18 4.6V17c0 1.9-.5 3-2.4 3H9.5c-.9 0-1.8-.4-2.4-1l-4.6-5-.5-1c0-1 .5-1 .5-1 .3 0 .6 0 1 .2L7 14V3.3C7 2.6 7.3 2 8 2c.6 0 1 .7 1 1.4V9h1V1.2c0-.6.3-1.2 1-1.2s1 .6 1 1.3V9h1V2c0-.7.3-1.3 1-1.3s1 .6 1 1.3v7h1V4.6c0-.7.3-1.3 1-1.3s1 .6 1 1.3%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-heart,.mw-ui-icon-heart:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E heart %3C/title%3E%3Cpath d=%22M14.75 1A5.24 5.24 0 0 0 10 4 5.24 5.24 0 0 0 0 6.25C0 11.75 10 19 10 19s10-7.25 10-12.75A5.25 5.25 0 0 0 14.75 1%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-heart,.mw-ui-icon-heart-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E heart %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M14.75 1A5.24 5.24 0 0 0 10 4 5.24 5.24 0 0 0 0 6.25C0 11.75 10 19 10 19s10-7.25 10-12.75A5.25 5.25 0 0 0 14.75 1%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-heart,.mw-ui-icon-heart-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E heart %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M14.75 1A5.24 5.24 0 0 0 10 4 5.24 5.24 0 0 0 0 6.25C0 11.75 10 19 10 19s10-7.25 10-12.75A5.25 5.25 0 0 0 14.75 1%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-help,.mw-ui-icon-help:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cpath d=%22M10.06 1C13 1 15 2.89 15 5.53a4.59 4.59 0 0 1-2.29 4.08c-1.42.92-1.82 1.53-1.82 2.71V13H8.38v-.81a3.84 3.84 0 0 1 2-3.84c1.34-.9 1.79-1.53 1.79-2.71a2.1 2.1 0 0 0-2.08-2.14h-.17a2.3 2.3 0 0 0-2.38 2.22v.17H5A4.71 4.71 0 0 1 9.51 1a5 5 0 0 1 .55 0%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-help,.mw-ui-icon-help-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10.06 1C13 1 15 2.89 15 5.53a4.59 4.59 0 0 1-2.29 4.08c-1.42.92-1.82 1.53-1.82 2.71V13H8.38v-.81a3.84 3.84 0 0 1 2-3.84c1.34-.9 1.79-1.53 1.79-2.71a2.1 2.1 0 0 0-2.08-2.14h-.17a2.3 2.3 0 0 0-2.38 2.22v.17H5A4.71 4.71 0 0 1 9.51 1a5 5 0 0 1 .55 0%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-help,.mw-ui-icon-help-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10.06 1C13 1 15 2.89 15 5.53a4.59 4.59 0 0 1-2.29 4.08c-1.42.92-1.82 1.53-1.82 2.71V13H8.38v-.81a3.84 3.84 0 0 1 2-3.84c1.34-.9 1.79-1.53 1.79-2.71a2.1 2.1 0 0 0-2.08-2.14h-.17a2.3 2.3 0 0 0-2.38 2.22v.17H5A4.71 4.71 0 0 1 9.51 1a5 5 0 0 1 .55 0%22/%3E%3Ccircle cx=%2210%22 cy=%2217%22 r=%222%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-helpNotice,.mw-ui-icon-helpNotice:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m1 16H9v-2h2zm2.71-7.6a2.6 2.6 0 0 1-.33.74 3.2 3.2 0 0 1-.48.55l-.54.48c-.21.18-.41.35-.58.52a2.5 2.5 0 0 0-.47.56A2.3 2.3 0 0 0 11 12a3.8 3.8 0 0 0-.11 1H9.08a9 9 0 0 1 .07-1.25 3.3 3.3 0 0 1 .25-.9 2.8 2.8 0 0 1 .41-.67 4 4 0 0 1 .58-.58c.17-.16.34-.3.51-.44a3 3 0 0 0 .43-.44 1.8 1.8 0 0 0 .3-.55 2 2 0 0 0 .11-.72 2.1 2.1 0 0 0-.17-.86 1.7 1.7 0 0 0-1-.9 1.7 1.7 0 0 0-.5-.1 1.77 1.77 0 0 0-1.53.68 3 3 0 0 0-.5 1.82H6.16a4.7 4.7 0 0 1 .28-1.68 3.6 3.6 0 0 1 .8-1.29 3.9 3.9 0 0 1 1.28-.83A4.6 4.6 0 0 1 10.18 4a4.4 4.4 0 0 1 1.44.23 3.5 3.5 0 0 1 1.15.65 3.1 3.1 0 0 1 .78 1.06 3.5 3.5 0 0 1 .29 1.45 3.4 3.4 0 0 1-.13 1.01%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-helpNotice,.mw-ui-icon-helpNotice-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m1 16H9v-2h2zm2.71-7.6a2.6 2.6 0 0 1-.33.74 3.2 3.2 0 0 1-.48.55l-.54.48c-.21.18-.41.35-.58.52a2.5 2.5 0 0 0-.47.56A2.3 2.3 0 0 0 11 12a3.8 3.8 0 0 0-.11 1H9.08a9 9 0 0 1 .07-1.25 3.3 3.3 0 0 1 .25-.9 2.8 2.8 0 0 1 .41-.67 4 4 0 0 1 .58-.58c.17-.16.34-.3.51-.44a3 3 0 0 0 .43-.44 1.8 1.8 0 0 0 .3-.55 2 2 0 0 0 .11-.72 2.1 2.1 0 0 0-.17-.86 1.7 1.7 0 0 0-1-.9 1.7 1.7 0 0 0-.5-.1 1.77 1.77 0 0 0-1.53.68 3 3 0 0 0-.5 1.82H6.16a4.7 4.7 0 0 1 .28-1.68 3.6 3.6 0 0 1 .8-1.29 3.9 3.9 0 0 1 1.28-.83A4.6 4.6 0 0 1 10.18 4a4.4 4.4 0 0 1 1.44.23 3.5 3.5 0 0 1 1.15.65 3.1 3.1 0 0 1 .78 1.06 3.5 3.5 0 0 1 .29 1.45 3.4 3.4 0 0 1-.13 1.01%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-helpNotice,.mw-ui-icon-helpNotice-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E help %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 0a10 10 0 1 0 10 10A10 10 0 0 0 10 0m1 16H9v-2h2zm2.71-7.6a2.6 2.6 0 0 1-.33.74 3.2 3.2 0 0 1-.48.55l-.54.48c-.21.18-.41.35-.58.52a2.5 2.5 0 0 0-.47.56A2.3 2.3 0 0 0 11 12a3.8 3.8 0 0 0-.11 1H9.08a9 9 0 0 1 .07-1.25 3.3 3.3 0 0 1 .25-.9 2.8 2.8 0 0 1 .41-.67 4 4 0 0 1 .58-.58c.17-.16.34-.3.51-.44a3 3 0 0 0 .43-.44 1.8 1.8 0 0 0 .3-.55 2 2 0 0 0 .11-.72 2.1 2.1 0 0 0-.17-.86 1.7 1.7 0 0 0-1-.9 1.7 1.7 0 0 0-.5-.1 1.77 1.77 0 0 0-1.53.68 3 3 0 0 0-.5 1.82H6.16a4.7 4.7 0 0 1 .28-1.68 3.6 3.6 0 0 1 .8-1.29 3.9 3.9 0 0 1 1.28-.83A4.6 4.6 0 0 1 10.18 4a4.4 4.4 0 0 1 1.44.23 3.5 3.5 0 0 1 1.15.65 3.1 3.1 0 0 1 .78 1.06 3.5 3.5 0 0 1 .29 1.45 3.4 3.4 0 0 1-.13 1.01%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-home,.mw-ui-icon-home:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E home %3C/title%3E%3Cpath d=%22M10 1 0 10h3v9h4v-4.6c0-1.47 1.31-2.66 3-2.66s3 1.19 3 2.66V19h4v-9h3z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-home,.mw-ui-icon-home-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E home %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M10 1 0 10h3v9h4v-4.6c0-1.47 1.31-2.66 3-2.66s3 1.19 3 2.66V19h4v-9h3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-home,.mw-ui-icon-home-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E home %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M10 1 0 10h3v9h4v-4.6c0-1.47 1.31-2.66 3-2.66s3 1.19 3 2.66V19h4v-9h3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-key,.mw-ui-icon-key:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E key %3C/title%3E%3Cpath d=%22M15 6a1.54 1.54 0 0 1-1.5-1.5 1.5 1.5 0 0 1 3 0A1.54 1.54 0 0 1 15 6m-1.5-5A5.55 5.55 0 0 0 8 6.5a6.8 6.8 0 0 0 .7 2.8L1 17v2h4v-2h2v-2h2l3.2-3.2a6 6 0 0 0 1.3.2A5.55 5.55 0 0 0 19 6.5 5.55 5.55 0 0 0 13.5 1%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-key,.mw-ui-icon-key-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E key %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M15 6a1.54 1.54 0 0 1-1.5-1.5 1.5 1.5 0 0 1 3 0A1.54 1.54 0 0 1 15 6m-1.5-5A5.55 5.55 0 0 0 8 6.5a6.8 6.8 0 0 0 .7 2.8L1 17v2h4v-2h2v-2h2l3.2-3.2a6 6 0 0 0 1.3.2A5.55 5.55 0 0 0 19 6.5 5.55 5.55 0 0 0 13.5 1%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-key,.mw-ui-icon-key-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E key %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M15 6a1.54 1.54 0 0 1-1.5-1.5 1.5 1.5 0 0 1 3 0A1.54 1.54 0 0 1 15 6m-1.5-5A5.55 5.55 0 0 0 8 6.5a6.8 6.8 0 0 0 .7 2.8L1 17v2h4v-2h2v-2h2l3.2-3.2a6 6 0 0 0 1.3.2A5.55 5.55 0 0 0 19 6.5 5.55 5.55 0 0 0 13.5 1%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-keyboard,.mw-ui-icon-keyboard:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E keyboard %3C/title%3E%3Cpath d=%22M0 15a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2H2a2 2 0 0 0-2 2zm9-9h2v2H9zm0 3h2v2H9zM6 6h2v2H6zm0 3h2v2H6zm-1 5H3v-2h2zm0-3H3V9h2zm0-3H3V6h2zm9 6H6v-2h8zm0-3h-2V9h2zm0-3h-2V6h2zm3 6h-2v-2h2zm0-3h-2V9h2zm0-3h-2V6h2z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-keyboard,.mw-ui-icon-keyboard-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E keyboard %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M0 15a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2H2a2 2 0 0 0-2 2zm9-9h2v2H9zm0 3h2v2H9zM6 6h2v2H6zm0 3h2v2H6zm-1 5H3v-2h2zm0-3H3V9h2zm0-3H3V6h2zm9 6H6v-2h8zm0-3h-2V9h2zm0-3h-2V6h2zm3 6h-2v-2h2zm0-3h-2V9h2zm0-3h-2V6h2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-keyboard,.mw-ui-icon-keyboard-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E keyboard %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M0 15a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2H2a2 2 0 0 0-2 2zm9-9h2v2H9zm0 3h2v2H9zM6 6h2v2H6zm0 3h2v2H6zm-1 5H3v-2h2zm0-3H3V9h2zm0-3H3V6h2zm9 6H6v-2h8zm0-3h-2V9h2zm0-3h-2V6h2zm3 6h-2v-2h2zm0-3h-2V9h2zm0-3h-2V6h2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-lightbulb,.mw-ui-icon-lightbulb:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E lightbulb %3C/title%3E%3Cpath d=%22M8 19a1 1 0 0 0 1 1h2a1 1 0 0 0 1-1v-1H8zm9-12a7 7 0 1 0-12 4.9S7 14 7 15v1a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1c0-1 2-3.1 2-3.1A7 7 0 0 0 17 7%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-lightbulb,.mw-ui-icon-lightbulb-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E lightbulb %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M8 19a1 1 0 0 0 1 1h2a1 1 0 0 0 1-1v-1H8zm9-12a7 7 0 1 0-12 4.9S7 14 7 15v1a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1c0-1 2-3.1 2-3.1A7 7 0 0 0 17 7%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-lightbulb,.mw-ui-icon-lightbulb-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E lightbulb %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M8 19a1 1 0 0 0 1 1h2a1 1 0 0 0 1-1v-1H8zm9-12a7 7 0 1 0-12 4.9S7 14 7 15v1a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1c0-1 2-3.1 2-3.1A7 7 0 0 0 17 7%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-logIn,.mw-ui-icon-logIn:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log in %3C/title%3E%3Cpath d=%22M1 11v6c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V3c0-1.1-.9-2-2-2H3c-1.1 0-2 .9-2 2v6h8V5l4.75 5L9 15v-4z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-logIn,.mw-ui-icon-logIn-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log in %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M1 11v6c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V3c0-1.1-.9-2-2-2H3c-1.1 0-2 .9-2 2v6h8V5l4.75 5L9 15v-4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-logIn,.mw-ui-icon-logIn-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log in %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M1 11v6c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V3c0-1.1-.9-2-2-2H3c-1.1 0-2 .9-2 2v6h8V5l4.75 5L9 15v-4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-logOut,.mw-ui-icon-logOut:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log out %3C/title%3E%3Cpath d=%22M3 3h8V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h8v-2H3z%22/%3E%3Cpath d=%22M13 5v4H5v2h8v4l6-5z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-logOut,.mw-ui-icon-logOut-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log out %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M3 3h8V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h8v-2H3z%22/%3E%3Cpath d=%22M13 5v4H5v2h8v4l6-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-logOut,.mw-ui-icon-logOut-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E log out %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M3 3h8V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h8v-2H3z%22/%3E%3Cpath d=%22M13 5v4H5v2h8v4l6-5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-network,.mw-ui-icon-network:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network %3C/title%3E%3Ccircle cx=%2210%22 cy=%2215%22 r=%222%22/%3E%3Cpath d=%22M1 7.4a12 13 0 0 1 18 0l-1.5 1.4a10 11.1 0 0 0-15 0zm3.7 3.2a7 7.3 0 0 1 10.7 0L14 12a5 5.3 0 0 0-7.8 0z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-network,.mw-ui-icon-network-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2215%22 r=%222%22/%3E%3Cpath d=%22M1 7.4a12 13 0 0 1 18 0l-1.5 1.4a10 11.1 0 0 0-15 0zm3.7 3.2a7 7.3 0 0 1 10.7 0L14 12a5 5.3 0 0 0-7.8 0z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-network,.mw-ui-icon-network-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2215%22 r=%222%22/%3E%3Cpath d=%22M1 7.4a12 13 0 0 1 18 0l-1.5 1.4a10 11.1 0 0 0-15 0zm3.7 3.2a7 7.3 0 0 1 10.7 0L14 12a5 5.3 0 0 0-7.8 0z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-networkOff,.mw-ui-icon-networkOff:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network off %3C/title%3E%3Ccircle cx=%2210%22 cy=%2216%22 r=%222%22/%3E%3Cpath d=%22M16.4 11.6A7.1 7.1 0 0 0 12 9.1l3.4 3.4zM19 8.4A12.2 14 0 0 0 8.2 4.2L10 6a9.9 9.9 0 0 1 7.4 3.7zM3.5 2 2 3.4l2.2 2.2A13.1 13.1 0 0 0 1 8.4l1.5 1.3a10.7 10.7 0 0 1 3.2-2.6L8 9.3a7.3 7.3 0 0 0-3.3 2.3L6.1 13a5.2 5.2 0 0 1 3.6-2l6.8 7 1.5-1.5z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-networkOff,.mw-ui-icon-networkOff-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network off %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2216%22 r=%222%22/%3E%3Cpath d=%22M16.4 11.6A7.1 7.1 0 0 0 12 9.1l3.4 3.4zM19 8.4A12.2 14 0 0 0 8.2 4.2L10 6a9.9 9.9 0 0 1 7.4 3.7zM3.5 2 2 3.4l2.2 2.2A13.1 13.1 0 0 0 1 8.4l1.5 1.3a10.7 10.7 0 0 1 3.2-2.6L8 9.3a7.3 7.3 0 0 0-3.3 2.3L6.1 13a5.2 5.2 0 0 1 3.6-2l6.8 7 1.5-1.5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-networkOff,.mw-ui-icon-networkOff-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E network off %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2216%22 r=%222%22/%3E%3Cpath d=%22M16.4 11.6A7.1 7.1 0 0 0 12 9.1l3.4 3.4zM19 8.4A12.2 14 0 0 0 8.2 4.2L10 6a9.9 9.9 0 0 1 7.4 3.7zM3.5 2 2 3.4l2.2 2.2A13.1 13.1 0 0 0 1 8.4l1.5 1.3a10.7 10.7 0 0 1 3.2-2.6L8 9.3a7.3 7.3 0 0 0-3.3 2.3L6.1 13a5.2 5.2 0 0 1 3.6-2l6.8 7 1.5-1.5z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-newWindow,.mw-ui-icon-newWindow:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E new window %3C/title%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.3 3.3L8.6 10l1.4 1.4 5.7-5.7L19 9V1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-newWindow,.mw-ui-icon-newWindow-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E new window %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.3 3.3L8.6 10l1.4 1.4 5.7-5.7L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-newWindow,.mw-ui-icon-newWindow-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E new window %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.3 3.3L8.6 10l1.4 1.4 5.7-5.7L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-pageSettings,.mw-ui-icon-pageSettings:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E page settings %3C/title%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%221.75%22/%3E%3Cpath d=%22M15 1H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2m0 9.75-1.37.25a3.7 3.7 0 0 1-.38.93l.82 1.07L13 14.07l-1.12-.82a3.7 3.7 0 0 1-.93.38l-.2 1.37h-1.5L9 13.63a3.7 3.7 0 0 1-.93-.38L7 14.07 5.93 13l.82-1.12a3.7 3.7 0 0 1-.38-.88L5 10.75v-1.5L6.37 9a3.7 3.7 0 0 1 .38-.93L5.93 7 7 5.93l1.12.82A3.7 3.7 0 0 1 9 6.37L9.25 5h1.5L11 6.37a3.7 3.7 0 0 1 .93.38L13 5.93 14.07 7l-.82 1.12a3.7 3.7 0 0 1 .38.93l1.37.2z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-pageSettings,.mw-ui-icon-pageSettings-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E page settings %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%221.75%22/%3E%3Cpath d=%22M15 1H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2m0 9.75-1.37.25a3.7 3.7 0 0 1-.38.93l.82 1.07L13 14.07l-1.12-.82a3.7 3.7 0 0 1-.93.38l-.2 1.37h-1.5L9 13.63a3.7 3.7 0 0 1-.93-.38L7 14.07 5.93 13l.82-1.12a3.7 3.7 0 0 1-.38-.88L5 10.75v-1.5L6.37 9a3.7 3.7 0 0 1 .38-.93L5.93 7 7 5.93l1.12.82A3.7 3.7 0 0 1 9 6.37L9.25 5h1.5L11 6.37a3.7 3.7 0 0 1 .93.38L13 5.93 14.07 7l-.82 1.12a3.7 3.7 0 0 1 .38.93l1.37.2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-pageSettings,.mw-ui-icon-pageSettings-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E page settings %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Ccircle cx=%2210%22 cy=%2210%22 r=%221.75%22/%3E%3Cpath d=%22M15 1H5a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2m0 9.75-1.37.25a3.7 3.7 0 0 1-.38.93l.82 1.07L13 14.07l-1.12-.82a3.7 3.7 0 0 1-.93.38l-.2 1.37h-1.5L9 13.63a3.7 3.7 0 0 1-.93-.38L7 14.07 5.93 13l.82-1.12a3.7 3.7 0 0 1-.38-.88L5 10.75v-1.5L6.37 9a3.7 3.7 0 0 1 .38-.93L5.93 7 7 5.93l1.12.82A3.7 3.7 0 0 1 9 6.37L9.25 5h1.5L11 6.37a3.7 3.7 0 0 1 .93.38L13 5.93 14.07 7l-.82 1.12a3.7 3.7 0 0 1 .38.93l1.37.2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-printer,.mw-ui-icon-printer:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E printer %3C/title%3E%3Cpath d=%22M5 1h10v4H5zM3 6a2 2 0 0 0-2 2v7h4v4h10v-4h4V8a2 2 0 0 0-2-2zm11 12H6v-6h8zm2-8a1 1 0 1 1 1-1 1 1 0 0 1-1 1%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-printer,.mw-ui-icon-printer-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E printer %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M5 1h10v4H5zM3 6a2 2 0 0 0-2 2v7h4v4h10v-4h4V8a2 2 0 0 0-2-2zm11 12H6v-6h8zm2-8a1 1 0 1 1 1-1 1 1 0 0 1-1 1%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-printer,.mw-ui-icon-printer-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E printer %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M5 1h10v4H5zM3 6a2 2 0 0 0-2 2v7h4v4h10v-4h4V8a2 2 0 0 0-2-2zm11 12H6v-6h8zm2-8a1 1 0 1 1 1-1 1 1 0 0 1-1 1%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-reload,.mw-ui-icon-reload:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E reload %3C/title%3E%3Cpath d=%22M15.65 4.35A8 8 0 1 0 17.4 13h-2.22a6 6 0 1 1-1-7.22L11 9h7V2z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-reload,.mw-ui-icon-reload-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E reload %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M15.65 4.35A8 8 0 1 0 17.4 13h-2.22a6 6 0 1 1-1-7.22L11 9h7V2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-reload,.mw-ui-icon-reload-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E reload %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M15.65 4.35A8 8 0 1 0 17.4 13h-2.22a6 6 0 1 1-1-7.22L11 9h7V2z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-search,.mw-ui-icon-search:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E search %3C/title%3E%3Cpath d=%22M12.2 13.6a7 7 0 1 1 1.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1 0 10 0A5 5 0 0 0 3 8%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-search,.mw-ui-icon-search-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E search %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M12.2 13.6a7 7 0 1 1 1.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1 0 10 0A5 5 0 0 0 3 8%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-search,.mw-ui-icon-search-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E search %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M12.2 13.6a7 7 0 1 1 1.4-1.4l5.4 5.4-1.4 1.4zM3 8a5 5 0 1 0 10 0A5 5 0 0 0 3 8%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-settings,.mw-ui-icon-settings:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-settings,.mw-ui-icon-settings-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cg xmlns:xlink=%22http://www.w3.org/1999/xlink%22 transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-settings,.mw-ui-icon-settings-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E settings %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cg xmlns:xlink=%22http://www.w3.org/1999/xlink%22 transform=%22translate%2810 10%29%22%3E%3Cpath id=%22a%22 d=%22M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2845%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%2890%29%22/%3E%3Cuse xlink:href=%22%23a%22 transform=%22rotate%28135%29%22/%3E%3C/g%3E%3Cpath d=%22M10 2.5a7.5 7.5 0 0 0 0 15 7.5 7.5 0 0 0 0-15v4a3.5 3.5 0 0 1 0 7 3.5 3.5 0 0 1 0-7%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-subtract,.mw-ui-icon-subtract:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-subtract,.mw-ui-icon-subtract-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-subtract,.mw-ui-icon-subtract-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-subtract,.mw-ui-icon-subtract-destructive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E subtract %3C/title%3E%3Cg fill=%22%23d73333%22%3E%3Cpath d=%22M4 9h12v2H4z%22/%3E%3C/g%3E%3C/svg%3E")}
.vector-icon.mw-ui-icon-wikimedia-appearance{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=appearance&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-appearance-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=appearance&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-speechBubbleAdd{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbleAdd&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-speechBubbleAdd-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbleAdd&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-speechBubbles{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbles&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-speechBubbles-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=speechBubbles&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-article{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=article&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-article-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=article&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-history{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=history&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-history-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=history&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-wikiText{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=wikiText&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-wikiText-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=wikiText&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-edit{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=edit&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-edit-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=edit&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-editLock{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=editLock&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-editLock-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=editLock&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-exitFullscreen{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=exitFullscreen&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-exitFullscreen-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=exitFullscreen&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-fullScreen{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=fullScreen&format=original&lang=en&skin=vector-2022&version=1akhj)}.vector-icon.mw-ui-icon-wikimedia-fullScreen-progressive{background-image:url(/w/load.php?modules=skins.vector.icons.js&image=fullScreen&variant=progressive&format=original&lang=en&skin=vector-2022&version=1akhj)}
.cite-accessibility-label{ top:-99999px;clip:rect(1px,1px,1px,1px); position:absolute !important;padding:0 !important;border:0 !important;height:1px !important;width:1px !important; overflow:hidden}:target .mw-cite-targeted-backlink{font-weight:bold}.mw-cite-up-arrow-backlink{display:none}:target .mw-cite-up-arrow-backlink{display:inline}:target .mw-cite-up-arrow{display:none}
.ext-urlshortener-result-dialog{font-size:0.90909em}.ext-urlshortener-result-dialog a{word-wrap:break-word}
.ve-init-mw-progressBarWidget{height:1em;overflow:hidden;margin:0 25%}.ve-init-mw-progressBarWidget-bar{height:1em;width:0} .ve-init-mw-progressBarWidget{background-color:#fff;box-sizing:border-box;height:0.875em;border:1px solid #36c;border-radius:0.875em;box-shadow:0 1px 1px rgba(0,0,0,0.15)}.ve-init-mw-progressBarWidget-bar{background-color:#36c;height:0.875em}
.scribunto-limitreport-logs{margin:0;white-space:pre-wrap}
.rt-tooltip{position:absolute;z-index:800; max-width:350px;background:#fff;color:#222;font-size:13px;line-height:1.5em;border:1px solid #c8ccd1;border-radius:3px;box-shadow:0 15px 45px -10px rgba(0,0,0,0.3);overflow-wrap:break-word}.rt-tooltip.rt-tooltip-insideWindow{z-index:810}.rt-tooltipContent{padding:8px 11px}.rt-tooltip-above .rt-tooltipContent{margin-bottom:-8px;padding-bottom:16px}.rt-tooltip-below .rt-tooltipContent{margin-top:-10px;padding-top:18px}.rt-tooltipTail,.rt-tooltipTail:after{position:absolute;width:12px;height:12px}.rt-tooltipTail{background:linear-gradient(to top right,#c8ccd1 50%,rgba(0,0,0,0) 50%)}.rt-tooltipTail:after{content:"";background:#fff;bottom:1px;left:1px}.rt-tooltip-above .rt-tooltipTail{transform:rotate(-45deg);transform-origin:100% 100%;bottom:0;left:15px}.rt-tooltip-below .rt-tooltipTail{transform:rotate(135deg);transform-origin:0 0;top:0;left:27px}.rt-settingsLink{background-image:url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%2024%2024%22%3E%0D%0A%20%20%20%20%3Cpath%20fill%3D%22%23555%22%20d%3D%22M20%2014.5v-2.9l-1.8-.3c-.1-.4-.3-.8-.6-1.4l1.1-1.5-2.1-2.1-1.5%201.1c-.5-.3-1-.5-1.4-.6L13.5%205h-2.9l-.3%201.8c-.5.1-.9.3-1.4.6L7.4%206.3%205.3%208.4l1%201.5c-.3.5-.4.9-.6%201.4l-1.7.2v2.9l1.8.3c.1.5.3.9.6%201.4l-1%201.5%202.1%202.1%201.5-1c.4.2.9.4%201.4.6l.3%201.8h3l.3-1.8c.5-.1.9-.3%201.4-.6l1.5%201.1%202.1-2.1-1.1-1.5c.3-.5.5-1%20.6-1.4l1.5-.3zM12%2016c-1.7%200-3-1.3-3-3s1.3-3%203-3%203%201.3%203%203-1.3%203-3%203z%22%2F%3E%0D%0A%3C%2Fsvg%3E);float:right;cursor:pointer;margin:-4px -4px 0 8px;height:24px;width:24px;border-radius:2px;background-position:center center;background-repeat:no-repeat;background-size:24px 24px}.rt-settingsLink:hover{background-color:#eee}.rt-target{background-color:#def}.rt-enableSelect{font-weight:bold}.rt-settingsFormSeparator{margin:0.85714286em 0}.rt-numberInput.rt-numberInput{width:150px}.rt-tooltipsForCommentsField.rt-tooltipsForCommentsField.rt-tooltipsForCommentsField{margin-top:1.64285714em}.rt-disabledHelp{border-collapse:collapse}.rt-disabledHelp td{padding:0}.rt-disabledNote.rt-disabledNote{vertical-align:bottom;padding-left:0.36em;font-weight:bold}@keyframes rt-fade-in-up{0%{opacity:0;transform:translate(0,20px) }100%{opacity:1;transform:translate(0,0) }}@keyframes rt-fade-in-down{0%{opacity:0;transform:translate(0,-20px) }100%{opacity:1;transform:translate(0,0) }}@keyframes rt-fade-out-down{0%{opacity:1;transform:translate(0,0) }100%{opacity:0;transform:translate(0,20px) }}@keyframes rt-fade-out-up{0%{opacity:1;transform:translate(0,0) }100%{opacity:0;transform:translate(0,-20px) }}.rt-fade-in-up{animation:rt-fade-in-up 0.2s ease forwards }.rt-fade-in-down{animation:rt-fade-in-down 0.2s ease forwards }.rt-fade-out-down{animation:rt-fade-out-down 0.2s ease forwards }.rt-fade-out-up{animation:rt-fade-out-up 0.2s ease forwards }
.mw-collapsible-toggle{float:right;-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;user-select:none}.mw-collapsible-toggle-default{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:none;margin:0;padding:0;border:0;font:inherit}.mw-collapsible-toggle-default .mw-collapsible-text{color:#36c}.mw-underline-always .mw-collapsible-toggle-default .mw-collapsible-text{text-decoration:underline}.mw-underline-never .mw-collapsible-toggle-default .mw-collapsible-text{text-decoration:none}.mw-collapsible-toggle-default:hover .mw-collapsible-text{text-decoration:underline}.mw-collapsible-toggle-default:active .mw-collapsible-text{color:#faa700}.mw-collapsible-toggle-default::before{content:'['}.mw-collapsible-toggle-default::after{content:']'}.mw-customtoggle,.mw-collapsible-toggle{cursor:pointer} caption .mw-collapsible-toggle,.mw-content-ltr caption .mw-collapsible-toggle,.mw-content-rtl caption .mw-collapsible-toggle,.mw-content-rtl .mw-content-ltr caption .mw-collapsible-toggle,.mw-content-ltr .mw-content-rtl caption .mw-collapsible-toggle{float:none}
@media screen {
	.toctoggle{-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;user-select:none;font-size:94%}}
@keyframes centralAuthPPersonalAnimation{0%{opacity:0;transform:translateY(-20px)}100%{opacity:1;transform:translateY(0)}}.centralAuthPPersonalAnimation{animation-duration:1s;animation-fill-mode:both;animation-name:centralAuthPPersonalAnimation}
#mw-teleport-target{position:absolute;z-index:450}
#vector-appearance form{font-size:0.875rem;padding:6px 0}
.uls-menu{border-radius:2px; font-size:medium}.uls-search,.uls-language-settings-close-block{border-top-right-radius:2px;border-top-left-radius:2px}.uls-language-list{border-bottom-right-radius:2px;border-bottom-left-radius:2px}.uls-menu.callout::before,.uls-menu.callout::after{border-top:10px solid transparent;border-bottom:10px solid transparent;display:inline-block; top:17px;position:absolute;content:''}.uls-menu.callout.selector-right::before{ border-left:10px solid #c8ccd1; right:-11px}.uls-menu.callout.selector-right::after{ border-left:10px solid #ffffff; right:-10px}.uls-menu.callout.selector-left::before{ border-right:10px solid #c8ccd1; left:-11px}.uls-menu.callout.selector-left::after{ border-right:10px solid #ffffff; left:-10px}.uls-ui-languages button{margin:5px 15px 5px 0;white-space:nowrap;overflow:hidden}.uls-search-wrapper-wrapper{position:relative;padding-left:40px;margin-top:5px;margin-bottom:5px}.uls-icon-back{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/back-grey-ltr.svg?c9c25) no-repeat scroll center center;background-size:28px;height:32px;width:40px;display:block;position:absolute;left:0;border-right:1px solid #c8ccd1;opacity:0.87}.uls-icon-back:hover{opacity:1;cursor:pointer}.uls-menu .uls-no-results-view .uls-no-found-more{background-color:#ffffff}.uls-menu .uls-no-results-view h3{padding:0 28px;margin:0;color:#54595d;font-size:1em;font-weight:normal}   .skin-vector .uls-menu{border-color:#c8ccd1;box-shadow:0 2px 2px 0 rgba(0,0,0,0.2);font-size:0.875em;z-index:50}.skin-vector .uls-search{border-bottom-color:#c8ccd1}.skin-vector .uls-search-label{opacity:0.51;transition:opacity 250ms}.skin-vector .uls-search-wrapper:hover .uls-search-label{opacity:0.87}.skin-vector .uls-languagefilter,.skin-vector .uls-lcd-region-title{color:#54595d}.skin-vector .uls-filtersuggestion{color:#72777d}
@media print{#centralNotice{display:none}}.cn-closeButton{display:inline-block;background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUBAMAAAB/pwA+AAAAElBMVEUAAAAQEBDPz88AAABAQEDv7+9oe1vvAAAABnRSTlMA3rLe3rJS22KzAAAARElEQVQI12PAAUIUQCSTK5BwFgIxFU1AhKECUFAYKAAioXwwBeZChMGCEGGQIFQYJohgIhQgtCEMQ7ECYTHCOciOxA4AADgJTXIb9s8AAAAASUVORK5CYII=) no-repeat;width:20px;height:20px;text-indent:20px;white-space:nowrap;overflow:hidden}
#uls-settings-block{background-color:#fcfcfc}#uls-settings-block.uls-settings-block--vector-2022{display:flex;justify-content:space-between;padding:8px 12px}#uls-settings-block.uls-settings-block--vector-2022.row::before,#uls-settings-block.uls-settings-block--vector-2022.row::after{content:none}#uls-settings-block.uls-settings-block--vector-2022.uls-settings-block--with-add-languages{background-color:#f8f9fa;border-top:1px solid #c8ccd1}#uls-settings-block.uls-settings-block--vector-2022 > button.uls-add-languages-button{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/add.svg?3165e) no-repeat left center;margin-right:32px;padding-left:32px}#uls-settings-block.uls-settings-block--vector-2022 > button.uls-language-settings-button{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/cog.svg?ce0b4) no-repeat center;margin-left:auto;border:0;min-height:20px;min-width:20px}#uls-settings-block:not(.uls-settings-block--vector-2022){background-color:#f8f9fa;border-top:1px solid #c8ccd1;padding-left:10px;line-height:1.2em;border-radius:0 0 2px 2px}#uls-settings-block:not(.uls-settings-block--vector-2022) > button{background:left top transparent no-repeat;background-size:20px auto;color:#54595d;display:inline-block;margin:8px 15px;border:0;padding:0 0 0 26px;font-size:medium;cursor:pointer}#uls-settings-block:not(.uls-settings-block--vector-2022) > button:hover{color:#202122}#uls-settings-block:not(.uls-settings-block--vector-2022) > button.display-settings-block{background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/display.svg?9fd85)}#uls-settings-block:not(.uls-settings-block--vector-2022) > button.input-settings-block{background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/input.svg?60384)}.uls-tipsy.uls-tipsy{z-index:1000}.uls-empty-state{padding:28px}.uls-empty-state .uls-empty-state__header,.uls-empty-state .uls-empty-state__desc{color:#54595d}.uls-empty-state .uls-language-action-items{list-style:none;margin:1em 0}.empty-language-selector__language-settings-button{margin:12px}.uls-menu.uls-language-actions-dialog{min-width:248px}.uls-menu.uls-language-actions-dialog .uls-language-actions-title{border-bottom:1px solid #c8ccd1;display:flex;align-items:center;height:32px;padding:5px 0}.uls-menu.uls-language-actions-dialog .uls-language-actions-title .uls-language-actions-close{min-width:unset;width:44px;background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/arrow-previous.svg?279af) no-repeat center}.uls-menu.uls-language-actions-dialog .uls-language-action-items .uls-language-action.oo-ui-widget{margin:0;padding:12px 8px;display:block}.uls-menu.uls-language-actions-dialog .uls-language-action-items .uls-language-action.oo-ui-widget .oo-ui-buttonElement-button{padding-left:36px}.mw-interlanguage-selector-disabled #p-lang-btn-sticky-header{display:none}</style><style class="darkreader darkreader--sync" media="screen"></style><style>
.mw-message-box{background-color:#eaecf0;color:#000;box-sizing:border-box;margin-bottom:16px;border:1px solid #54595d;padding:12px 24px;word-wrap:break-word; overflow-wrap:break-word;overflow:hidden; }.mw-message-box > :only-child{margin:0}.mw-message-box h2{color:inherit;display:block;border:0;font-size:1em;font-weight:bold}.mw-message-box .mw-logevent-loglines li{font-size:90%}.mw-message-box-error{background-color:#fee7e6;border-color:#b32424}.mw-message-box-warning{background-color:#fef6e7;border-color:#a66200}.mw-message-box-success{background-color:#d5fdf4;border-color:#096450}
.mw-mmv-overlay{position:fixed;top:0;left:0;right:0;bottom:0;z-index:1000;background-color:#000}body.mw-mmv-lightbox-open{overflow-y:auto}body.mw-mmv-lightbox-open > *:not(.mw-notification-area-overlay){display:none}body.mw-mmv-lightbox-open > .mw-mmv-overlay,body.mw-mmv-lightbox-open > .mw-mmv-wrapper{display:block}.mw-mmv-filepage-buttons{margin-top:5px}.mw-mmv-filepage-buttons .cdx-button:nth-child(n + 2){border-left:none}.mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon{ min-width:16px;min-height:16px;width:1rem;height:1rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon{background-position:center;background-repeat:no-repeat;background-size:calc(max(1rem,16px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon{ -webkit-mask-size:calc(max(1rem,16px));mask-size:calc(max(1rem,16px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M3 5a2 2 0 00-2 2v10a2 2 0 002 2h14a2 2 0 002-2V7a2 2 0 00-2-2zm0 11 3.5-4.5 2.5 3 3.5-4.5 4.5 6zM16 2a2 2 0 012 2H2a2 2 0 012-2z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon,.cdx-button--weight-primary.cdx-button--action-progressive .mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon,.cdx-button--weight-primary.cdx-button--action-destructive .mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.mw-mmv-filepage-buttons .mw-mmv-view-expanded .cdx-button__icon{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M3 5a2 2 0 00-2 2v10a2 2 0 002 2h14a2 2 0 002-2V7a2 2 0 00-2-2zm0 11 3.5-4.5 2.5 3 3.5-4.5 4.5 6zM16 2a2 2 0 012 2H2a2 2 0 012-2z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M3 5a2 2 0 00-2 2v10a2 2 0 002 2h14a2 2 0 002-2V7a2 2 0 00-2-2zm0 11 3.5-4.5 2.5 3 3.5-4.5 4.5 6zM16 2a2 2 0 012 2H2a2 2 0 012-2z\"/></svg>");transition-property:background-color;transition-duration:100ms}}.mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon{ min-width:16px;min-height:16px;width:1rem;height:1rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon{background-position:center;background-repeat:no-repeat;background-size:calc(max(1rem,16px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon{ -webkit-mask-size:calc(max(1rem,16px));mask-size:calc(max(1rem,16px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><g transform=\"translate(10 10)\"><path id=\"cdx-icon-settings-a\" d=\"M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(45)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(90)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(135)\"/></g><path d=\"M10 2.5a7.5 7.5 0 000 15 7.5 7.5 0 000-15v4a3.5 3.5 0 010 7 3.5 3.5 0 010-7\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon,.cdx-button--weight-primary.cdx-button--action-progressive .mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon,.cdx-button--weight-primary.cdx-button--action-destructive .mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.mw-mmv-filepage-buttons .mw-mmv-view-config .cdx-button__icon{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><g transform=\"translate(10 10)\"><path id=\"cdx-icon-settings-a\" d=\"M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(45)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(90)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(135)\"/></g><path d=\"M10 2.5a7.5 7.5 0 000 15 7.5 7.5 0 000-15v4a3.5 3.5 0 010 7 3.5 3.5 0 010-7\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><g transform=\"translate(10 10)\"><path id=\"cdx-icon-settings-a\" d=\"M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(45)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(90)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(135)\"/></g><path d=\"M10 2.5a7.5 7.5 0 000 15 7.5 7.5 0 000-15v4a3.5 3.5 0 010 7 3.5 3.5 0 010-7\"/></svg>");transition-property:background-color;transition-duration:100ms}}.mw-mmv-button{background-color:transparent;min-width:0;border:0;padding:0;overflow-x:hidden;text-indent:-9999em}
.ve-init-mw-tempWikitextEditorWidget{border:0;padding:0;color:inherit;line-height:1.5em;width:100%;-moz-tab-size:4;tab-size:4; }.ve-init-mw-tempWikitextEditorWidget:focus{outline:0;padding:0}.ve-init-mw-tempWikitextEditorWidget::selection{background:rgba(109,169,247,0.5); }</style><style class="darkreader darkreader--sync" media="screen"></style><style>
.ve-active .ve-init-mw-desktopArticleTarget-targetContainer #siteNotice,.ve-active .mw-indicators,.ve-active #t-print,.ve-active #t-permalink,.ve-active #p-coll-print_export,.ve-active #t-cite,.ve-active .ve-init-mw-desktopArticleTarget-editableContent,.ve-active .ve-init-mw-tempWikitextEditorWidget{display:none}.ve-deactivating .ve-ui-surface{display:none}.ve-activating{ }.ve-activating .ve-ui-surface{height:0;padding:0 !important; overflow:hidden} .ve-loading .ve-init-mw-desktopArticleTarget-targetContainer > :not(.ve-init-mw-desktopArticleTarget-toolbarPlaceholder):not(.ve-init-mw-desktopArticleTarget),.ve-loading .ve-init-mw-desktopArticleTarget-originalContent,.ve-activated:not(.ve-loading) .ve-init-mw-desktopArticleTarget-uneditableContent{pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;opacity:0.5}.ve-activated .ve-init-mw-desktopArticleTarget-targetContainer #firstHeading{ -webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;pointer-events:auto;cursor:text}.ve-activated .ve-init-mw-desktopArticleTarget-targetContainer #firstHeading a{ pointer-events:none}.ve-activated .ve-init-mw-desktopArticleTarget-originalContent #catlinks{cursor:pointer}.ve-activated .ve-init-mw-desktopArticleTarget-originalContent #catlinks:hover{ background:#e9f2fd}.ve-activated .ve-init-mw-desktopArticleTarget-originalContent #catlinks a{opacity:1} .ve-init-mw-desktopArticleTarget-loading-overlay{z-index:2;position:absolute;width:100%;top:1em}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder{overflow:hidden;transition:height 250ms ease;height:0;padding-bottom:2px; }.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{transform:translateY(-100%);transition:transform 250ms ease}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-open .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{transform:translateY(0)}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-floating{transition:none}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-floating .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{position:fixed;top:0;z-index:1;background:#fff} .oo-ui-element-hidden{display:none !important; } .mw-editsection{ unicode-bidi:-moz-isolate;unicode-bidi:-webkit-isolate;unicode-bidi:isolate}.mw-editsection::before{content:'\200B'}.mw-editsection a{white-space:nowrap}.mw-editsection-divider{color:#54595d} .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar{height:42px;border-bottom:1px solid #c8ccd1;box-shadow:0 1px 1px 0 rgba(0,0,0,0.1)}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-floating,.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-open{height:42px} .ve-init-mw-desktopArticleTarget-toolbarPlaceholder-bar,.ve-init-mw-desktopArticleTarget-toolbar.ve-ui-toolbar > .oo-ui-toolbar-bar{box-shadow:0 2px 1px -1px rgba(0,0,0,0.1)}.ve-ui-mwSaveDialog-preview .mw-body{ }.ve-ui-mwSaveDialog-preview .mw-body .firstHeading{grid-area:titlebar}.ve-ui-mwSaveDialog-preview .mw-body .mw-body-content{grid-area:content}.ve-ui-mwSaveDialog-preview .mw-content-container{max-width:960px;margin:0 auto}.ve-init-mw-desktopArticleTarget .ve-init-mw-target-surface > .ve-ce-surface .ve-ce-attachedRootNode{min-height:15em}</style><style class="darkreader darkreader--sync" media="screen"></style><style>
.popups-icon--preview-generic{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Ctitle%3E sad face %3C/title%3E %3Cpath d=%22M2 0a2 2 0 0 0-2 2v18l4-4h14a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2zm4 4c1.336 0 2.007 1.617 1.06 2.56-.943.947-2.56.276-2.56-1.06A1.5 1.5 0 0 1 6 4m8 0c1.336 0 2.007 1.617 1.06 2.56-.943.947-2.56.276-2.56-1.06A1.5 1.5 0 0 1 14 4m-4 5c2.61 0 4.83.67 5.65 3H4.35C5.17 9.67 7.39 9 10 9%22/%3E %3C/svg%3E")}.popups-icon--footer{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%22230%22 height=%22179%22 viewBox=%220 0 230 179%22%3E %3Cdefs%3E %3Crect id=%22a%22 width=%22201%22 height=%2213%22 rx=%222%22/%3E %3Crect id=%22b%22 width=%22201%22 height=%22169%22 y=%2210%22 rx=%222%22/%3E %3Crect id=%22c%22 width=%2230%22 height=%222%22 x=%22135%22 y=%22158%22 rx=%221%22/%3E %3C/defs%3E %3Cg fill=%22none%22 fill-rule=%22evenodd%22%3E %3Cg transform=%22matrix%281 0 0 -1 0 13%29%22%3E %3Cuse xlink:href=%22%23a%22 fill=%22%23f8f9fa%22/%3E %3Crect width=%22199%22 height=%2211%22 x=%221%22 y=%221%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E %3C/g%3E %3Cuse xlink:href=%22%23b%22 fill=%22%23fff%22/%3E %3Crect width=%22199%22 height=%22167%22 x=%221%22 y=%2211%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E %3Cg fill=%22%2372777d%22 opacity=%22.4%22 transform=%22translate%2867 35%29%22%3E %3Crect width=%2273%22 height=%222%22 y=%227%22 fill=%22%23c8ccd1%22 rx=%221%22/%3E %3Crect width=%2281%22 height=%222%22 y=%2231%22 rx=%221%22/%3E %3Crect width=%2232%22 height=%222%22 y=%2285%22 rx=%221%22/%3E %3Crect width=%2273%22 height=%222%22 x=%2235%22 y=%2285%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 x=%2291%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2268%22 height=%222%22 x=%2220%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2237%22 height=%222%22 x=%2272%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2249%22 height=%222%22 x=%2220%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2224%22 height=%222%22 x=%2284%22 y=%2231%22 rx=%221%22 transform=%22matrix%28-1 0 0 1 192 0%29%22/%3E %3Crect width=%2281%22 height=%222%22 y=%2266%22 rx=%221%22/%3E %3Crect width=%2214%22 height=%222%22 x=%2254%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%2237%22 height=%222%22 x=%2271%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%2251%22 height=%222%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2259%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2252%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2292%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2238%22 rx=%221%22/%3E %3Crect width=%2251%22 height=%222%22 rx=%221%22/%3E %3C/g%3E %3Crect width=%2230%22 height=%222%22 x=%2267%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E %3Crect width=%2230%22 height=%222%22 x=%2299%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E %3Cuse xlink:href=%22%23c%22 fill=%22%2336c%22/%3E %3Crect width=%2233%22 height=%225%22 x=%22133.5%22 y=%22156.5%22 stroke=%22%23ffc057%22 stroke-opacity=%22.447%22 stroke-width=%223%22 rx=%222.5%22/%3E %3Ccircle cx=%2234%22 cy=%2249%22 r=%2219%22 fill=%22%23eaecf0%22/%3E %3Cg fill=%22%23a2a9b1%22 transform=%22translate%285 5%29%22%3E %3Ccircle cx=%221.5%22 cy=%221.5%22 r=%221.5%22/%3E %3Ccircle cx=%226%22 cy=%221.5%22 r=%221.5%22/%3E %3Ccircle cx=%2210.5%22 cy=%221.5%22 r=%221.5%22/%3E %3C/g%3E %3Cpath stroke=%22%23ff00af%22 stroke-linecap=%22square%22 d=%22M174.5 159.5h54.01%22/%3E %3C/g%3E %3C/svg%3E")}
.oo-ui-icon-edit,.mw-ui-icon-edit:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit %3C/title%3E%3Cpath d=%22m16.77 8 1.94-2a1 1 0 0 0 0-1.41l-3.34-3.3a1 1 0 0 0-1.41 0L12 3.23zM1 14.25V19h4.75l9.96-9.96-4.75-4.75z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-edit,.mw-ui-icon-edit-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22m16.77 8 1.94-2a1 1 0 0 0 0-1.41l-3.34-3.3a1 1 0 0 0-1.41 0L12 3.23zM1 14.25V19h4.75l9.96-9.96-4.75-4.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-edit,.mw-ui-icon-edit-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22m16.77 8 1.94-2a1 1 0 0 0 0-1.41l-3.34-3.3a1 1 0 0 0-1.41 0L12 3.23zM1 14.25V19h4.75l9.96-9.96-4.75-4.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-editLock,.mw-ui-icon-editLock:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit lock %3C/title%3E%3Cpath d=%22M12 12a2 2 0 0 1-2-2V5.25l-9 9V19h4.75l7-7zm7-8h-.5V2.5a2.5 2.5 0 0 0-5 0V4H13a1 1 0 0 0-1 1v4a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V5a1 1 0 0 0-1-1m-3 4a1 1 0 1 1 1-1 1 1 0 0 1-1 1m1.5-4h-3V2.75C14.5 2 14.5 1 16 1s1.5 1 1.5 1.75z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-editLock,.mw-ui-icon-editLock-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit lock %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M12 12a2 2 0 0 1-2-2V5.25l-9 9V19h4.75l7-7zm7-8h-.5V2.5a2.5 2.5 0 0 0-5 0V4H13a1 1 0 0 0-1 1v4a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V5a1 1 0 0 0-1-1m-3 4a1 1 0 1 1 1-1 1 1 0 0 1-1 1m1.5-4h-3V2.75C14.5 2 14.5 1 16 1s1.5 1 1.5 1.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-editLock,.mw-ui-icon-editLock-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E edit lock %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M12 12a2 2 0 0 1-2-2V5.25l-9 9V19h4.75l7-7zm7-8h-.5V2.5a2.5 2.5 0 0 0-5 0V4H13a1 1 0 0 0-1 1v4a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1V5a1 1 0 0 0-1-1m-3 4a1 1 0 1 1 1-1 1 1 0 0 1-1 1m1.5-4h-3V2.75C14.5 2 14.5 1 16 1s1.5 1 1.5 1.75z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-editUndo,.mw-ui-icon-editUndo:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo edit %3C/title%3E%3Cpath d=%22M1 14.25V19h4.75l8.33-8.33-5.27-4.23zM13 2.86V0L8 4l5 4V5h.86c2.29 0 4 1.43 4 4.29H20a6.51 6.51 0 0 0-6.14-6.43z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-editUndo,.mw-ui-icon-editUndo-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo edit %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M1 14.25V19h4.75l8.33-8.33-5.27-4.23zM13 2.86V0L8 4l5 4V5h.86c2.29 0 4 1.43 4 4.29H20a6.51 6.51 0 0 0-6.14-6.43z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-editUndo,.mw-ui-icon-editUndo-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo edit %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M1 14.25V19h4.75l8.33-8.33-5.27-4.23zM13 2.86V0L8 4l5 4V5h.86c2.29 0 4 1.43 4 4.29H20a6.51 6.51 0 0 0-6.14-6.43z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-link,.mw-ui-icon-link:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E link %3C/title%3E%3Cpath d=%22M4.83 15h2.91a4.9 4.9 0 0 1-1.55-2H5a3 3 0 1 1 0-6h3a3 3 0 0 1 2.82 4h2.1a5 5 0 0 0 .08-.83v-.34A4.83 4.83 0 0 0 8.17 5H4.83A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15%22/%3E%3Cpath d=%22M15.17 5h-2.91a4.9 4.9 0 0 1 1.55 2H15a3 3 0 1 1 0 6h-3a3 3 0 0 1-2.82-4h-2.1a5 5 0 0 0-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-link,.mw-ui-icon-link-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E link %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M4.83 15h2.91a4.9 4.9 0 0 1-1.55-2H5a3 3 0 1 1 0-6h3a3 3 0 0 1 2.82 4h2.1a5 5 0 0 0 .08-.83v-.34A4.83 4.83 0 0 0 8.17 5H4.83A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15%22/%3E%3Cpath d=%22M15.17 5h-2.91a4.9 4.9 0 0 1 1.55 2H15a3 3 0 1 1 0 6h-3a3 3 0 0 1-2.82-4h-2.1a5 5 0 0 0-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-link,.mw-ui-icon-link-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E link %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M4.83 15h2.91a4.9 4.9 0 0 1-1.55-2H5a3 3 0 1 1 0-6h3a3 3 0 0 1 2.82 4h2.1a5 5 0 0 0 .08-.83v-.34A4.83 4.83 0 0 0 8.17 5H4.83A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15%22/%3E%3Cpath d=%22M15.17 5h-2.91a4.9 4.9 0 0 1 1.55 2H15a3 3 0 1 1 0 6h-3a3 3 0 0 1-2.82-4h-2.1a5 5 0 0 0-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-unLink,.mw-ui-icon-unLink:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.9 4.9 0 0 1-1.55-2H5c-4 0-4-6 0-6h3q.113.002.225.012L6.215 5zm7.43 0a4.9 4.9 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03M7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34q.475 0 .941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-unLink,.mw-ui-icon-unLink-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.9 4.9 0 0 1-1.55-2H5c-4 0-4-6 0-6h3q.113.002.225.012L6.215 5zm7.43 0a4.9 4.9 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03M7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34q.475 0 .941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-unLink,.mw-ui-icon-unLink-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.9 4.9 0 0 1-1.55-2H5c-4 0-4-6 0-6h3q.113.002.225.012L6.215 5zm7.43 0a4.9 4.9 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03M7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34q.475 0 .941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-destructive.oo-ui-icon-unLink,.mw-ui-icon-unLink-destructive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E unlink %3C/title%3E%3Cg fill=%22%23d73333%22%3E%3Cpath d=%22M4.83 5A4.83 4.83 0 0 0 0 9.83v.34A4.83 4.83 0 0 0 4.83 15h2.91a4.9 4.9 0 0 1-1.55-2H5c-4 0-4-6 0-6h3q.113.002.225.012L6.215 5zm7.43 0a4.9 4.9 0 0 1 1.55 2H15c3.179.003 4.17 4.3 1.314 5.695l1.508 1.508A4.83 4.83 0 0 0 20 10.17v-.34A4.83 4.83 0 0 0 15.17 5zm-3.612.03 4.329 4.327A4.83 4.83 0 0 0 8.648 5.03M7.227 8.411C7.17 8.595 7.08 9 7.08 9c-.045.273-.08.584-.08.83v.34A4.83 4.83 0 0 0 11.83 15h3.34q.475 0 .941-.094L14.205 13H12c-2.067-.006-3.51-2.051-2.82-4zm3.755 1.36A3 3 0 0 1 10.82 11h1.389z%22/%3E%3Cpath d=%22M1.22 0 0 1.22 18.8 20l1.2-1.22z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-linkExternal,.mw-ui-icon-linkExternal:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E external link %3C/title%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.29 3.29-5.73 5.73 1.42 1.42 5.73-5.73L19 9V1z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-linkExternal,.mw-ui-icon-linkExternal-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E external link %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.29 3.29-5.73 5.73 1.42 1.42 5.73-5.73L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-linkExternal,.mw-ui-icon-linkExternal-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E external link %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M17 17H3V3h5V1H3a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-5h-2z%22/%3E%3Cpath d=%22m11 1 3.29 3.29-5.73 5.73 1.42 1.42 5.73-5.73L19 9V1z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-linkSecure,.mw-ui-icon-linkSecure:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E secure link %3C/title%3E%3Cpath d=%22M16.07 8H15V5s0-5-5-5-5 5-5 5v3H3.93A1.93 1.93 0 0 0 2 9.93v8.15A1.93 1.93 0 0 0 3.93 20h12.14A1.93 1.93 0 0 0 18 18.07V9.93A1.93 1.93 0 0 0 16.07 8M7 5.5C7 4 7 2 10 2s3 2 3 3.5V8H7zM10 16a2 2 0 1 1 2-2 2 2 0 0 1-2 2%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-linkSecure,.mw-ui-icon-linkSecure-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E secure link %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M16.07 8H15V5s0-5-5-5-5 5-5 5v3H3.93A1.93 1.93 0 0 0 2 9.93v8.15A1.93 1.93 0 0 0 3.93 20h12.14A1.93 1.93 0 0 0 18 18.07V9.93A1.93 1.93 0 0 0 16.07 8M7 5.5C7 4 7 2 10 2s3 2 3 3.5V8H7zM10 16a2 2 0 1 1 2-2 2 2 0 0 1-2 2%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-linkSecure,.mw-ui-icon-linkSecure-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E secure link %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M16.07 8H15V5s0-5-5-5-5 5-5 5v3H3.93A1.93 1.93 0 0 0 2 9.93v8.15A1.93 1.93 0 0 0 3.93 20h12.14A1.93 1.93 0 0 0 18 18.07V9.93A1.93 1.93 0 0 0 16.07 8M7 5.5C7 4 7 2 10 2s3 2 3 3.5V8H7zM10 16a2 2 0 1 1 2-2 2 2 0 0 1-2 2%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-redo,.mw-ui-icon-redo:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E redo %3C/title%3E%3Cpath d=%22M19 8.5 12 3v11zM12 7v3h-1c-4 0-7 2-7 6v1H1v-1c0-6 5-9 10-9z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-redo,.mw-ui-icon-redo-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E redo %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M19 8.5 12 3v11zM12 7v3h-1c-4 0-7 2-7 6v1H1v-1c0-6 5-9 10-9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-redo,.mw-ui-icon-redo-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E redo %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M19 8.5 12 3v11zM12 7v3h-1c-4 0-7 2-7 6v1H1v-1c0-6 5-9 10-9z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-icon-undo,.mw-ui-icon-undo:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo %3C/title%3E%3Cpath d=%22M1 8.5 8 14v-4h1c4 0 7 2 7 6v1h3v-1c0-6-5-9-10-9H8V3z%22/%3E%3C/svg%3E")}.oo-ui-image-invert.oo-ui-icon-undo,.mw-ui-icon-undo-invert:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo %3C/title%3E%3Cg fill=%22%23fff%22%3E%3Cpath d=%22M1 8.5 8 14v-4h1c4 0 7 2 7 6v1h3v-1c0-6-5-9-10-9H8V3z%22/%3E%3C/g%3E%3C/svg%3E")}.oo-ui-image-progressive.oo-ui-icon-undo,.mw-ui-icon-undo-progressive:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E%3Ctitle%3E undo %3C/title%3E%3Cg fill=%22%2336c%22%3E%3Cpath d=%22M1 8.5 8 14v-4h1c4 0 7 2 7 6v1h3v-1c0-6-5-9-10-9H8V3z%22/%3E%3C/g%3E%3C/svg%3E")}</style><style class="darkreader darkreader--sync" media="screen"></style><style>
@keyframes mwe-popups-fade-in-up{0%{opacity:0;transform:translate(0,20px)}100%{opacity:1;transform:translate(0,0)}}@keyframes mwe-popups-fade-in-down{0%{opacity:0;transform:translate(0,-20px)}100%{opacity:1;transform:translate(0,0)}}@keyframes mwe-popups-fade-out-down{0%{opacity:1;transform:translate(0,0)}100%{opacity:0;transform:translate(0,20px)}}@keyframes mwe-popups-fade-out-up{0%{opacity:1;transform:translate(0,0)}100%{opacity:0;transform:translate(0,-20px)}}.mwe-popups-fade-in-up{animation:mwe-popups-fade-in-up 0.2s ease forwards}.mwe-popups-fade-in-down{animation:mwe-popups-fade-in-down 0.2s ease forwards}.mwe-popups-fade-out-down{animation:mwe-popups-fade-out-down 0.2s ease forwards}.mwe-popups-fade-out-up{animation:mwe-popups-fade-out-up 0.2s ease forwards}.popups-icon--settings{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--settings{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--settings{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--settings{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><g transform=\"translate(10 10)\"><path id=\"cdx-icon-settings-a\" d=\"M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(45)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(90)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(135)\"/></g><path d=\"M10 2.5a7.5 7.5 0 000 15 7.5 7.5 0 000-15v4a3.5 3.5 0 010 7 3.5 3.5 0 010-7\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--settings,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--settings,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--settings{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--settings{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><g transform=\"translate(10 10)\"><path id=\"cdx-icon-settings-a\" d=\"M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(45)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(90)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(135)\"/></g><path d=\"M10 2.5a7.5 7.5 0 000 15 7.5 7.5 0 000-15v4a3.5 3.5 0 010 7 3.5 3.5 0 010-7\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><g transform=\"translate(10 10)\"><path id=\"cdx-icon-settings-a\" d=\"M1.5-10h-3l-1 6.5h5m0 7h-5l1 6.5h3\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(45)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(90)\"/><use xlink:href=\"%23cdx-icon-settings-a\" transform=\"rotate(135)\"/></g><path d=\"M10 2.5a7.5 7.5 0 000 15 7.5 7.5 0 000-15v4a3.5 3.5 0 010 7 3.5 3.5 0 010-7\"/></svg>");background-color:#202122}}.popups-icon--infoFilled{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--infoFilled{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--infoFilled{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--infoFilled{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M10 0C4.477 0 0 4.477 0 10s4.477 10 10 10 10-4.477 10-10S15.523 0 10 0M9 5h2v2H9zm0 4h2v6H9z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--infoFilled,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--infoFilled,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--infoFilled{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--infoFilled{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M10 0C4.477 0 0 4.477 0 10s4.477 10 10 10 10-4.477 10-10S15.523 0 10 0M9 5h2v2H9zm0 4h2v6H9z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M10 0C4.477 0 0 4.477 0 10s4.477 10 10 10 10-4.477 10-10S15.523 0 10 0M9 5h2v2H9zm0 4h2v6H9z\"/></svg>");background-color:#202122}}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--infoFilled:lang(ar){background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M8 19a1 1 0 001 1h2a1 1 0 001-1v-1H8zm9-12a7 7 0 10-12 4.9S7 14 7 15v1a1 1 0 001 1h4a1 1 0 001-1v-1c0-1 2-3.1 2-3.1A7 7 0 0017 7\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--infoFilled:lang(ar),.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--infoFilled:lang(ar),.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--infoFilled:lang(ar){filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--infoFilled:lang(ar){ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M8 19a1 1 0 001 1h2a1 1 0 001-1v-1H8zm9-12a7 7 0 10-12 4.9S7 14 7 15v1a1 1 0 001 1h4a1 1 0 001-1v-1c0-1 2-3.1 2-3.1A7 7 0 0017 7\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M8 19a1 1 0 001 1h2a1 1 0 001-1v-1H8zm9-12a7 7 0 10-12 4.9S7 14 7 15v1a1 1 0 001 1h4a1 1 0 001-1v-1c0-1 2-3.1 2-3.1A7 7 0 0017 7\"/></svg>");background-color:#202122}}.popups-icon--close{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--close{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--close{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--close{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"m4.34 2.93 12.73 12.73-1.41 1.41L2.93 4.35z\"/><path d=\"M17.07 4.34 4.34 17.07l-1.41-1.41L15.66 2.93z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--close,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--close,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--close{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--close{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"m4.34 2.93 12.73 12.73-1.41 1.41L2.93 4.35z\"/><path d=\"M17.07 4.34 4.34 17.07l-1.41-1.41L15.66 2.93z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"m4.34 2.93 12.73 12.73-1.41 1.41L2.93 4.35z\"/><path d=\"M17.07 4.34 4.34 17.07l-1.41-1.41L15.66 2.93z\"/></svg>");background-color:#202122}}#mwe-popups-settings{z-index:1000;background-color:#fff;width:420px;border:1px solid #a2a9b1;box-shadow:0 2px 2px 0 rgba(0,0,0,0.2);border-radius:2px;font-size:14px}#mwe-popups-settings header{box-sizing:border-box;border-bottom:1px solid #c8ccd1;position:relative;display:table;width:100%;padding:5px 7px}#mwe-popups-settings header > div{display:table-cell;width:3.25rem;vertical-align:middle;cursor:pointer}#mwe-popups-settings header h1{margin-bottom:0.6em;padding-top:0.5em;border:0;width:100%;font-family:sans-serif;font-size:18px;font-weight:bold;text-align:center}#mwe-popups-settings main#mwe-popups-settings-form{display:block;width:350px;padding:32px 0 24px;margin:0 auto}#mwe-popups-settings main#mwe-popups-settings-form p{color:#54595d;font-size:14px;margin:16px 0 0}#mwe-popups-settings main#mwe-popups-settings-form p:first-child{margin-top:0}#mwe-popups-settings main#mwe-popups-settings-form form img{margin-right:60px}#mwe-popups-settings main#mwe-popups-settings-form form label{font-size:13px;line-height:16px;width:300px;margin-left:10px;flex-direction:column}#mwe-popups-settings main#mwe-popups-settings-form form label > span{color:#000;font-size:14px;font-weight:bold;display:block;margin-bottom:5px}#mwe-popups-settings main#mwe-popups-settings-form form label::before{top:0.78125em !important}.mwe-popups-settings-help{font-size:13px;font-weight:800;margin:40px;position:relative}.mwe-popups-settings-help .popups-icon{background-size:contain;width:180px;max-width:none;height:140px;margin:0;padding:0}.mwe-popups-settings-help p{left:180px;bottom:20px;position:absolute}.mwe-popups{background:#fff;position:absolute;z-index:110;box-shadow:0 30px 90px -20px rgba(0,0,0,0.3),0 0 1px 1px rgba(0,0,0,0.05);padding:0;display:none;font-size:14px;line-height:20px;min-width:300px;border-radius:2px; }.mwe-popups .mwe-popups-container{color:#202122;text-decoration:none}.mwe-popups .mwe-popups-container footer{padding:0 16px 16px;margin:0;position:absolute;bottom:0;pointer-events:none}.mwe-popups .mwe-popups-container footer a{pointer-events:auto}.mwe-popups .mwe-popups-settings-button{float:right;pointer-events:auto;min-width:32px !important; min-height:32px !important; }.mwe-popups .mwe-popups-extract{margin:16px;display:block;color:#202122;text-decoration:none;position:relative;padding-bottom:4px}.mwe-popups .mwe-popups-extract:hover{text-decoration:none}.mwe-popups .mwe-popups-extract::after,.mwe-popups .mwe-popups-extract blockquote::after{content:' ';position:absolute;bottom:0;width:25%;height:20px;background-color:transparent;pointer-events:none}.mwe-popups .mwe-popups-extract[dir='ltr']::after{ right:0; background-image:linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract[dir='rtl']::after{ left:0; background-image:linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract blockquote::after{width:100%;height:25px; bottom:0; background-image:linear-gradient(to bottom,rgba(255,255,255,0),#ffffff 75%)}.mwe-popups .mwe-popups-extract p{margin:0}.mwe-popups .mwe-popups-extract ul,.mwe-popups .mwe-popups-extract ol,.mwe-popups .mwe-popups-extract li,.mwe-popups .mwe-popups-extract dl,.mwe-popups .mwe-popups-extract dd,.mwe-popups .mwe-popups-extract dt{margin-top:0;margin-bottom:0}.mwe-popups svg{overflow:hidden}.mwe-popups.mwe-popups-is-tall{width:450px}.mwe-popups.mwe-popups-is-tall > div > a > svg{vertical-align:middle}.mwe-popups.mwe-popups-is-tall .mwe-popups-extract{width:215px;height:176px;overflow:hidden;float:left}.mwe-popups.mwe-popups-is-tall footer{left:0;right:203px}.mwe-popups.mwe-popups-is-not-tall{width:320px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-extract{min-height:50px;max-height:136px;overflow:hidden;margin-bottom:50px}.mwe-popups.mwe-popups-is-not-tall footer{left:0;right:0}.mwe-popups.mwe-popups-no-image-pointer::before{content:'';position:absolute;border:8px solid transparent;border-top:0;border-bottom:8px solid rgba(0,0,0,0.07000000000000001);top:-8px;left:10px}.mwe-popups.mwe-popups-no-image-pointer::after{content:'';position:absolute;border:11px solid transparent;border-top:0;border-bottom:11px solid #fff;top:-7px;left:7px}.mwe-popups.flipped-x.mwe-popups-no-image-pointer::before{left:auto;right:10px}.mwe-popups.flipped-x.mwe-popups-no-image-pointer::after{left:auto;right:7px}.mwe-popups.mwe-popups-image-pointer::before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:9px;z-index:111}.mwe-popups.mwe-popups-image-pointer::after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #fff;top:-8px;left:6px;z-index:112}.mwe-popups.mwe-popups-image-pointer.flipped-x::before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:293px}.mwe-popups.mwe-popups-image-pointer.flipped-x::after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #fff;top:-8px;left:290px}.mwe-popups.mwe-popups-image-pointer > div > a > svg{margin-top:-8px;position:absolute;z-index:113;left:0}.mwe-popups.flipped-x.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped-x.mwe-popups-is-tall::before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:420px;z-index:111}.mwe-popups.flipped-x.mwe-popups-is-tall > div > a > svg{margin:0;margin-top:-8px;margin-bottom:-7px;position:absolute;z-index:113;right:0}.mwe-popups.flipped-x-y::before{content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px;left:293px;z-index:111}.mwe-popups.flipped-x-y::after{content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #fff;bottom:-8px;left:290px;z-index:112}.mwe-popups.flipped-x-y.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped-x-y.mwe-popups-is-tall::before{content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px;left:420px}.mwe-popups.flipped-x-y.mwe-popups-is-tall::after{content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #fff;bottom:-8px;left:417px}.mwe-popups.flipped-x-y.mwe-popups-is-tall > div > a > svg{margin:0;margin-bottom:-9px;position:absolute;z-index:113;right:0}.mwe-popups.flipped-y::before{content:'';position:absolute;border:8px solid transparent;border-bottom:0;border-top:8px solid #a2a9b1;bottom:-8px;left:10px}.mwe-popups.flipped-y::after{content:'';position:absolute;border:11px solid transparent;border-bottom:0;border-top:11px solid #fff;bottom:-7px;left:7px}.mwe-popups-is-tall polyline{transform:translate(0,0)}.mwe-popups-is-tall.flipped-x-y polyline{transform:translate(0,-8px)}.mwe-popups-is-tall.flipped-x polyline{transform:translate(0,8px)}.rtl .mwe-popups-is-tall polyline{transform:translate(-100%,0)}.rtl .mwe-popups-is-tall.flipped-x-y polyline{transform:translate(-100%,-8px)}.rtl .mwe-popups-is-tall.flipped-x polyline{transform:translate(-100%,8px)}@supports (clip-path:polygon(1px 1px)){.mwe-popups .mwe-popups-thumbnail{display:block;object-fit:cover;outline:1px solid rgba(0,0,0,0.1)}.mwe-popups.flipped-y .mwe-popups-container,.mwe-popups.flipped-x-y .mwe-popups-container{--y1:100%;--y2:calc(100% - var(--pointer-height));--y3:calc(100% - var(--pointer-height) - var(--pseudo-radius));--y4:var(--pseudo-radius);--y5:0;margin-bottom:calc(var(--pointer-height) * -1);padding-bottom:var(--pointer-height)}.mwe-popups:not(.flipped-y):not(.flipped-x-y) .mwe-popups-container{margin-top:calc(var(--pointer-height) * -1);padding-top:var(--pointer-height)}.mwe-popups .mwe-popups-discreet{margin-top:calc(var(--pointer-height) * -1)}.mwe-popups.mwe-popups-is-tall.flipped-y .mwe-popups-discreet,.mwe-popups.mwe-popups-is-tall.flipped-x-y .mwe-popups-discreet{margin-top:0;margin-bottom:calc(var(--pointer-height) * -1)}.mwe-popups .mwe-popups-container{--x1:0;--x2:var(--pseudo-radius);--x3:calc(var(--pointer-offset) - (var(--pointer-width) / 2));--x4:var(--pointer-offset);--x5:calc(var(--pointer-offset) + (var(--pointer-width) / 2));--x6:calc(100% - var(--pseudo-radius));--x7:100%;--y1:0;--y2:var(--pointer-height);--y3:calc(var(--pointer-height) + var(--pseudo-radius));--y4:calc(100% - var(--pseudo-radius));--y5:100%;padding-top:0;display:flex;background:#fff;--pseudo-radius:2px;--pointer-height:8px;--pointer-width:16px;--pointer-offset:26px;clip-path:polygon(var(--x2) var(--y2),var(--x3) var(--y2),var(--x4) var(--y1),var(--x5) var(--y2),var(--x6) var(--y2),var(--x7) var(--y3),var(--x7) var(--y4),var(--x6) var(--y5),var(--x2) var(--y5),var(--x1) var(--y4),var(--x1) var(--y3))}.mwe-popups.mwe-popups-is-tall{flex-direction:row}.mwe-popups.mwe-popups-is-tall .mwe-popups-discreet{order:1}.mwe-popups.mwe-popups-is-tall .mwe-popups-discreet .mwe-popups-thumbnail{width:203px;box-sizing:border-box;height:250px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-thumbnail{width:320px;height:192px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-container{flex-direction:column}.mwe-popups::before{display:none}.mwe-popups::after{display:none}body.ltr .mwe-popups.flipped-x .mwe-popups-container,body.ltr .mwe-popups.flipped-x-y .mwe-popups-container,body.rtl .mwe-popups:not(.flipped-x):not(.flipped-x-y) .mwe-popups-container{--x3:calc(100% - var(--pointer-offset) - (var(--pointer-width) / 2));--x4:calc(100% - var(--pointer-offset));--x5:calc(100% - var(--pointer-offset) + (var(--pointer-width) / 2))}}html.skin-theme-clientpref-night .mwe-popups{box-shadow:0 30px 90px -20px rgba(255,255,255,0.3),0 0 1px 1px rgba(255,255,255,0.05)}html.skin-theme-clientpref-night .mwe-popups.mwe-popups-no-image-pointer::before{content:'';position:absolute;border:8px solid transparent;border-top:0;border-bottom:8px solid rgba(255,255,255,0.07000000000000001);top:-8px;left:10px}html.skin-theme-clientpref-night .mwe-popups-extract[dir='ltr']::after{ background-image:linear-gradient(to right,rgba(0,0,0,0),#000000 50%)}html.skin-theme-clientpref-night .mwe-popups-extract[dir='rtl']::after{ background-image:linear-gradient(to left,rgba(0,0,0,0),#000000 50%)}@media (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mwe-popups{box-shadow:0 30px 90px -20px rgba(255,255,255,0.3),0 0 1px 1px rgba(255,255,255,0.05)}html.skin-theme-clientpref-os .mwe-popups.mwe-popups-no-image-pointer::before{content:'';position:absolute;border:8px solid transparent;border-top:0;border-bottom:8px solid rgba(255,255,255,0.07000000000000001);top:-8px;left:10px}html.skin-theme-clientpref-os .mwe-popups-extract[dir='ltr']::after{ background-image:linear-gradient(to right,rgba(0,0,0,0),#000000 50%)}html.skin-theme-clientpref-os .mwe-popups-extract[dir='rtl']::after{ background-image:linear-gradient(to left,rgba(0,0,0,0),#000000 50%)}}.mwe-popups .mwe-popups-title{display:block;margin-bottom:12px}.mwe-popups-type-generic.mwe-popups .mwe-popups-title{font-weight:normal;margin:0}.mwe-popups .mwe-popups-title .popups-icon,.mwe-popups .mw-parser-output .popups-icon{margin:0 8px 0 0}.mwe-popups.mwe-popups-type-generic .mwe-popups-extract,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-extract{min-height:auto}.mwe-popups.mwe-popups-type-generic .mwe-popups-read-link,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-read-link{font-weight:bold;font-size:12px;text-decoration:none}.mwe-popups.mwe-popups-type-generic .mwe-popups-extract:hover + footer .mwe-popups-read-link,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-extract:hover + footer .mwe-popups-read-link,.mwe-popups.mwe-popups-type-generic .mwe-popups-read-link:hover,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-read-link:hover{text-decoration:underline}.mwe-popups-overlay{background-color:rgba(255,255,255,0.9);z-index:999;position:fixed;height:100%;width:100%;top:0;bottom:0;left:0;right:0;display:flex;justify-content:center;align-items:center}#mwe-popups-svg{position:absolute;top:-1000px}.popups-icon{min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}.popups-icon--size-small{min-width:16px;min-height:16px;width:1rem;height:1rem}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--size-small{background-position:center;background-repeat:no-repeat;background-size:calc(max(1rem,16px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--size-small{ -webkit-mask-size:calc(max(1rem,16px));mask-size:calc(max(1rem,16px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}.mwe-popups-overlay .cdx-button.cdx-button--icon-only span + span,.mwe-popups .cdx-button.cdx-button--icon-only span + span{display:block;position:absolute !important; clip:rect(1px,1px,1px,1px);width:1px;height:1px;margin:-1px;border:0;padding:0;overflow:hidden}.cdx-button{display:inline-flex;align-items:center;justify-content:center;gap:4px;box-sizing:border-box;min-width:32px;min-height:32px;max-width:28rem;margin:0;border-width:1px;border-style:solid;border-radius:2px;padding-right:11px;padding-left:11px;font-family:inherit;font-size:inherit;font-weight:700;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;text-transform:none;transition-property:background-color,color,border-color,box-shadow;transition-duration:.1s}.cdx-button--size-large{min-width:44px;min-height:44px;padding-right:15px;padding-left:15px}.cdx-button--icon-only{padding-right:5px;padding-left:5px}.cdx-button--icon-only.cdx-button--size-large{padding-right:11px;padding-left:11px}.cdx-button::-moz-focus-inner{border:0;padding:0}.cdx-button .cdx-button__icon,.cdx-button .cdx-icon{vertical-align:middle}.cdx-button .cdx-icon{color:inherit}.cdx-button--fake-button,.cdx-button--fake-button:hover,.cdx-button--fake-button:focus{text-decoration:none}.cdx-button:enabled,.cdx-button.cdx-button--fake-button--enabled{background-color:#f8f9fa;color:#202122;border-color:#a2a9b1}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled .cdx-button__icon{background-color:#202122}}.cdx-button:enabled:hover,.cdx-button.cdx-button--fake-button--enabled:hover{background-color:#fff;color:#404244;cursor:pointer}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled:hover .cdx-button__icon{background-color:#404244}}.cdx-button:enabled:active,.cdx-button.cdx-button--fake-button--enabled:active,.cdx-button:enabled.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--is-active{background-color:#eaecf0;color:#000;border-color:#72777d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled:active .cdx-button__icon,.cdx-button:enabled.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--is-active .cdx-button__icon{background-color:#000}}.cdx-button:enabled:focus,.cdx-button.cdx-button--fake-button--enabled:focus{outline:1px solid transparent}.cdx-button:enabled:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c}.cdx-button:enabled.cdx-button--action-progressive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive{color:#36c}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-progressive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive .cdx-button__icon{background-color:#36c}}.cdx-button:enabled.cdx-button--action-progressive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:hover{color:#447ff5;border-color:#447ff5}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-progressive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:hover .cdx-button__icon{background-color:#447ff5}}.cdx-button:enabled.cdx-button--action-progressive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:active,.cdx-button:enabled.cdx-button--action-progressive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive.cdx-button--is-active{background-color:#eaf3ff;color:#2a4b8d;border-color:#2a4b8d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon{background-color:#2a4b8d}}.cdx-button:enabled.cdx-button--action-destructive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive{color:#d73333}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-destructive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive .cdx-button__icon{background-color:#d73333}}.cdx-button:enabled.cdx-button--action-destructive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:hover{color:#ff4242;border-color:#ff4242}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-destructive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:hover .cdx-button__icon{background-color:#ff4242}}.cdx-button:enabled.cdx-button--action-destructive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:active,.cdx-button:enabled.cdx-button--action-destructive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive.cdx-button--is-active{background-color:#fee7e6;color:#b32424;border-color:#b32424}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon{background-color:#b32424}}.cdx-button:enabled.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive{background-color:#36c;color:#fff;border-color:#36c}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover{background-color:#447ff5;border-color:#447ff5}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:hover .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:active,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active{background-color:#2a4b8d;border-color:#2a4b8d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-progressive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-progressive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c,inset 0 0 0 2px #fff}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive{background-color:#d73333;color:#fff;border-color:#d73333}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover{background-color:#ff4242;border-color:#ff4242}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:hover .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:active,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active{background-color:#b32424;border-color:#b32424}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-primary.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-primary.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c,inset 0 0 0 2px #fff}.cdx-button:enabled.cdx-button--weight-quiet,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet{background-color:transparent;border-color:transparent}.cdx-button:enabled.cdx-button--weight-quiet:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet:hover{background-color:rgba(0,24,73,.027)}.cdx-button:enabled.cdx-button--weight-quiet:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet:active,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--is-active{background-color:rgba(0,24,73,.082);color:#000;border-color:#72777d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--is-active .cdx-button__icon{background-color:#000}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive{color:#36c}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive .cdx-button__icon{background-color:#36c}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover{background-color:#eaf3ff;color:#447ff5}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:hover .cdx-button__icon{background-color:#447ff5}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active{background-color:#2a4b8d;color:#fff;border-color:#2a4b8d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-progressive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive{color:#d73333}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive .cdx-button__icon{background-color:#d73333}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover{background-color:#fee7e6;color:#ff4242}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:hover .cdx-button__icon{background-color:#ff4242}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active{background-color:#b32424;color:#fff;border-color:#b32424}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:active .cdx-button__icon,.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon,.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive.cdx-button--is-active .cdx-button__icon{background-color:#fff}}.cdx-button:enabled.cdx-button--weight-quiet.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active),.cdx-button.cdx-button--fake-button--enabled.cdx-button--weight-quiet.cdx-button--action-destructive:focus:not(:active):not(.cdx-button--is-active){border-color:#36c;box-shadow:inset 0 0 0 1px #36c}.cdx-button:disabled,.cdx-button.cdx-button--fake-button--disabled{background-color:#c8ccd1;color:#fff;border-color:transparent}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:disabled .cdx-button__icon,.cdx-button.cdx-button--fake-button--disabled .cdx-button__icon{background-color:#fff}}.cdx-button:disabled.cdx-button--weight-quiet,.cdx-button.cdx-button--fake-button--disabled.cdx-button--weight-quiet{background-color:transparent;color:#72777d}@supports ((-webkit-mask-image:none) or (mask-image:none)){.cdx-button:disabled.cdx-button--weight-quiet .cdx-button__icon,.cdx-button.cdx-button--fake-button--disabled.cdx-button--weight-quiet .cdx-button__icon{background-color:#72777d}}.cdx-icon{color:#202122;display:inline-flex;align-items:center;justify-content:center;vertical-align:text-bottom}.cdx-icon svg{fill:currentcolor;width:100%;height:100%}.cdx-icon--x-small{min-width:12px;min-height:12px;width:.75rem;height:.75rem}.cdx-icon--small{min-width:16px;min-height:16px;width:1rem;height:1rem}.cdx-icon--medium{min-width:20px;min-height:20px;width:1.25rem;height:1.25rem}.cdx-icon--flipped svg{transform:scaleX(-1)}.cdx-label{display:flex;flex-direction:column;line-height:1.375}.cdx-label__label__icon.cdx-icon{margin-right:4px}.cdx-label__label__text{font-weight:700}legend.cdx-label{padding:0}fieldset label.cdx-label__label .cdx-label__label__text{font-weight:400}.cdx-label:not(.cdx-label--disabled) .cdx-label__label__optional-flag,.cdx-label:not(.cdx-label--disabled) .cdx-label__description{color:#54595d}.cdx-label--disabled,.cdx-label--disabled .cdx-label__label__icon{color:#72777d}.cdx-label--visually-hidden{display:block;clip:rect(1px,1px,1px,1px);position:absolute!important;width:1px;height:1px;margin:-1px;border:0;padding:0;overflow:hidden}.cdx-label:not(.cdx-label--visually-hidden){padding-bottom:8px}@media screen and (min-width:640px){.cdx-label:not(.cdx-label--visually-hidden){padding-bottom:4px}}.cdx-checkbox{position:relative}.cdx-checkbox:not(.cdx-checkbox--inline){display:flex;margin-bottom:12px}.cdx-checkbox:not(.cdx-checkbox--inline):last-child{margin-bottom:0}.cdx-checkbox--inline{display:inline-flex;margin-right:16px;white-space:nowrap}.cdx-checkbox--inline:last-child{margin-right:0}.cdx-checkbox__label,.cdx-checkbox__label.cdx-label{display:inline-flex;position:relative;z-index:0;padding-left:calc(1.25rem + 8px);line-height:1.4285714}.cdx-checkbox__label.cdx-label{padding-bottom:0}.cdx-checkbox__label.cdx-label .cdx-label__label__text{font-weight:400}.cdx-checkbox--inline .cdx-checkbox__label{display:inline}.cdx-checkbox__icon{background-color:#fff;position:absolute;left:0;box-sizing:border-box;min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;border-width:1px;border-style:solid;transition-property:background-color,color,border-color,box-shadow;transition-duration:.1s}.cdx-checkbox__input{opacity:0;position:absolute;left:0;z-index:1;min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;margin:0;font-size:inherit;cursor:inherit}.cdx-checkbox:hover>.cdx-checkbox__input:enabled,.cdx-checkbox:hover>.cdx-checkbox__input:enabled~.cdx-label .cdx-label__label,.cdx-checkbox:hover>.cdx-checkbox__input:enabled~.cdx-checkbox__label:not(.cdx-label){cursor:pointer}.cdx-checkbox__icon{background-size:0 0;border-radius:2px}.cdx-checkbox__input:indeterminate+.cdx-checkbox__icon:before{content:" ";background-color:#fff;position:absolute;top:calc(50% - .5px);right:3px;left:3px;height:2px}.cdx-checkbox__input:checked:not(:indeterminate)+.cdx-checkbox__icon:before{content:" ";background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\"><path fill=\"%23fff\" d=\"M7 14.17L2.83 10l-1.41 1.41L7 17 19 5l-1.41-1.42z\"/></svg>");background-position:center;background-repeat:no-repeat;background-size:1rem 1rem;position:absolute;width:100%;height:100%}.cdx-checkbox__input:enabled+.cdx-checkbox__icon{border-color:#72777d}.cdx-checkbox__input:enabled:hover+.cdx-checkbox__icon{border-color:#447ff5}.cdx-checkbox__input:enabled:active+.cdx-checkbox__icon{background-color:#2a4b8d;border-color:#2a4b8d}.cdx-checkbox__input:enabled:focus:not(:active)+.cdx-checkbox__icon{border-color:#36c;box-shadow:inset 0 0 0 1px #36c;outline:1px solid transparent}.cdx-checkbox__input:enabled:checked+.cdx-checkbox__icon,.cdx-checkbox__input:enabled:indeterminate+.cdx-checkbox__icon{background-color:#36c;border-color:#36c}.cdx-checkbox__input:enabled:checked:hover+.cdx-checkbox__icon,.cdx-checkbox__input:enabled:indeterminate:hover+.cdx-checkbox__icon{background-color:#447ff5;border-color:#447ff5}.cdx-checkbox__input:enabled:checked:active+.cdx-checkbox__icon,.cdx-checkbox__input:enabled:indeterminate:active+.cdx-checkbox__icon{background-color:#2a4b8d;border-color:#2a4b8d}.cdx-checkbox__input:enabled:checked:focus:not(:active):not(:hover)+.cdx-checkbox__icon,.cdx-checkbox__input:enabled:indeterminate:focus:not(:active):not(:hover)+.cdx-checkbox__icon{background-color:#36c;border-color:#36c}.cdx-checkbox__input:enabled:checked:focus:not(:active)+.cdx-checkbox__icon,.cdx-checkbox__input:enabled:indeterminate:focus:not(:active)+.cdx-checkbox__icon{box-shadow:inset 0 0 0 1px #36c,inset 0 0 0 2px #fff}.cdx-checkbox--status-error .cdx-checkbox__input:enabled+.cdx-checkbox__icon{border-color:#b32424}.cdx-checkbox--status-error .cdx-checkbox__input:enabled:hover+.cdx-checkbox__icon{border-color:#ff4242}.cdx-checkbox--status-error .cdx-checkbox__input:enabled:active+.cdx-checkbox__icon{background-color:#b32424;border-color:transparent}.cdx-checkbox--status-error .cdx-checkbox__input:enabled:focus+.cdx-checkbox__icon{border-color:#36c}.cdx-checkbox--status-error .cdx-checkbox__input:enabled:checked+.cdx-checkbox__icon,.cdx-checkbox--status-error .cdx-checkbox__input:enabled:indeterminate+.cdx-checkbox__icon{background-color:#d73333;border-color:transparent}.cdx-checkbox--status-error .cdx-checkbox__input:enabled:checked:hover+.cdx-checkbox__icon,.cdx-checkbox--status-error .cdx-checkbox__input:enabled:indeterminate:hover+.cdx-checkbox__icon{background-color:#ff4242;border-color:#ff4242}.cdx-checkbox--status-error .cdx-checkbox__input:enabled:checked:active+.cdx-checkbox__icon,.cdx-checkbox--status-error .cdx-checkbox__input:enabled:indeterminate:active+.cdx-checkbox__icon{background-color:#b32424;border-color:transparent}.cdx-checkbox--status-error .cdx-checkbox__input:enabled:checked:focus:not(:active)+.cdx-checkbox__icon,.cdx-checkbox--status-error .cdx-checkbox__input:enabled:indeterminate:focus:not(:active)+.cdx-checkbox__icon{background-color:#d73333;border-color:#36c}.cdx-checkbox__input:disabled+.cdx-checkbox__icon{background-color:#c8ccd1;border-color:#c8ccd1}.cdx-checkbox__input:disabled~.cdx-checkbox__label,.cdx-checkbox__input:disabled~.cdx-checkbox__label.cdx-label{color:#72777d}</style><style class="darkreader darkreader--sync" media="screen"></style><style>
.popups-icon--reference-generic{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-generic{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-generic{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-generic{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"m15 10-2.78-2.78L9.44 10V1H5a2 2 0 00-2 2v14a2 2 0 002 2h10a2 2 0 002-2V3a2 2 0 00-2-2z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--reference-generic,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--reference-generic,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--reference-generic{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-generic{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"m15 10-2.78-2.78L9.44 10V1H5a2 2 0 00-2 2v14a2 2 0 002 2h10a2 2 0 002-2V3a2 2 0 00-2-2z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"m15 10-2.78-2.78L9.44 10V1H5a2 2 0 00-2 2v14a2 2 0 002 2h10a2 2 0 002-2V3a2 2 0 00-2-2z\"/></svg>");background-color:#202122}}.popups-icon--reference-book{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-book{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-book{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-book{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M15 2a7.65 7.65 0 00-5 2 7.65 7.65 0 00-5-2H1v15h4a7.65 7.65 0 015 2 7.65 7.65 0 015-2h4V2zm2.5 13.5H14a4.38 4.38 0 00-3 1V5s1-1.5 4-1.5h2.5z\"/><path d=\"M9 3.5h2v1H9z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--reference-book,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--reference-book,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--reference-book{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-book{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M15 2a7.65 7.65 0 00-5 2 7.65 7.65 0 00-5-2H1v15h4a7.65 7.65 0 015 2 7.65 7.65 0 015-2h4V2zm2.5 13.5H14a4.38 4.38 0 00-3 1V5s1-1.5 4-1.5h2.5z\"/><path d=\"M9 3.5h2v1H9z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M15 2a7.65 7.65 0 00-5 2 7.65 7.65 0 00-5-2H1v15h4a7.65 7.65 0 015 2 7.65 7.65 0 015-2h4V2zm2.5 13.5H14a4.38 4.38 0 00-3 1V5s1-1.5 4-1.5h2.5z\"/><path d=\"M9 3.5h2v1H9z\"/></svg>");background-color:#202122}}.popups-icon--reference-book[dir='rtl'],html[dir='rtl'] .popups-icon--reference-book:not([dir='ltr']){transform:scaleX(-1)}.popups-icon--reference-journal{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-journal{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-journal{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-journal{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M2 18.5A1.5 1.5 0 003.5 20H5V0H3.5A1.5 1.5 0 002 1.5zM6 0v20h10a2 2 0 002-2V2a2 2 0 00-2-2zm7 8H8V7h5zm3-2H8V5h8z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--reference-journal,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--reference-journal,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--reference-journal{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-journal{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M2 18.5A1.5 1.5 0 003.5 20H5V0H3.5A1.5 1.5 0 002 1.5zM6 0v20h10a2 2 0 002-2V2a2 2 0 00-2-2zm7 8H8V7h5zm3-2H8V5h8z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M2 18.5A1.5 1.5 0 003.5 20H5V0H3.5A1.5 1.5 0 002 1.5zM6 0v20h10a2 2 0 002-2V2a2 2 0 00-2-2zm7 8H8V7h5zm3-2H8V5h8z\"/></svg>");background-color:#202122}}.popups-icon--reference-journal[dir='rtl'],html[dir='rtl'] .popups-icon--reference-journal:not([dir='ltr']){transform:scaleX(-1)}.popups-icon--reference-news{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-news{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-news{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-news{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M5 2a2 2 0 00-2 2v12a1 1 0 01-1-1V5h-.5A1.5 1.5 0 000 6.5v10A1.5 1.5 0 001.5 18H18a2 2 0 002-2V4a2 2 0 00-2-2zm1 2h11v4H6zm0 6h6v1H6zm0 2h6v1H6zm0 2h6v1H6zm7-4h4v5h-4z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--reference-news,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--reference-news,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--reference-news{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-news{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M5 2a2 2 0 00-2 2v12a1 1 0 01-1-1V5h-.5A1.5 1.5 0 000 6.5v10A1.5 1.5 0 001.5 18H18a2 2 0 002-2V4a2 2 0 00-2-2zm1 2h11v4H6zm0 6h6v1H6zm0 2h6v1H6zm0 2h6v1H6zm7-4h4v5h-4z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M5 2a2 2 0 00-2 2v12a1 1 0 01-1-1V5h-.5A1.5 1.5 0 000 6.5v10A1.5 1.5 0 001.5 18H18a2 2 0 002-2V4a2 2 0 00-2-2zm1 2h11v4H6zm0 6h6v1H6zm0 2h6v1H6zm0 2h6v1H6zm7-4h4v5h-4z\"/></svg>");background-color:#202122}}.popups-icon--reference-news[dir='rtl'],html[dir='rtl'] .popups-icon--reference-news:not([dir='ltr']){transform:scaleX(-1)}.popups-icon--reference-web{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-web{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-web{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--reference-web{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M2 2a2 2 0 00-2 2v12a2 2 0 002 2h16a2 2 0 002-2V4a2 2 0 00-2-2zm2 1.5A1.5 1.5 0 112.5 5 1.5 1.5 0 014 3.5M18 16H2V8h16z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--reference-web,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--reference-web,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--reference-web{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--reference-web{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M2 2a2 2 0 00-2 2v12a2 2 0 002 2h16a2 2 0 002-2V4a2 2 0 00-2-2zm2 1.5A1.5 1.5 0 112.5 5 1.5 1.5 0 014 3.5M18 16H2V8h16z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M2 2a2 2 0 00-2 2v12a2 2 0 002 2h16a2 2 0 002-2V4a2 2 0 00-2-2zm2 1.5A1.5 1.5 0 112.5 5 1.5 1.5 0 014 3.5M18 16H2V8h16z\"/></svg>");background-color:#202122}}.popups-icon--reference-web[dir='rtl'],html[dir='rtl'] .popups-icon--reference-web:not([dir='ltr']){transform:scaleX(-1)}.popups-icon--preview-disambiguation{ min-width:20px;min-height:20px;width:1.25rem;height:1.25rem;display:inline-block;vertical-align:text-bottom}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--preview-disambiguation{background-position:center;background-repeat:no-repeat;background-size:calc(max(1.25rem,20px))}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--preview-disambiguation{ -webkit-mask-size:calc(max(1.25rem,20px));mask-size:calc(max(1.25rem,20px));-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-position:center;mask-position:center; }}@supports not ((-webkit-mask-image:none) or (mask-image:none)){.popups-icon--preview-disambiguation{background-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M7 0a2 2 0 00-2 2h9a2 2 0 012 2v12a2 2 0 002-2V2a2 2 0 00-2-2z\"/><path d=\"M13 20a2 2 0 002-2V5a2 2 0 00-2-2H4a2 2 0 00-2 2v13a2 2 0 002 2zM9 5h4v5H9zM4 5h4v1H4zm0 2h4v1H4zm0 2h4v1H4zm0 2h9v1H4zm0 2h9v1H4zm0 2h9v1H4z\"/></svg>");filter:invert(0);opacity:0.87}.cdx-button:not(.cdx-button--weight-quiet):disabled .popups-icon--preview-disambiguation,.cdx-button--weight-primary.cdx-button--action-progressive .popups-icon--preview-disambiguation,.cdx-button--weight-primary.cdx-button--action-destructive .popups-icon--preview-disambiguation{filter:invert(1)}}@supports (-webkit-mask-image:none) or (mask-image:none){.popups-icon--preview-disambiguation{ -webkit-mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M7 0a2 2 0 00-2 2h9a2 2 0 012 2v12a2 2 0 002-2V2a2 2 0 00-2-2z\"/><path d=\"M13 20a2 2 0 002-2V5a2 2 0 00-2-2H4a2 2 0 00-2 2v13a2 2 0 002 2zM9 5h4v5H9zM4 5h4v1H4zm0 2h4v1H4zm0 2h4v1H4zm0 2h9v1H4zm0 2h9v1H4zm0 2h9v1H4z\"/></svg>"); mask-image:url("data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"20\" height=\"20\" viewBox=\"0 0 20 20\" fill=\"%23000000\"><path d=\"M7 0a2 2 0 00-2 2h9a2 2 0 012 2v12a2 2 0 002-2V2a2 2 0 00-2-2z\"/><path d=\"M13 20a2 2 0 002-2V5a2 2 0 00-2-2H4a2 2 0 00-2 2v13a2 2 0 002 2zM9 5h4v5H9zM4 5h4v1H4zm0 2h4v1H4zm0 2h4v1H4zm0 2h9v1H4zm0 2h9v1H4zm0 2h9v1H4z\"/></svg>");background-color:#202122}}.popups-icon--preview-disambiguation[dir='rtl'],html[dir='rtl'] .popups-icon--preview-disambiguation:not([dir='ltr']){transform:scaleX(-1)} #mw-content-text .reference a[href*='#'] *{pointer-events:none}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-popups-title .popups-icon--reference-note{display:none}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-popups-extract{margin-right:0;max-height:inherit}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-popups-extract .mwe-popups-scroll{max-height:343px;overflow:auto;padding-right:16px}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-popups-extract .mw-parser-output{overflow-wrap:break-word}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-popups-extract::after{display:none}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-popups-extract .mwe-popups-fade{position:absolute;width:100%;height:20px;background-color:transparent;background-image:linear-gradient(rgba(255,255,255,0),#ffffff);opacity:0;pointer-events:none;transition:opacity 250ms ease}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-popups-extract.mwe-popups-fade-out .mwe-popups-fade{opacity:1}.mwe-popups.mwe-popups-type-reference .mwe-popups-container .mwe-collapsible-placeholder{font-weight:bold;margin:1em 0;position:relative}</style><style class="darkreader darkreader--sync" media="screen"></style><meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="Large%20language%20model%20-%20Wikipedia_files/load.css"><style class="darkreader darkreader--sync" media="screen"></style>
<meta name="generator" content="MediaWiki 1.43.0-wmf.3">
<meta name="referrer" content="origin">
<meta name="referrer" content="origin-when-cross-origin">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta name="viewport" content="width=1000">
<meta property="og:title" content="Large language model - Wikipedia">
<meta property="og:type" content="website">
<link rel="preconnect" href="https://upload.wikimedia.org/">
<link rel="alternate" media="only screen and (max-width: 720px)" href="https://en.m.wikipedia.org/wiki/Large_language_model">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit">
<link rel="apple-touch-icon" href="https://en.wikipedia.org/static/apple-touch/wikipedia.png">
<link rel="icon" href="https://en.wikipedia.org/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="https://en.wikipedia.org/w/opensearch_desc.php" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://en.wikipedia.org/w/api.php?action=rsd">
<link rel="canonical" href="https://en.wikipedia.org/wiki/Large_language_model">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="https://en.wikipedia.org/w/index.php?title=Special:RecentChanges&amp;feed=atom">
<link rel="dns-prefetch" href="https://meta.wikimedia.org/">
<link rel="dns-prefetch" href="https://login.wikimedia.org/">
<meta name="darkreader" content="c59d3c2dba5245f2ae92d3d07117e0fb"><style class="darkreader darkreader--override" media="screen">.vimvixen-hint {
    background-color: #7b5300 !important;
    border-color: #d8b013 !important;
    color: #f3e8c8 !important;
}
#vimvixen-console-frame {
    color-scheme: light !important;
}
::placeholder {
    opacity: 0.5 !important;
}
#edge-translate-panel-body,
.MuiTypography-body1,
.nfe-quote-text {
    color: var(--darkreader-neutral-text) !important;
}
gr-main-header {
    background-color: #0f3a48 !important;
}
.tou-z65h9k,
.tou-mignzq,
.tou-1b6i2ox,
.tou-lnqlqk {
    background-color: var(--darkreader-neutral-background) !important;
}
.tou-75mvi {
    background-color: #032029 !important;
}
.tou-ta9e87,
.tou-1w3fhi0,
.tou-1b8t2us,
.tou-py7lfi,
.tou-1lpmd9d,
.tou-1frrtv8,
.tou-17ezmgn {
    background-color: #0a0a0a !important;
}
.tou-uknfeu {
    background-color: #231603 !important;
}
.tou-6i3zyv {
    background-color: #19576c !important;
}
div.mermaid-viewer-control-panel .btn {
    background-color: var(--darkreader-neutral-background);
    fill: var(--darkreader-neutral-text);
}
svg g rect.er {
    fill: var(--darkreader-neutral-background) !important;
}
svg g rect.er.entityBox {
    fill: var(--darkreader-neutral-background) !important;
}
svg g rect.er.attributeBoxOdd {
    fill: var(--darkreader-neutral-background) !important;
}
svg g rect.er.attributeBoxEven {
    fill: var(--darkreader-selection-background);
    fill-opacity: 0.8 !important;
}
svg rect.er.relationshipLabelBox {
    fill: var(--darkreader-neutral-background) !important;
}
svg g g.nodes rect,
svg g g.nodes polygon {
    fill: var(--darkreader-neutral-background) !important;
}
svg g rect.task {
    fill: var(--darkreader-selection-background) !important;
}
svg line.messageLine0,
svg line.messageLine1 {
    stroke: var(--darkreader-neutral-text) !important;
}
div.mermaid .actor {
    fill: var(--darkreader-neutral-background) !important;
}
.google-material-icons {
    font-family: 'Google Material Icons' !important;
}
.google-symbols {
    font-family: 'Google Symbols Subset', 'Google Symbols' !important;
}
.material-icons-extended {
    font-family: 'Material Icons Extended' !important;
}
mitid-authenticators-code-app > .code-app-container {
    background-color: white !important;
    padding-top: 1rem;
}
iframe#unpaywall[src$="unpaywall.html"] {
    color-scheme: light !important;
}
.oui-icon {
    font-family: 'Oui Icons' !important;
}
embed[type="application/pdf"] { filter: invert(100%) contrast(90%); }
.mwe-popups-discreet > img,
div .thumbimage[src$=".png"],
div .thumbimage img[src$=".png"],
.image-carousel .image-loaded {
    background-color: white;
}
.mw-mmv-image .svg,
.fullImageLink [src*=".svg"],
a[href$=".svg"]:hover > img,
a[href*=".gif"]:hover > img {
    background-blend-mode: color;
    background-color: rgba(255, 255, 255, 0.75) !important;
}
.diff-addedline .diffchange {
    background-color: #0f3a48 !important;
}
.diff-deletedline .diffchange {
    background-color: #2f1f00 !important;
}
@keyframes unseen-fadeout-to-unread {
    from {
        background-color: #030f26 !important;
    }
    to {
        background-color: #000000 !important;
    }
}
@keyframes unseen-fadeout-to-read {
    from {
        background-color: #030f26 !important;
    }
    to {
        background-color: #0f1115 !important;
    }
}
.main-top {
    background: none !important;
}
ol.references li:target,
sup.reference:target {
    background-color: #0f3a48 !important;
}
.control-bar {
    background-color: var(--darkreader-neutral-background) !important;
    background-image: none !important;
}
.k-player,
body.mediawiki,
#dialogEngineContainer #dialogEngineDialog {
    background-color: var(--darkreader-neutral-background) !important;
}
.template-facttext {
    background-color: #3b3936 !important;
}
#mw-page-base {
    background-color: var(--darkreader-neutral-background);
    background-image: linear-gradient(rgb(24, 26, 27) 50%, var(--darkreader-neutral-background) 100%);
}
body.skin--responsive,
#menus-cover-background {
    background-image: linear-gradient(rgb(24, 26, 27) 50%, var(--darkreader-neutral-background) 100%) !important;
}
.vector-sticky-pinned-container::after {
    background: linear-gradient(transparent, var(--darkreader-neutral-background)) !important;
}
[style*="background: rgb(221, 221, 255)"],
[style*="background-color: rgb(221, 221, 255)"] {
    background: #0b0b2d !important;
}</style></head>
<body class="skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Large_language_model rootpage-Large_language_model skin-vector-2022 action-view uls-dialog-sticky-hide vector-below-page-title"><a class="mw-jump-link" href="#bodyContent">Jump to content</a>
<div class="vector-header-container">
	<header class="vector-header mw-header">
		<div class="vector-header-start">
			<nav class="vector-main-menu-landmark" aria-label="Site" role="navigation">
				
<div id="vector-main-menu-dropdown" class="vector-dropdown vector-main-menu-dropdown vector-button-flush-left vector-button-flush-right">
	<input type="checkbox" id="vector-main-menu-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-main-menu-dropdown" class="vector-dropdown-checkbox " aria-label="Main menu">
	<label id="vector-main-menu-dropdown-label" for="vector-main-menu-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"><span class="vector-icon mw-ui-icon-menu mw-ui-icon-wikimedia-menu"></span>

<span class="vector-dropdown-label-text">Main menu</span>
	</label>
	<div class="vector-dropdown-content">


				<div id="vector-main-menu-unpinned-container" class="vector-unpinned-container">
		
<div id="vector-main-menu" class="vector-main-menu vector-pinnable-element">
	<div class="vector-pinnable-header vector-main-menu-pinnable-header vector-pinnable-header-unpinned" data-feature-name="main-menu-pinned" data-pinnable-element-id="vector-main-menu" data-pinned-container-id="vector-main-menu-pinned-container" data-unpinned-container-id="vector-main-menu-unpinned-container" data-saved-pinned-state="false">
	<div class="vector-pinnable-header-label">Main menu</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-main-menu.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-main-menu.unpin">hide</button>
</div>

	
<div id="p-navigation" class="vector-menu mw-portlet mw-portlet-navigation">
	<div class="vector-menu-heading">
		Navigation
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-mainpage-description" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Main_Page" title="Visit the main page [Alt+Shift+z]" accesskey="z"><span>Main page</span></a></li><li id="n-contents" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia"><span>Contents</span></a></li><li id="n-currentevents" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Portal:Current_events" title="Articles related to current events"><span>Current events</span></a></li><li id="n-randompage" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:Random" title="Visit a randomly selected article [Alt+Shift+x]" accesskey="x"><span>Random article</span></a></li><li id="n-aboutsite" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works"><span>About Wikipedia</span></a></li><li id="n-contactpage" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia"><span>Contact us</span></a></li><li id="n-sitesupport" class="mw-list-item"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation"><span>Donate</span></a></li>
		</ul>
		
	</div>
</div>

	
	
<div id="p-interaction" class="vector-menu mw-portlet mw-portlet-interaction">
	<div class="vector-menu-heading">
		Contribute
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-help" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia"><span>Help</span></a></li><li id="n-introduction" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Help:Introduction" title="Learn how to edit Wikipedia"><span>Learn to edit</span></a></li><li id="n-portal" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:Community_portal" title="The hub for editors"><span>Community portal</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [Alt+Shift+r]" accesskey="r"><span>Recent changes</span></a></li><li id="n-upload" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard" title="Add images or other media for use on Wikipedia"><span>Upload file</span></a></li>
		</ul>
		
	</div>
</div>

</div>

				</div>

	</div>
</div>

		</nav>
			
<a href="https://en.wikipedia.org/wiki/Main_Page" class="mw-logo">
	<img class="mw-logo-icon" src="Large%20language%20model%20-%20Wikipedia_files/wikipedia.png" alt="" aria-hidden="true" height="50" width="50">
	<span class="mw-logo-container">
		<img class="mw-logo-wordmark" alt="Wikipedia" src="Large%20language%20model%20-%20Wikipedia_files/wikipedia-wordmark-en.svg" style="width: 7.5em; height: 1.125em;">
		<img class="mw-logo-tagline" alt="The Free Encyclopedia" src="Large%20language%20model%20-%20Wikipedia_files/wikipedia-tagline-en.svg" width="117" height="13" style="width: 7.3125em; height: 0.8125em;">
	</span>
</a>

		</div>
		<div class="vector-header-end">
			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-collapses vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<a href="https://en.wikipedia.org/wiki/Special:Search" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only search-toggle" id="" title="Search Wikipedia [Alt+Shift+f]" accesskey="f"><span class="vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search"></span>

<span>Search</span>
	</a>
	<div class="vector-typeahead-search-container">
		<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail cdx-typeahead-search--auto-expand-width">
			<form action="/w/index.php" id="searchform" class="cdx-search-input cdx-search-input--has-end-button">
				<div id="simpleSearch" class="cdx-search-input__input-wrapper" data-search-loc="header-moved">
					<div class="cdx-text-input cdx-text-input--has-start-icon">
						<input class="cdx-text-input__input" type="search" name="search" placeholder="Search Wikipedia" aria-label="Search Wikipedia" autocapitalize="sentences" title="Search Wikipedia [Alt+Shift+f]" accesskey="f" id="searchInput" autocomplete="off">
						<span class="cdx-text-input__icon cdx-text-input__start-icon"></span>
					</div>
					<input type="hidden" name="title" value="Special:Search">
				</div>
				<button class="cdx-button cdx-search-input__end-button">Search</button>
			</form>
		</div>
	</div>
</div>

			<nav class="vector-user-links vector-user-links-wide" aria-label="Personal tools" role="navigation">
	<div class="vector-user-links-main">
	
<div id="p-vector-user-menu-preferences" class="vector-menu mw-portlet emptyPortlet">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-userpage" class="vector-menu mw-portlet emptyPortlet">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	<nav class="vector-appearance-landmark" aria-label="Appearance">
		
		
	</nav>
	
<div id="p-vector-user-menu-notifications" class="vector-menu mw-portlet emptyPortlet">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-overflow" class="vector-menu mw-portlet">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			<li id="pt-createaccount-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw="interface" href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&amp;returnto=Large+language+model" title="You are encouraged to create an account and log in; however, it is not mandatory" class=""><span>Create account</span></a>
</li>
<li id="pt-login-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw="interface" href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Large+language+model" title="You're encouraged to log in; however, it's not mandatory. [Alt+Shift+o]" accesskey="o" class=""><span>Log in</span></a>
</li>

			
		</ul>
		
	</div>
</div>

	</div>
	
<div id="vector-user-links-dropdown" class="vector-dropdown vector-user-menu vector-button-flush-right vector-user-menu-logged-out" title="Log in and more options">
	<input type="checkbox" id="vector-user-links-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-user-links-dropdown" class="vector-dropdown-checkbox " aria-label="Personal tools">
	<label id="vector-user-links-dropdown-label" for="vector-user-links-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"><span class="vector-icon mw-ui-icon-ellipsis mw-ui-icon-wikimedia-ellipsis"></span>

<span class="vector-dropdown-label-text">Personal tools</span>
	</label>
	<div class="vector-dropdown-content">


		
<div id="p-personal" class="vector-menu mw-portlet mw-portlet-personal user-links-collapsible-item" title="User menu">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-createaccount" class="user-links-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&amp;returnto=Large+language+model" title="You are encouraged to create an account and log in; however, it is not mandatory"><span class="vector-icon mw-ui-icon-userAdd mw-ui-icon-wikimedia-userAdd"></span> <span>Create account</span></a></li><li id="pt-login" class="user-links-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Large+language+model" title="You're encouraged to log in; however, it's not mandatory. [Alt+Shift+o]" accesskey="o"><span class="vector-icon mw-ui-icon-logIn mw-ui-icon-wikimedia-logIn"></span> <span>Log in</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-user-menu-anon-editor" class="vector-menu mw-portlet mw-portlet-user-menu-anon-editor">
	<div class="vector-menu-heading">
		Pages for logged out editors <a href="https://en.wikipedia.org/wiki/Help:Introduction" aria-label="Learn more about editing"><span>learn more</span></a>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-anoncontribs" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:MyContributions" title="A list of edits made from this IP address [Alt+Shift+y]" accesskey="y"><span>Contributions</span></a></li><li id="pt-anontalk" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:MyTalk" title="Discussion about edits from this IP address [Alt+Shift+n]" accesskey="n"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

	
	</div>
</div>

</nav>

		</div>
	</header>
</div>
<div class="mw-page-container">
	<div class="mw-page-container-inner">
		<div class="vector-sitenotice-container">
			<div id="siteNotice" class="notheme"><div id="centralNotice"></div><!-- CentralNotice --></div>
		</div>
		<div class="vector-column-start">
			<div class="vector-main-menu-container">
		<div id="mw-navigation">
			<nav id="mw-panel" class="vector-main-menu-landmark" aria-label="Site" role="navigation">
				<div id="vector-main-menu-pinned-container" class="vector-pinned-container">
				
				</div>
		</nav>
		</div>
	</div>
	<div class="vector-sticky-pinned-container">
				<nav id="mw-panel-toc" role="navigation" aria-label="Contents" data-event-name="ui.sidebar-toc" class="mw-table-of-contents-container vector-toc-landmark">
					<div id="vector-toc-pinned-container" class="vector-pinned-container">
					<div id="vector-toc" class="vector-toc vector-pinnable-element">
	<div class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned" data-feature-name="toc-pinned" data-pinnable-element-id="vector-toc">
	<h2 class="vector-pinnable-header-label">Contents</h2>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-toc.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button>
</div>


	<ul class="vector-toc-contents" id="mw-panel-toc-list">
		<li id="toc-mw-content-text" class="vector-toc-list-item vector-toc-level-1">
			<a href="#" class="vector-toc-link">
				<div class="vector-toc-text">(Top)</div>
			</a>
		</li>
		<li id="toc-History" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#History">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">1</span>History</div>
		</a>
		
		<ul id="toc-History-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Dataset_preprocessing" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Dataset_preprocessing">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">2</span>Dataset preprocessing</div>
		</a>
		
			<button aria-controls="toc-Dataset_preprocessing-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle" aria-expanded="false">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Dataset preprocessing subsection</span>
			</button>
		
		<ul id="toc-Dataset_preprocessing-sublist" class="vector-toc-list">
			<li id="toc-Probabilistic_tokenization" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Probabilistic_tokenization">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.1</span>Probabilistic tokenization</div>
			</a>
			
			<ul id="toc-Probabilistic_tokenization-sublist" class="vector-toc-list">
				<li id="toc-BPE" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#BPE">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.1.1</span>BPE</div>
			</a>
			
			<ul id="toc-BPE-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Dataset_cleaning" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Dataset_cleaning">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.2</span>Dataset cleaning</div>
			</a>
			
			<ul id="toc-Dataset_cleaning-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Synthetic_data" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Synthetic_data">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.3</span>Synthetic data</div>
			</a>
			
			<ul id="toc-Synthetic_data-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Training_and_architecture" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Training_and_architecture">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">3</span>Training and architecture</div>
		</a>
		
			<button aria-controls="toc-Training_and_architecture-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle" aria-expanded="false">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Training and architecture subsection</span>
			</button>
		
		<ul id="toc-Training_and_architecture-sublist" class="vector-toc-list">
			<li id="toc-Reinforcement_learning_from_human_feedback_(RLHF)" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Reinforcement_learning_from_human_feedback_(RLHF)">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.1</span>Reinforcement learning from human feedback (RLHF)</div>
			</a>
			
			<ul id="toc-Reinforcement_learning_from_human_feedback_(RLHF)-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Instruction_tuning" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Instruction_tuning">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.2</span>Instruction tuning</div>
			</a>
			
			<ul id="toc-Instruction_tuning-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Mixture_of_experts" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Mixture_of_experts">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.3</span>Mixture of experts</div>
			</a>
			
			<ul id="toc-Mixture_of_experts-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Prompt_engineering,_attention_mechanism,_and_context_window" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Prompt_engineering,_attention_mechanism,_and_context_window">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.4</span>Prompt engineering, attention mechanism, and context window</div>
			</a>
			
			<ul id="toc-Prompt_engineering,_attention_mechanism,_and_context_window-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Training_cost" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Training_cost">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">4</span>Training cost</div>
		</a>
		
		<ul id="toc-Training_cost-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Tool_use" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Tool_use">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">5</span>Tool use</div>
		</a>
		
		<ul id="toc-Tool_use-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Agency" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Agency">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">6</span>Agency</div>
		</a>
		
		<ul id="toc-Agency-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Compression" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Compression">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">7</span>Compression</div>
		</a>
		
		<ul id="toc-Compression-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Multimodality" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Multimodality">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">8</span>Multimodality</div>
		</a>
		
		<ul id="toc-Multimodality-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Properties" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Properties">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">9</span>Properties</div>
		</a>
		
			<button aria-controls="toc-Properties-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle" aria-expanded="false">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Properties subsection</span>
			</button>
		
		<ul id="toc-Properties-sublist" class="vector-toc-list">
			<li id="toc-Scaling_laws" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Scaling_laws">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">9.1</span>Scaling laws</div>
			</a>
			
			<ul id="toc-Scaling_laws-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Emergent_abilities" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Emergent_abilities">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">9.2</span>Emergent abilities</div>
			</a>
			
			<ul id="toc-Emergent_abilities-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Interpretation" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Interpretation">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">10</span>Interpretation</div>
		</a>
		
			<button aria-controls="toc-Interpretation-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle" aria-expanded="false">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Interpretation subsection</span>
			</button>
		
		<ul id="toc-Interpretation-sublist" class="vector-toc-list">
			<li id="toc-Understanding_and_intelligence" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Understanding_and_intelligence">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">10.1</span>Understanding and intelligence</div>
			</a>
			
			<ul id="toc-Understanding_and_intelligence-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Evaluation" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Evaluation">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">11</span>Evaluation</div>
		</a>
		
			<button aria-controls="toc-Evaluation-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle" aria-expanded="false">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Evaluation subsection</span>
			</button>
		
		<ul id="toc-Evaluation-sublist" class="vector-toc-list">
			<li id="toc-Perplexity" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Perplexity">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">11.1</span>Perplexity</div>
			</a>
			
			<ul id="toc-Perplexity-sublist" class="vector-toc-list">
				<li id="toc-BPW,_BPC,_and_BPT" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#BPW,_BPC,_and_BPT">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">11.1.1</span>BPW, BPC, and BPT</div>
			</a>
			
			<ul id="toc-BPW,_BPC,_and_BPT-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Task-specific_datasets_and_benchmarks" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Task-specific_datasets_and_benchmarks">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">11.2</span>Task-specific datasets and benchmarks</div>
			</a>
			
			<ul id="toc-Task-specific_datasets_and_benchmarks-sublist" class="vector-toc-list">
				<li id="toc-Adversarially_constructed_evaluations" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Adversarially_constructed_evaluations">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">11.2.1</span>Adversarially constructed evaluations</div>
			</a>
			
			<ul id="toc-Adversarially_constructed_evaluations-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Wider_impact" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Wider_impact">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">12</span>Wider impact</div>
		</a>
		
			<button aria-controls="toc-Wider_impact-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle" aria-expanded="false">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Wider impact subsection</span>
			</button>
		
		<ul id="toc-Wider_impact-sublist" class="vector-toc-list">
			<li id="toc-Memorization_and_copyright" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Memorization_and_copyright">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">12.1</span>Memorization and copyright</div>
			</a>
			
			<ul id="toc-Memorization_and_copyright-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Security" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Security">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">12.2</span>Security</div>
			</a>
			
			<ul id="toc-Security-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Algorithmic_bias" class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Algorithmic_bias">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">12.3</span>Algorithmic bias</div>
			</a>
			
			<ul id="toc-Algorithmic_bias-sublist" class="vector-toc-list">
				<li id="toc-Stereotyping" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Stereotyping">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">12.3.1</span>Stereotyping</div>
			</a>
			
			<ul id="toc-Stereotyping-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Political_bias" class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Political_bias">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">12.3.2</span>Political bias</div>
			</a>
			
			<ul id="toc-Political_bias-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-List" class="vector-toc-list-item vector-toc-level-1 vector-toc-level-1-active vector-toc-list-item-active">
		<a class="vector-toc-link" href="#List">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">13</span>List</div>
		</a>
		
		<ul id="toc-List-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-See_also" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#See_also">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">14</span>See also</div>
		</a>
		
		<ul id="toc-See_also-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Notes" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Notes">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">15</span>Notes</div>
		</a>
		
		<ul id="toc-Notes-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-References" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#References">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">16</span>References</div>
		</a>
		
		<ul id="toc-References-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Further_reading" class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Further_reading">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">17</span>Further reading</div>
		</a>
		
		<ul id="toc-Further_reading-sublist" class="vector-toc-list">
		</ul>
	</li>
</ul>
</div>

					</div>
		</nav>
			</div>
		</div>
		<div class="mw-content-container">
			<main id="content" class="mw-body" role="main">
				<header class="mw-body-header vector-page-titlebar">
					<nav role="navigation" aria-label="Contents" class="vector-toc-landmark">
						
<div id="vector-page-titlebar-toc" class="vector-dropdown vector-page-titlebar-toc vector-button-flush-left">
	<input type="checkbox" id="vector-page-titlebar-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-titlebar-toc" class="vector-dropdown-checkbox " aria-label="Toggle the table of contents">
	<label id="vector-page-titlebar-toc-label" for="vector-page-titlebar-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--icon-only" aria-hidden="true"><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
	</label>
	<div class="vector-dropdown-content">


							<div id="vector-page-titlebar-toc-unpinned-container" class="vector-unpinned-container">
			</div>
		
	</div>
</div>

					</nav>
					<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">Large language model</span></h1>
							
<div id="p-lang-btn" class="vector-dropdown mw-portlet mw-portlet-lang">
	<input type="checkbox" id="p-lang-btn-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-lang-btn" class="vector-dropdown-checkbox mw-interlanguage-selector" aria-label="Go to an article in another language. Available in 36 languages">
	<label id="p-lang-btn-label" for="p-lang-btn-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-36" aria-hidden="true"><span class="vector-icon mw-ui-icon-language-progressive mw-ui-icon-wikimedia-language-progressive"></span>

<span class="vector-dropdown-label-text">36 languages</span>
	</label>
	<div class="vector-dropdown-content">

		<div class="vector-menu-content">
			
			<ul class="vector-menu-content-list">
				
				<li class="interlanguage-link interwiki-ar mw-list-item"><a href="https://ar.wikipedia.org/wiki/%D9%86%D9%85%D9%88%D8%B0%D8%AC_%D8%A7%D9%84%D9%84%D8%BA%D8%A9_%D8%A7%D9%84%D9%83%D8%A8%D9%8A%D8%B1" title="نموذج اللغة الكبير – Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target"><span>العربية</span></a></li><li class="interlanguage-link interwiki-az mw-list-item"><a href="https://az.wikipedia.org/wiki/B%C3%B6y%C3%BCk_dil_modeli" title="Böyük dil modeli – Azerbaijani" lang="az" hreflang="az" class="interlanguage-link-target"><span>Azərbaycanca</span></a></li><li class="interlanguage-link interwiki-zh-min-nan mw-list-item"><a href="https://zh-min-nan.wikipedia.org/wiki/T%C5%8Da-h%C3%AAng_g%C3%AD-gi%C3%A2n_b%C3%B4%CD%98-h%C3%AAng" title="Tōa-hêng gí-giân bô͘-hêng – Minnan" lang="nan" hreflang="nan" class="interlanguage-link-target"><span>閩南語 / Bân-lâm-gú</span></a></li><li class="interlanguage-link interwiki-bar mw-list-item"><a href="https://bar.wikipedia.org/wiki/Large_language_model" title="Large language model – Bavarian" lang="bar" hreflang="bar" class="interlanguage-link-target"><span>Boarisch</span></a></li><li class="interlanguage-link interwiki-bs mw-list-item"><a href="https://bs.wikipedia.org/wiki/Veliki_jezi%C4%8Dki_modeli" title="Veliki jezički modeli – Bosnian" lang="bs" hreflang="bs" class="interlanguage-link-target"><span>Bosanski</span></a></li><li class="interlanguage-link interwiki-ca mw-list-item"><a href="https://ca.wikipedia.org/wiki/Model_de_llenguatge_extens" title="Model de llenguatge extens – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target"><span>Català</span></a></li><li class="interlanguage-link interwiki-cs mw-list-item"><a href="https://cs.wikipedia.org/wiki/Velk%C3%BD_jazykov%C3%BD_model" title="Velký jazykový model – Czech" lang="cs" hreflang="cs" class="interlanguage-link-target"><span>Čeština</span></a></li><li class="interlanguage-link interwiki-de mw-list-item"><a href="https://de.wikipedia.org/wiki/Large_Language_Model" title="Large Language Model – German" lang="de" hreflang="de" class="interlanguage-link-target"><span>Deutsch</span></a></li><li class="interlanguage-link interwiki-el mw-list-item"><a href="https://el.wikipedia.org/wiki/%CE%9C%CE%B5%CE%B3%CE%AC%CE%BB%CE%BF_%CE%B3%CE%BB%CF%89%CF%83%CF%83%CE%B9%CE%BA%CF%8C_%CE%BC%CE%BF%CE%BD%CF%84%CE%AD%CE%BB%CE%BF" title="Μεγάλο γλωσσικό μοντέλο – Greek" lang="el" hreflang="el" class="interlanguage-link-target"><span>Ελληνικά</span></a></li><li class="interlanguage-link interwiki-es mw-list-item"><a href="https://es.wikipedia.org/wiki/Modelo_de_lenguaje_grande" title="Modelo de lenguaje grande – Spanish" lang="es" hreflang="es" class="interlanguage-link-target"><span>Español</span></a></li><li class="interlanguage-link interwiki-eu mw-list-item"><a href="https://eu.wikipedia.org/wiki/Hizkuntza_Eredu_Handiak_(LLM)" title="Hizkuntza Eredu Handiak (LLM) – Basque" lang="eu" hreflang="eu" class="interlanguage-link-target"><span>Euskara</span></a></li><li class="interlanguage-link interwiki-fa mw-list-item"><a href="https://fa.wikipedia.org/wiki/%D9%85%D8%AF%D9%84_%D8%B2%D8%A8%D8%A7%D9%86%DB%8C_%D8%A8%D8%B2%D8%B1%DA%AF" title="مدل زبانی بزرگ – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target"><span>فارسی</span></a></li><li class="interlanguage-link interwiki-fr mw-list-item"><a href="https://fr.wikipedia.org/wiki/Grand_mod%C3%A8le_de_langage" title="Grand modèle de langage – French" lang="fr" hreflang="fr" class="interlanguage-link-target"><span>Français</span></a></li><li class="interlanguage-link interwiki-ga mw-list-item"><a href="https://ga.wikipedia.org/wiki/Samhail_teanga_mh%C3%B3r" title="Samhail teanga mhór – Irish" lang="ga" hreflang="ga" class="interlanguage-link-target"><span>Gaeilge</span></a></li><li class="interlanguage-link interwiki-gl mw-list-item"><a href="https://gl.wikipedia.org/wiki/Modelo_de_linguaxe_de_grande_escala" title="Modelo de linguaxe de grande escala – Galician" lang="gl" hreflang="gl" class="interlanguage-link-target"><span>Galego</span></a></li><li class="interlanguage-link interwiki-ko mw-list-item"><a href="https://ko.wikipedia.org/wiki/%EB%8C%80%ED%98%95_%EC%96%B8%EC%96%B4_%EB%AA%A8%EB%8D%B8" title="대형 언어 모델 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target"><span>한국어</span></a></li><li class="interlanguage-link interwiki-hi mw-list-item"><a href="https://hi.wikipedia.org/wiki/%E0%A4%AC%E0%A4%A1%E0%A4%BC%E0%A5%87_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE_%E0%A4%AE%E0%A5%89%E0%A4%A1%E0%A4%B2" title="बड़े भाषा मॉडल – Hindi" lang="hi" hreflang="hi" class="interlanguage-link-target"><span>हिन्दी</span></a></li><li class="interlanguage-link interwiki-id mw-list-item"><a href="https://id.wikipedia.org/wiki/Model_bahasa_besar" title="Model bahasa besar – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target"><span>Bahasa Indonesia</span></a></li><li class="interlanguage-link interwiki-zu mw-list-item"><a href="https://zu.wikipedia.org/wiki/UNongo_lolimi_olukhulu" title="UNongo lolimi olukhulu – Zulu" lang="zu" hreflang="zu" class="interlanguage-link-target"><span>IsiZulu</span></a></li><li class="interlanguage-link interwiki-it mw-list-item"><a href="https://it.wikipedia.org/wiki/Modello_linguistico_di_grandi_dimensioni" title="Modello linguistico di grandi dimensioni – Italian" lang="it" hreflang="it" class="interlanguage-link-target"><span>Italiano</span></a></li><li class="interlanguage-link interwiki-he mw-list-item"><a href="https://he.wikipedia.org/wiki/%D7%9E%D7%95%D7%93%D7%9C_%D7%A9%D7%A4%D7%94_%D7%92%D7%93%D7%95%D7%9C" title="מודל שפה גדול – Hebrew" lang="he" hreflang="he" class="interlanguage-link-target"><span>עברית</span></a></li><li class="interlanguage-link interwiki-mk mw-list-item"><a href="https://mk.wikipedia.org/wiki/%D0%93%D0%BE%D0%BB%D0%B5%D0%BC_%D1%98%D0%B0%D0%B7%D0%B8%D1%87%D0%B5%D0%BD_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB" title="Голем јазичен модел – Macedonian" lang="mk" hreflang="mk" class="interlanguage-link-target"><span>Македонски</span></a></li><li class="interlanguage-link interwiki-nl mw-list-item"><a href="https://nl.wikipedia.org/wiki/Groot_taalmodel" title="Groot taalmodel – Dutch" lang="nl" hreflang="nl" class="interlanguage-link-target"><span>Nederlands</span></a></li><li class="interlanguage-link interwiki-ja mw-list-item"><a href="https://ja.wikipedia.org/wiki/%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB" title="大規模言語モデル – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target"><span>日本語</span></a></li><li class="interlanguage-link interwiki-pt mw-list-item"><a href="https://pt.wikipedia.org/wiki/Grandes_modelos_de_linguagem" title="Grandes modelos de linguagem – Portuguese" lang="pt" hreflang="pt" class="interlanguage-link-target"><span>Português</span></a></li><li class="interlanguage-link interwiki-qu mw-list-item"><a href="https://qu.wikipedia.org/wiki/Hatun_simi_wallpama" title="Hatun simi wallpama – Quechua" lang="qu" hreflang="qu" class="interlanguage-link-target"><span>Runa Simi</span></a></li><li class="interlanguage-link interwiki-ru mw-list-item"><a href="https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%B0%D1%8F_%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C" title="Большая языковая модель – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target"><span>Русский</span></a></li><li class="interlanguage-link interwiki-sl mw-list-item"><a href="https://sl.wikipedia.org/wiki/Obse%C5%BEni_jezikovni_model" title="Obsežni jezikovni model – Slovenian" lang="sl" hreflang="sl" class="interlanguage-link-target"><span>Slovenščina</span></a></li><li class="interlanguage-link interwiki-sr mw-list-item"><a href="https://sr.wikipedia.org/wiki/Veliki_jezi%C4%8Dki_modeli" title="Veliki jezički modeli – Serbian" lang="sr" hreflang="sr" class="interlanguage-link-target"><span>Српски / srpski</span></a></li><li class="interlanguage-link interwiki-tl mw-list-item"><a href="https://tl.wikipedia.org/wiki/Malaking_modelong_pangwika" title="Malaking modelong pangwika – Tagalog" lang="tl" hreflang="tl" class="interlanguage-link-target"><span>Tagalog</span></a></li><li class="interlanguage-link interwiki-tr mw-list-item"><a href="https://tr.wikipedia.org/wiki/Geni%C5%9F_dil_modeli" title="Geniş dil modeli – Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target"><span>Türkçe</span></a></li><li class="interlanguage-link interwiki-uk mw-list-item"><a href="https://uk.wikipedia.org/wiki/%D0%92%D0%B5%D0%BB%D0%B8%D0%BA%D0%B0_%D0%BC%D0%BE%D0%B2%D0%BD%D0%B0_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C" title="Велика мовна модель – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target"><span>Українська</span></a></li><li class="interlanguage-link interwiki-ug mw-list-item"><a href="https://ug.wikipedia.org/wiki/%DA%86%D9%88%DA%AD_%D8%AA%D9%89%D9%84_%D9%85%D9%88%D8%AF%D9%89%D9%84%D9%89" title="چوڭ تىل مودىلى – Uyghur" lang="ug" hreflang="ug" class="interlanguage-link-target"><span>ئۇيغۇرچە / Uyghurche</span></a></li><li class="interlanguage-link interwiki-vi mw-list-item"><a href="https://vi.wikipedia.org/wiki/M%C3%B4_h%C3%ACnh_ng%C3%B4n_ng%E1%BB%AF_l%E1%BB%9Bn" title="Mô hình ngôn ngữ lớn – Vietnamese" lang="vi" hreflang="vi" class="interlanguage-link-target"><span>Tiếng Việt</span></a></li><li class="interlanguage-link interwiki-zh-yue mw-list-item"><a href="https://zh-yue.wikipedia.org/wiki/%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B" title="大型語言模型 – Cantonese" lang="yue" hreflang="yue" class="interlanguage-link-target"><span>粵語</span></a></li><li class="interlanguage-link interwiki-zh mw-list-item"><a href="https://zh.wikipedia.org/wiki/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B" title="大型语言模型 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target"><span>中文</span></a></li>
			</ul>
			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q115305900#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
		</div>

	</div>
</div>
</header>
				<div class="vector-page-toolbar">
					<div class="vector-page-toolbar-container">
						<div id="left-navigation">
							<nav aria-label="Namespaces">
								
<div id="p-associated-pages" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-nstab-main" class="selected vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/wiki/Large_language_model" title="View the content page [Alt+Shift+c]" accesskey="c"><span>Article</span></a></li><li id="ca-talk" class="vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/wiki/Talk:Large_language_model" rel="discussion" title="Discuss improvements to the content page [Alt+Shift+t]" accesskey="t"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

								
<div id="p-variants" class="vector-dropdown emptyPortlet">
	<input type="checkbox" id="p-variants-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-variants" class="vector-dropdown-checkbox " aria-label="Change language variant">
	<label id="p-variants-label" for="p-variants-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"><span class="vector-dropdown-label-text">English</span>
	</label>
	<div class="vector-dropdown-content">


					
<div id="p-variants" class="vector-menu mw-portlet mw-portlet-variants emptyPortlet">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

				
	</div>
</div>

							</nav>
						</div>
						<div id="right-navigation" class="vector-collapsible">
							<nav aria-label="Views">
								
<div id="p-views" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-views">
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-view" class="selected vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/wiki/Large_language_model"><span>Read</span></a></li><li id="ca-edit" class="vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit" title="Edit this page [Alt+Shift+e]" accesskey="e"><span>Edit</span></a></li><li id="ca-history" class="vector-tab-noicon mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=history" title="Past revisions of this page [Alt+Shift+h]" accesskey="h"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

							</nav>
				
							<nav class="vector-page-tools-landmark" aria-label="Page tools">
								
<div id="vector-page-tools-dropdown" class="vector-dropdown vector-page-tools-dropdown">
	<input type="checkbox" id="vector-page-tools-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-tools-dropdown" class="vector-dropdown-checkbox " aria-label="Tools">
	<label id="vector-page-tools-dropdown-label" for="vector-page-tools-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"><span class="vector-dropdown-label-text">Tools</span>
	</label>
	<div class="vector-dropdown-content">


									<div id="vector-page-tools-unpinned-container" class="vector-unpinned-container">
						
<div id="vector-page-tools" class="vector-page-tools vector-pinnable-element">
	<div class="vector-pinnable-header vector-page-tools-pinnable-header vector-pinnable-header-unpinned" data-feature-name="page-tools-pinned" data-pinnable-element-id="vector-page-tools" data-pinned-container-id="vector-page-tools-pinned-container" data-unpinned-container-id="vector-page-tools-unpinned-container" data-saved-pinned-state="false">
	<div class="vector-pinnable-header-label">Tools</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-page-tools.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-page-tools.unpin">hide</button>
</div>

	
<div id="p-cactions" class="vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-has-collapsible-items" title="More options">
	<div class="vector-menu-heading">
		Actions
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-more-view" class="selected vector-more-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/wiki/Large_language_model"><span>Read</span></a></li><li id="ca-more-edit" class="vector-more-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit" title="Edit this page [Alt+Shift+e]" accesskey="e"><span>Edit</span></a></li><li id="ca-more-history" class="vector-more-collapsible-item mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=history"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-tb" class="vector-menu mw-portlet mw-portlet-tb">
	<div class="vector-menu-heading">
		General
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-whatlinkshere" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:WhatLinksHere/Large_language_model" title="List of all English Wikipedia pages containing links to this page [Alt+Shift+j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Large_language_model" rel="nofollow" title="Recent changes in pages linked from this page [Alt+Shift+k]" accesskey="k"><span>Related changes</span></a></li><li id="t-upload" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [Alt+Shift+u]" accesskey="u"><span>Upload file</span></a></li><li id="t-specialpages" class="mw-list-item"><a href="https://en.wikipedia.org/wiki/Special:SpecialPages" title="A list of all special pages [Alt+Shift+q]" accesskey="q"><span>Special pages</span></a></li><li id="t-permalink" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;oldid=1222500509" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=info" title="More information about this page"><span>Page information</span></a></li><li id="t-cite" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&amp;page=Large_language_model&amp;id=1222500509&amp;wpFormIdentifier=titleform" title="Information on how to cite this page"><span>Cite this page</span></a></li><li id="t-urlshortener" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:UrlShortener&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FLarge_language_model" aria-haspopup="dialog"><span>Get shortened URL</span></a></li><li id="t-urlshortener-qrcode" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:QrCode&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FLarge_language_model"><span>Download QR code</span></a></li><li id="t-wikibase" class="mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q115305900" title="Structured data on this page hosted by Wikidata [Alt+Shift+g]" accesskey="g"><span>Wikidata item</span></a></li>
		<li class="mw-list-item mw-list-item-js" id="t-collapsible-toggle-all"><a href="#" title="Expand all collapsible elements on the current page" role="button" aria-expanded="false"><span>Expand all</span></a></li><li class="mw-list-item mw-list-item-js" id="wbc-editpage"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q115305900#sitelinks-wikipedia" title="Edit interlanguage links"><span>Edit interlanguage links</span></a></li></ul>
		
	</div>
</div>

<div id="p-coll-print_export" class="vector-menu mw-portlet mw-portlet-coll-print_export">
	<div class="vector-menu-heading">
		Print/export
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="coll-download-as-rl" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Special:DownloadAsPdf&amp;page=Large_language_model&amp;action=show-download-screen" title="Download this page as a PDF file"><span>Download as PDF</span></a></li><li id="t-print" class="mw-list-item"><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;printable=yes" title="Printable version of this page [Alt+Shift+p]" accesskey="p"><span>Printable version</span></a></li>
		</ul>
		
	</div>
</div>

</div>

									</div>
				
	</div>
</div>

							</nav>
						</div>
					</div>
				</div>
				<div class="vector-column-end">
					<div class="vector-sticky-pinned-container">
						<nav class="vector-page-tools-landmark" aria-label="Page tools">
							<div id="vector-page-tools-pinned-container" class="vector-pinned-container">
				
							</div>
		</nav>
						<nav class="vector-appearance-landmark" aria-label="Appearance">
						</nav>
					</div>
				</div>
				<div id="bodyContent" class="vector-body ve-init-mw-desktopArticleTarget-targetContainer" aria-labelledby="firstHeading" data-mw-ve-target-container="">
					<div class="vector-body-before-content">
							<div class="mw-indicators">
		</div>

						<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
					</div>
					<div id="contentSub"><div id="mw-content-subtitle"></div></div>
					
					
					<div id="mw-content-text" class="mw-body-content"><div class="mw-content-ltr mw-parser-output" lang="en" dir="ltr"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Type of artificial neural network</div>
<style data-mw-deduplicate="TemplateStyles:r1129693374">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:" · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}</style><style class="darkreader darkreader--sync" media="screen"></style><style data-mw-deduplicate="TemplateStyles:r1045330069">.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}</style><style class="darkreader darkreader--sync" media="screen"></style><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><style class="darkreader darkreader--sync" media="screen"></style><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886047488"><table class="sidebar sidebar-collapse nomobile nowraplinks"><tbody><tr><td class="sidebar-pretitle">Part of a series on</td></tr><tr><th class="sidebar-title-with-pretitle"><a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">Machine learning</a><br>and <a href="https://en.wikipedia.org/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Paradigms</div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Batch_learning" class="mw-redirect" title="Batch learning">Batch learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Meta-learning_(computer_science)" title="Meta-learning (computer science)">Meta-learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semi-supervised_learning" class="mw-redirect" title="Semi-supervised learning">Semi-supervised learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Self-supervised_learning" title="Self-supervised learning">Self-supervised learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Curriculum_learning" title="Curriculum learning">Curriculum learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Rule-based_machine_learning" title="Rule-based machine learning">Rule-based learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Quantum_machine_learning" title="Quantum machine learning">Quantum machine learning</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Problems</div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="https://en.wikipedia.org/wiki/Generative_model" title="Generative model">Generative modeling</a></li>
<li><a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="https://en.wikipedia.org/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Density_estimation" title="Density estimation">Density estimation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Data_cleaning" class="mw-redirect" title="Data cleaning">Data cleaning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="https://en.wikipedia.org/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semantic_analysis_(machine_learning)" title="Semantic analysis (machine learning)">Semantic analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="https://en.wikipedia.org/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="https://en.wikipedia.org/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ontology_learning" title="Ontology learning">Ontology learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Multimodal_learning" title="Multimodal learning">Multimodal learning</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage=""><div style="display: inline-block; line-height: 1.2em; padding: .1em 0;"><a href="https://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br><span class="nobold"><span style="font-size:85%;">(<b><a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&nbsp;• <b><a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Apprenticeship_learning" title="Apprenticeship learning">Apprenticeship learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="https://en.wikipedia.org/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="https://en.wikipedia.org/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="https://en.wikipedia.org/wiki/Artificial_neural_network" class="mw-redirect" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="https://en.wikipedia.org/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="https://en.wikipedia.org/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="https://en.wikipedia.org/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support vector machine">Support vector machine (SVM)</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage=""><a href="https://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a href="https://en.wikipedia.org/wiki/CURE_algorithm" title="CURE algorithm">CURE</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="https://en.wikipedia.org/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a href="https://en.wikipedia.org/wiki/Fuzzy_clustering" title="Fuzzy clustering">Fuzzy</a></li>
<li><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">Expectation–maximization (EM)</a></li>
<li><br><a href="https://en.wikipedia.org/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="https://en.wikipedia.org/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a href="https://en.wikipedia.org/wiki/Mean_shift" title="Mean shift">Mean shift</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage=""><a href="https://en.wikipedia.org/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="https://en.wikipedia.org/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>
<li><a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sparse_dictionary_learning" title="Sparse dictionary learning">SDL</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage=""><a href="https://en.wikipedia.org/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="https://en.wikipedia.org/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage=""><a href="https://en.wikipedia.org/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Random_sample_consensus" title="Random sample consensus">RANSAC</a></li>
<li><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="https://en.wikipedia.org/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li>
<li><a href="https://en.wikipedia.org/wiki/Isolation_forest" title="Isolation forest">Isolation forest</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default" aria-expanded="true" tabindex="0"><span class="mw-collapsible-text">hide</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage=""><a href="https://en.wikipedia.org/wiki/Artificial_neural_network" class="mw-redirect" title="Artificial neural network">Artificial neural network</a></div><div class="sidebar-list-content mw-collapsible-content hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cognitive_computing" title="Cognitive computing">Cognitive computing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="https://en.wikipedia.org/wiki/Feedforward_neural_network" title="Feedforward neural network">Feedforward neural network</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_Network" title="Kolmogorov–Arnold Network">Kolmogorov–Arnold Network</a></li>
<li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" title="Recurrent neural network">Recurrent neural network</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li>
<li><a href="https://en.wikipedia.org/wiki/Echo_state_network" title="Echo state network">ESN</a></li>
<li><a href="https://en.wikipedia.org/wiki/Reservoir_computing" title="Reservoir computing">reservoir computing</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a href="https://en.wikipedia.org/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>
<li><a href="https://en.wikipedia.org/wiki/Diffusion_model" title="Diffusion model">Diffusion model</a></li>
<li><a href="https://en.wikipedia.org/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="https://en.wikipedia.org/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" class="mw-redirect" title="Transformer (machine learning model)">Transformer</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Vision_transformer" title="Vision transformer">Vision</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Mamba_(deep_learning_architecture)" title="Mamba (deep learning architecture)">Mamba</a></li>
<li><a href="https://en.wikipedia.org/wiki/Spiking_neural_network" title="Spiking neural network">Spiking neural network</a></li>
<li><a href="https://en.wikipedia.org/wiki/Memtransistor" title="Memtransistor">Memtransistor</a></li>
<li><a href="https://en.wikipedia.org/wiki/Electrochemical_RAM" title="Electrochemical RAM">Electrochemical RAM</a> (ECRAM)</li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage=""><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning" title="Multi-agent reinforcement learning">Multi-agent</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Self-play_(reinforcement_learning_technique)" class="mw-redirect" title="Self-play (reinforcement learning technique)">Self-play</a></li></ul></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Learning with humans</div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)" title="Active learning (machine learning)">Active learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Crowdsourcing" title="Crowdsourcing">Crowdsourcing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Human-in-the-loop" title="Human-in-the-loop">Human-in-the-loop</a></li>
<li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" title="Reinforcement learning from human feedback">RLHF</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Model diagnostics</div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Coefficient_of_determination" title="Coefficient of determination">Coefficient of determination</a></li>
<li><a href="https://en.wikipedia.org/wiki/Confusion_matrix" title="Confusion matrix">Confusion matrix</a></li>
<li><a href="https://en.wikipedia.org/wiki/Learning_curve_(machine_learning)" title="Learning curve (machine learning)">Learning curve</a></li>
<li><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" title="Receiver operating characteristic">ROC curve</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Mathematical foundations</div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Kernel_machines" class="mw-redirect" title="Kernel machines">Kernel machines</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" title="Bias–variance tradeoff">Bias–variance tradeoff</a></li>
<li><a href="https://en.wikipedia.org/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="https://en.wikipedia.org/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="https://en.wikipedia.org/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Machine-learning venues</div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/ECML_PKDD" title="ECML PKDD">ECML PKDD</a></li>
<li><a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>
<li><a href="https://en.wikipedia.org/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations" title="International Conference on Learning Representations">ICLR</a></li>
<li><a href="https://en.wikipedia.org/wiki/International_Joint_Conference_on_Artificial_Intelligence" title="International Joint Conference on Artificial Intelligence">IJCAI</a></li>
<li><a href="https://en.wikipedia.org/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="https://en.wikipedia.org/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-content">
<div class="sidebar-list mw-collapsible mw-collapsed mw-made-collapsible"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><div class="sidebar-list-title" style="border-top: 1px solid rgb(170, 170, 170); text-align: center; background: rgb(221, 221, 221); --darkreader-inline-border-top: #484e51; --darkreader-inline-bgcolor: #2b2f31; --darkreader-inline-bgimage: none;" data-darkreader-inline-border-top="" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Related articles</div><div class="sidebar-list-content mw-collapsible-content hlist" style="display: none;">
<ul><li><a href="https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a>
<ul><li><a href="https://en.wikipedia.org/wiki/List_of_datasets_in_computer_vision_and_image_processing" title="List of datasets in computer vision and image processing">List of datasets in computer vision and image processing</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul></div></div></td>
</tr><tr><td class="sidebar-navbar"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><style data-mw-deduplicate="TemplateStyles:r1063604349">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}</style><style class="darkreader darkreader--sync" media="screen"></style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="https://en.wikipedia.org/wiki/Template:Machine_learning" title="Template:Machine learning"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="https://en.wikipedia.org/wiki/Template_talk:Machine_learning" title="Template talk:Machine learning"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a href="https://en.wikipedia.org/wiki/Special:EditPage/Template:Machine_learning" title="Special:EditPage/Template:Machine learning"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p>A <b>large language model</b> (<b>LLM</b>) is a computational <a href="https://en.wikipedia.org/wiki/Model#Conceptual_model" title="Model">model</a> notable for its ability to achieve general-purpose language generation and other <a href="https://en.wikipedia.org/wiki/Natural_language_processing" title="Natural language processing">natural language processing</a> tasks such as <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">classification</a>. Based on <a href="https://en.wikipedia.org/wiki/Language_model" title="Language model">language models</a>, LLMs acquire these abilities by learning statistical relationships from text documents during a computationally intensive <a href="https://en.wikipedia.org/wiki/Self-supervised_learning" title="Self-supervised learning">self-supervised</a> and <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning" class="mw-redirect" title="Semi-supervised learning">semi-supervised</a> training process.<sup id="cite_ref-:7_1-0" class="reference"><a href="#cite_note-:7-1">[1]</a></sup> LLMs can be used for text generation, a form of <a href="https://en.wikipedia.org/wiki/Generative_artificial_intelligence" title="Generative artificial intelligence">generative AI</a>, by taking an input text and repeatedly predicting the next token or word.<sup id="cite_ref-Bowman_2-0" class="reference"><a href="#cite_note-Bowman-2">[2]</a></sup>
</p><p>LLMs are <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" class="mw-redirect" title="Artificial neural network">artificial neural networks</a>. The largest and most capable, as of March&nbsp;2024<sup class="plainlinks noexcerpt noprint asof-tag update" style="display:none;"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit">[update]</a></sup>, are built with a decoder-only <a href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)" title="Transformer (deep learning architecture)">transformer</a>-based architecture while some recent implementations are based on other architectures, such as <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" title="Recurrent neural network">recurrent neural network</a> variants and <a href="https://en.wikipedia.org/wiki/Mamba_(deep_learning_architecture)" title="Mamba (deep learning architecture)">Mamba</a> (a <a href="https://en.wikipedia.org/wiki/State-space_representation" title="State-space representation">state space</a> model).<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">[3]</a></sup><sup id="cite_ref-4" class="reference"><a href="#cite_note-4">[4]</a></sup><sup id="cite_ref-5" class="reference"><a href="#cite_note-5">[5]</a></sup>
</p><p>Up to 2020, <a href="https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)" title="Fine-tuning (deep learning)">fine tuning</a> was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as <a href="https://en.wikipedia.org/wiki/GPT-3" title="GPT-3">GPT-3</a>, however, can be <a href="https://en.wikipedia.org/wiki/Prompt_engineering" title="Prompt engineering">prompt-engineered</a> to achieve similar results.<sup id="cite_ref-few-shot-learners_6-0" class="reference"><a href="#cite_note-few-shot-learners-6">[6]</a></sup>
 They are thought to acquire knowledge about syntax, semantics and 
"ontology" inherent in human language corpora, but also inaccuracies and
 <a href="https://en.wikipedia.org/wiki/Algorithmic_bias" title="Algorithmic bias">biases</a> present in the corpora.<sup id="cite_ref-Manning-2022_7-0" class="reference"><a href="#cite_note-Manning-2022-7">[7]</a></sup>
</p><p>Some notable LLMs are <a href="https://en.wikipedia.org/wiki/OpenAI" title="OpenAI">OpenAI</a>'s <a href="https://en.wikipedia.org/wiki/Generative_pre-trained_transformer" title="Generative pre-trained transformer">GPT</a> series of models (e.g., <a href="https://en.wikipedia.org/wiki/GPT-3.5" class="mw-redirect" title="GPT-3.5">GPT-3.5</a> and <a href="https://en.wikipedia.org/wiki/GPT-4" title="GPT-4">GPT-4</a>, used in <a href="https://en.wikipedia.org/wiki/ChatGPT" title="ChatGPT">ChatGPT</a> and <a href="https://en.wikipedia.org/wiki/Microsoft_Copilot" title="Microsoft Copilot">Microsoft Copilot</a>), <a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a>'s <a href="https://en.wikipedia.org/wiki/PaLM" title="PaLM">PaLM</a> and <a href="https://en.wikipedia.org/wiki/Gemini_(language_model)" title="Gemini (language model)">Gemini</a> (the latter of which is currently used in <a href="https://en.wikipedia.org/wiki/Gemini_(chatbot)" title="Gemini (chatbot)">the chatbot of the same name</a>), <a href="https://en.wikipedia.org/wiki/XAI_(company)" title="XAI (company)">xAI</a>'s <a href="https://en.wikipedia.org/wiki/Grok_(chatbot)" title="Grok (chatbot)">Grok</a>, <a href="https://en.wikipedia.org/wiki/Meta_Platforms" title="Meta Platforms">Meta</a>'s <a href="https://en.wikipedia.org/wiki/LLaMA" title="LLaMA">LLaMA</a> family of models, <a href="https://en.wikipedia.org/wiki/Anthropic" title="Anthropic">Anthropic</a>'s <a href="https://en.wikipedia.org/wiki/Claude_(language_model)" title="Claude (language model)">Claude</a> models, <a href="https://en.wikipedia.org/wiki/Mistral_AI" title="Mistral AI">Mistral AI</a>'s models, and <a href="https://en.wikipedia.org/wiki/Databricks" title="Databricks">Databricks</a>' <a href="https://en.wikipedia.org/wiki/DBRX" title="DBRX">DBRX</a>.
</p>
<meta property="mw:PageProp/toc">
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=1" title="Edit section: History"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:The-Transformer-model-architecture.png" class="mw-file-description"><img src="Large%20language%20model%20-%20Wikipedia_files/The-Transformer-model-architecture_003.png" decoding="async" width="290" height="261" class="mw-file-element" srcset="Large%20language%20model%20-%20Wikipedia_files/The-Transformer-model-architecture_002.png 1.5x, Large%20language%20model%20-%20Wikipedia_files/The-Transformer-model-architecture.png 2x" data-file-width="850" data-file-height="765"></a><figcaption>An
 illustration of main components of the transformer model from the 
original paper, where layers were normalized after (instead of before) 
multiheaded attention</figcaption></figure>
<p>At the 2017 <a href="https://en.wikipedia.org/wiki/NeurIPS" class="mw-redirect" title="NeurIPS">NeurIPS</a> conference, Google researchers introduced the <a href="https://en.wikipedia.org/wiki/Transformer_architecture" class="mw-redirect" title="Transformer architecture">transformer architecture</a> in their landmark paper "<a href="https://en.wikipedia.org/wiki/Attention_Is_All_You_Need" title="Attention Is All You Need">Attention Is All You Need</a>". This paper's goal was to improve upon 2014 <a href="https://en.wikipedia.org/wiki/Seq2seq" title="Seq2seq">Seq2seq</a> technology, <sup id="cite_ref-8" class="reference"><a href="#cite_note-8">[8]</a></sup> and was based mainly on the <a href="https://en.wikipedia.org/wiki/Attention_(machine_learning)" title="Attention (machine learning)">attention</a> mechanism developed by Bahdanau et al. in 2014.<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">[9]</a></sup> The following year in 2018, <a href="https://en.wikipedia.org/wiki/BERT_(language_model)" title="BERT (language model)">BERT</a> was introduced and quickly became "ubiquitous".<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">[10]</a></sup> Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model.
</p><p>Although decoder-only <a href="https://en.wikipedia.org/wiki/GPT-1" title="GPT-1">GPT-1</a> was introduced in 2018, it was <a href="https://en.wikipedia.org/wiki/GPT-2" title="GPT-2">GPT-2</a> in 2019 that caught widespread attention because <a href="https://en.wikipedia.org/wiki/OpenAI" title="OpenAI">OpenAI</a> at first deemed it too powerful to release publicly, out of fear of malicious use.<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">[11]</a></sup> <a href="https://en.wikipedia.org/wiki/GPT-3" title="GPT-3">GPT-3</a> in 2020 went a step further and as of 2024<sup class="plainlinks noexcerpt noprint asof-tag update" style="display:none;"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit">[update]</a></sup> is available only via <a href="https://en.wikipedia.org/wiki/Web_API" title="Web API">API</a> with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based <a href="https://en.wikipedia.org/wiki/ChatGPT" title="ChatGPT">ChatGPT</a> that captured the imaginations of the general population and caused some media hype and online buzz.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">[12]</a></sup> The 2023 <a href="https://en.wikipedia.org/wiki/GPT-4" title="GPT-4">GPT-4</a> was praised for its increased accuracy and as a "holy grail" for its <a href="https://en.wikipedia.org/wiki/Multimodal_learning" title="Multimodal learning">multimodal</a> capabilities.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">[13]</a></sup> OpenAI did not reveal high-level architecture and the number of <a href="https://en.wikipedia.org/wiki/Parameter#Artificial_Intelligence" title="Parameter">parameters</a> of GPT-4.
</p><p>In the meantime, competing language models have for the most part
 been playing catch-up to the GPT series, at least in terms of number of
 parameters.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">[14]</a></sup> Notable exceptions in terms of either number of parameters or measured accuracy include Google's 2019 <a href="https://en.wikipedia.org/wiki/T5_(language_model)" title="T5 (language model)">T5-11B</a> and 2022 <a href="https://en.wikipedia.org/wiki/PaLM" title="PaLM">PaLM-E</a>, and <a href="https://en.wikipedia.org/wiki/Anthropic" title="Anthropic">Anthropic</a>'s 2024 <a href="https://en.wikipedia.org/wiki/Claude_(language_model)#Claude_v3" title="Claude (language model)">Claude 3</a>. In terms of <a href="https://en.wikipedia.org/wiki/Elo_rating_system" title="Elo rating system">Elo ratings</a>, on January 26, 2024, Google's Bard (Gemini Pro) surpassed the regular GPT-4, but not the <a href="https://en.wikipedia.org/wiki/Software_release_life_cycle#Beta" title="Software release life cycle">limited-availability</a> GPT-4-Turbo.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">[15]</a></sup>
</p><p>Since 2022, <a href="https://en.wikipedia.org/wiki/Source-available_software" title="Source-available software">source-available</a> models have been gaining popularity, especially at first with <a href="https://en.wikipedia.org/wiki/BLOOM_(language_model)" title="BLOOM (language model)">BLOOM</a> and <a href="https://en.wikipedia.org/wiki/LLaMA" title="LLaMA">LLaMA</a>, though both have restrictions on the field of use. <a href="https://en.wikipedia.org/wiki/Mistral_AI" title="Mistral AI">Mistral AI</a>'s models Mistral 7B and Mixtral 8x7b have the more permissive <a href="https://en.wikipedia.org/wiki/Apache_License" title="Apache License">Apache License</a>. As of January&nbsp;2024<sup class="plainlinks noexcerpt noprint asof-tag update" style="display:none;"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit">[update]</a></sup>,
 Mixtral 8x7b is the most powerful open LLM according to the LMSYS 
Chatbot Arena Leaderboard, being more powerful than GPT-3.5 but not as 
powerful as GPT-4.<sup id="cite_ref-16" class="reference"><a href="#cite_note-16">[16]</a></sup>
</p>
<h2><span class="mw-headline" id="Dataset_preprocessing">Dataset preprocessing</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=2" title="Edit section: Dataset preprocessing"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style><style class="darkreader darkreader--sync" media="screen"></style><div role="note" class="hatnote navigation-not-searchable">See also: <a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Internet" title="List of datasets for machine-learning research">List of datasets for machine-learning research §&nbsp;Internet</a></div>
<h3><span class="mw-headline" id="Probabilistic_tokenization">Probabilistic tokenization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=3" title="Edit section: Probabilistic tokenization"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Because <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">machine learning</a>
 algorithms process numbers rather than text, the text must be converted
 to numbers. In the first step, a vocabulary is decided upon, then 
integer indexes are arbitrarily but uniquely assigned to each vocabulary
 entry, and finally, an <a href="https://en.wikipedia.org/wiki/Word_embedding" title="Word embedding">embedding</a> is associated to the integer index. Algorithms include <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding" title="Byte pair encoding">byte-pair encoding</a> and <a href="https://en.wikipedia.org/wiki/BERT_(language_model)#Design" title="BERT (language model)">WordPiece</a>.
</p><p>Probabilistic tokenization also <a href="https://en.wikipedia.org/wiki/Data_compression" title="Data compression">compresses</a> the datasets. Because LLMs generally require input to be an <a href="https://en.wikipedia.org/wiki/Array_(data_structure)" title="Array (data structure)">array</a> that is not <a href="https://en.wikipedia.org/wiki/Jagged_array" title="Jagged array">jagged</a>,
 the shorter texts must be "padded" until they match the length of the 
longest one. How many tokens are, on average, needed per word depends on
 the language of the dataset.<sup id="cite_ref-17" class="reference"><a href="#cite_note-17">[17]</a></sup><sup id="cite_ref-18" class="reference"><a href="#cite_note-18">[18]</a></sup>
</p>
<h4><span class="mw-headline" id="BPE">BPE</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=4" title="Edit section: BPE"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Using a modification of byte-pair encoding, in the first step, all unique characters (including blanks and <a href="https://en.wikipedia.org/wiki/Punctuation_mark" class="mw-redirect" title="Punctuation mark">punctuation marks</a>) are treated as an initial set of <a href="https://en.wikipedia.org/wiki/N-gram" title="N-gram"><i>n</i>-grams</a>
 (i.e. initial set of uni-grams). Successively the most frequent pair of
 adjacent characters is merged into a bi-gram and all instances of the 
pair are replaced by it. All occurrences of adjacent pairs of 
(previously merged) <i>n</i>-grams that most frequently occur together are then again merged into even lengthier <i>n</i>-gram repeatedly until a vocabulary of prescribed size is obtained (in case of <a href="https://en.wikipedia.org/wiki/GPT-3" title="GPT-3">GPT-3</a>, the size is 50257).<sup id="cite_ref-xbiWb_19-0" class="reference"><a href="#cite_note-xbiWb-19">[19]</a></sup> Token vocabulary consists of <a href="https://en.wikipedia.org/wiki/Integers" class="mw-redirect" title="Integers">integers</a>,
 spanning from zero up to the size of the token vocabulary. New words 
can always be interpreted as combinations of the tokens and the 
initial-set uni-grams.<sup id="cite_ref-2022Book_20-0" class="reference"><a href="#cite_note-2022Book_-20">[20]</a></sup>
</p><p>A token vocabulary based on the frequencies extracted from mainly
 English corpora uses as few tokens as possible for an average English 
word. An average word in another language encoded by such an 
English-optimized tokenizer is however split into suboptimal amount of 
tokens. GPT-2 tokenizer can use up to 15 times more tokens per word for 
some languages, for example for <a href="https://en.wikipedia.org/wiki/Shan_language" title="Shan language">Shan language</a> from <a href="https://en.wikipedia.org/wiki/Myanmar" title="Myanmar">Myanmar</a>. Even more widespread languages such as Portuguese and German have "a premium of 50%" compared to English.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">[21]</a></sup>
</p><p>For example, here is how tokenizer used by GPT-3 (Legacy) split the following sentence <small><code>tokenizer: texts -&gt; series of numerical "tokens"</code></small>.
</p>
<table cellpadding="0;" cellspacing="0;" style="border: 1px solid black; --darkreader-inline-border-top: #8c8273; --darkreader-inline-border-right: #8c8273; --darkreader-inline-border-bottom: #8c8273; --darkreader-inline-border-left: #8c8273;" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left="">

<tbody><tr>
<td style="border-left: 2px green; border-right: 2px green; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">token
</td>
<td style="background-color: grey; color: white; border-left: 2px green; border-right: 2px green; --darkreader-inline-bgcolor: #60686c; --darkreader-inline-color: #e8e6e3; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-bgcolor="" data-darkreader-inline-color="" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">izer
</td>
<td style="border-left: 2px green; border-right: 2px green; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">:
</td>
<td style="background-color: grey; color: white; border-left: 2px green; border-right: 2px green; --darkreader-inline-bgcolor: #60686c; --darkreader-inline-color: #e8e6e3; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-bgcolor="" data-darkreader-inline-color="" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">&nbsp;texts
</td>
<td style="border-left: 2px green; border-right: 2px green; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">&nbsp;-&gt;
</td>
<td style="background-color: grey; color: white; border-left: 2px green; border-right: 2px green; --darkreader-inline-bgcolor: #60686c; --darkreader-inline-color: #e8e6e3; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-bgcolor="" data-darkreader-inline-color="" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">series
</td>
<td style="border-left: 2px green; border-right: 2px green; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">&nbsp;of
</td>
<td style="background-color: grey; color: white; border-left: 2px green; border-right: 2px green; --darkreader-inline-bgcolor: #60686c; --darkreader-inline-color: #e8e6e3; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-bgcolor="" data-darkreader-inline-color="" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">&nbsp;numerical
</td>
<td style="border-left: 2px green; border-right: 2px green; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">&nbsp;"
</td>
<td style="background-color: grey; color: white; border-left: 2px green; border-right: 2px green; --darkreader-inline-bgcolor: #60686c; --darkreader-inline-color: #e8e6e3; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-bgcolor="" data-darkreader-inline-color="" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">t
</td>
<td style="border-left: 2px green; border-right: 2px green; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">ok
</td>
<td style="background-color: grey; color: white; border-left: 2px green; border-right: 2px green; --darkreader-inline-bgcolor: #60686c; --darkreader-inline-color: #e8e6e3; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-bgcolor="" data-darkreader-inline-color="" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">ens
</td>
<td style="border-left: 2px green; border-right: 2px green; --darkreader-inline-border-left: #00d900; --darkreader-inline-border-right: #00d900;" data-darkreader-inline-border-left="" data-darkreader-inline-border-right="">"
</td></tr></tbody></table>
<h3><span class="mw-headline" id="Dataset_cleaning">Dataset cleaning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=5" title="Edit section: Dataset cleaning"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Data_cleansing" title="Data cleansing">Data cleansing</a></div>
<p>In the context of training LLMs, datasets are typically cleaned by 
removing toxic passages from the dataset, discarding low-quality data, 
and de-duplication.<sup id="cite_ref-aYNg4_22-0" class="reference"><a href="#cite_note-aYNg4-22">[22]</a></sup> Cleaned datasets can increase training efficiency and lead to improved downstream performance.<sup id="cite_ref-23" class="reference"><a href="#cite_note-23">[23]</a></sup><sup id="cite_ref-24" class="reference"><a href="#cite_note-24">[24]</a></sup> A trained LLM can be used to clean datasets for training a further LLM.<sup id="cite_ref-25" class="reference"><a href="#cite_note-25">[25]</a></sup>
</p><p>With the increasing proportion of LLM-generated content on the 
web, data cleaning in the future may include filtering out such content.
 LLM-generated content can pose a problem if the content is similar to 
human text (making filtering difficult) but of lower quality (degrading 
performance of models trained on it).<sup id="cite_ref-qbFw1_26-0" class="reference"><a href="#cite_note-qbFw1-26">[26]</a></sup>
</p>
<h3><span class="mw-headline" id="Synthetic_data">Synthetic data</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=6" title="Edit section: Synthetic data"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Synthetic_data" title="Synthetic data">Synthetic data</a></div>
<p>Training of largest language models might need more linguistic data 
than naturally available, or that the naturally occurring data is of 
insufficient quality. In these cases, synthetic data might be used. The 
Microsoft's Phi series of LLMs is trained on textbook-like data 
generated by another LLM.<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">[27]</a></sup>
</p>
<h2><span class="mw-headline" id="Training_and_architecture">Training and architecture</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=7" title="Edit section: Training and architecture"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="https://en.wikipedia.org/wiki/Fine-tuning_(machine_learning)" class="mw-redirect" title="Fine-tuning (machine learning)">Fine-tuning (machine learning)</a></div>
<h3><span id="Reinforcement_learning_from_human_feedback_.28RLHF.29"></span><span class="mw-headline" id="Reinforcement_learning_from_human_feedback_(RLHF)">Reinforcement learning from human feedback (RLHF)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=8" title="Edit section: Reinforcement learning from human feedback (RLHF)"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback" title="Reinforcement learning from human feedback">Reinforcement learning from human feedback</a> (RLHF) through algorithms, such as <a href="https://en.wikipedia.org/wiki/Proximal_Policy_Optimization" class="mw-redirect" title="Proximal Policy Optimization">proximal policy optimization</a>, is used to further fine-tune a model based on a dataset of human preferences.<sup id="cite_ref-instructGPT-paper_28-0" class="reference"><a href="#cite_note-instructGPT-paper-28">[28]</a></sup>
</p>
<h3><span class="mw-headline" id="Instruction_tuning">Instruction tuning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=9" title="Edit section: Instruction tuning"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Using "self-instruct" approaches, LLMs have been able to <a href="https://en.wikipedia.org/wiki/Bootstrapping" title="Bootstrapping">bootstrap</a>
 correct responses, replacing any naive responses, starting from 
human-generated corrections of a few cases. For example, in the 
instruction "Write an essay about the main themes represented in 
Hamlet," an initial naive completion might be "If you submit the essay 
after March 17, your grade will be reduced by 10% for each day of 
delay," based on the frequency of this textual sequence in the corpus.<sup id="cite_ref-self-instruct-paper_29-0" class="reference"><a href="#cite_note-self-instruct-paper-29">[29]</a></sup>
</p>
<h3><span class="mw-headline" id="Mixture_of_experts">Mixture of experts</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=10" title="Edit section: Mixture of experts"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Mixture_of_experts" title="Mixture of experts">Mixture of experts</a></div>
<p>The largest LLM may be too expensive to train and use directly. For such models, <a href="https://en.wikipedia.org/wiki/Mixture_of_experts" title="Mixture of experts">mixture of experts</a>
 (MoE) can be applied, a line of research pursued by Google researchers 
since 2017 to train models reaching up to 1 trillion parameters.<sup id="cite_ref-HGZCJ_30-0" class="reference"><a href="#cite_note-HGZCJ-30">[30]</a></sup><sup id="cite_ref-R9Qq5_31-0" class="reference"><a href="#cite_note-R9Qq5-31">[31]</a></sup><sup id="cite_ref-glam-blog_32-0" class="reference"><a href="#cite_note-glam-blog-32">[32]</a></sup>
</p>
<h3><span id="Prompt_engineering.2C_attention_mechanism.2C_and_context_window"></span><span class="mw-headline" id="Prompt_engineering,_attention_mechanism,_and_context_window">Prompt engineering, attention mechanism, and context window</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=11" title="Edit section: Prompt engineering, attention mechanism, and context window"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="https://en.wikipedia.org/wiki/Prompt_engineering" title="Prompt engineering">Prompt engineering</a> and <a href="https://en.wikipedia.org/wiki/Attention_(machine_learning)" title="Attention (machine learning)">Attention (machine learning)</a></div>
<p>Most results previously achievable only by (costly) fine-tuning, can be achieved through <a href="https://en.wikipedia.org/wiki/Prompt_engineering" title="Prompt engineering">prompt engineering</a>, although limited to the scope of a single conversation (more precisely, limited to the scope of a context window).<sup id="cite_ref-emergentpaper_33-0" class="reference"><a href="#cite_note-emergentpaper-33">[33]</a></sup>
</p>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Multiple_attention_heads.png" class="mw-file-description"><img src="Large%20language%20model%20-%20Wikipedia_files/Multiple_attention_heads_002.png" decoding="async" width="300" height="441" class="mw-file-element" srcset="Large%20language%20model%20-%20Wikipedia_files/Multiple_attention_heads_003.png 1.5x, Large%20language%20model%20-%20Wikipedia_files/Multiple_attention_heads.png 2x" data-file-width="870" data-file-height="1280"></a><figcaption>When
 each head calculates, according to its own criteria, how much other 
tokens are relevant for the "it_" token, note that the second attention 
head, represented by the second column, is focusing most on the first 
two rows, i.e. the tokens "The" and "animal", while the third column is 
focusing most on the bottom two rows, i.e. on "tired", which has been 
tokenized into two tokens.<sup id="cite_ref-Jay_Allamar_34-0" class="reference"><a href="#cite_note-Jay_Allamar-34">[34]</a></sup></figcaption></figure>
<p>In order to find out which tokens are relevant to each other within 
the scope of the context window, the attention mechanism calculates 
"soft" weights for each token, more precisely for its embedding, by 
using multiple attention heads, each with its own "relevance" for 
calculating its own soft weights. For example, the small (i.e. 117M 
parameter sized) <a href="https://en.wikipedia.org/wiki/GPT-2" title="GPT-2">GPT-2</a> model, has had twelve attention heads and a context window of only 1k token.<sup id="cite_ref-Jay_Allamar_GPT2_35-0" class="reference"><a href="#cite_note-Jay_Allamar_GPT2-35">[35]</a></sup>
 In its medium version it has 345M parameters and contains 24 layers, 
each with 12 attention heads. For the training with gradient descent a 
batch size of 512 was utilized.<sup id="cite_ref-2022Book_20-1" class="reference"><a href="#cite_note-2022Book_-20">[20]</a></sup>
</p><p>The largest models, such as Google's <a href="https://en.wikipedia.org/wiki/Gemini_(language_model)" title="Gemini (language model)">Gemini 1.5</a>,
 presented in February 2024, can have a context window sized up to 1 
million (context window of 10 million was also "successfully tested").<sup id="cite_ref-36" class="reference"><a href="#cite_note-36">[36]</a></sup> Other models with large context windows includes Anthropic's Claude 2.1, with a context window of up to 200k tokens.<sup id="cite_ref-37" class="reference"><a href="#cite_note-37">[37]</a></sup>
 Note that this maximum refers to the number of input tokens and that 
the maximum number of output tokens differs from the input and is often 
smaller. For example, the GPT-4 Turbo model has a maximum output of 4096
 tokens.<sup id="cite_ref-38" class="reference"><a href="#cite_note-38">[38]</a></sup>
</p><p>Length of a conversation that the model can take into account 
when generating its next answer is limited by the size of a context 
window, as well. If the length of a conversation, for example with <a href="https://en.wikipedia.org/wiki/Chat-GPT" class="mw-redirect" title="Chat-GPT">Chat-GPT</a>,
 is longer than its context window, only the parts inside the context 
window are taken into account when generating the next answer, or the 
model needs to apply some algorithm to summarize the too distant parts 
of conversation.
</p><p>The shortcomings of making a context window larger include higher
 computational cost and possibly diluting the focus on local context, 
while making it smaller can cause a model to miss an important 
long-range dependency. Balancing them are a matter of experimentation 
and domain-specific considerations.
</p><p>A model may be pre-trained either to predict how the segment 
continues, or what is missing in the segment, given a segment from its 
training dataset.<sup id="cite_ref-ioUpE_39-0" class="reference"><a href="#cite_note-ioUpE-39">[39]</a></sup> It can be either
</p>
<ul><li>autoregressive (i.e. predicting how the segment continues, the way <a href="https://en.wikipedia.org/wiki/Generative_pretrained_transformer" class="mw-redirect" title="Generative pretrained transformer">GPTs</a> do it): for example given a segment "I like to eat", the model predicts "ice cream", or "sushi".</li>
<li>"<a href="https://en.wikipedia.org/wiki/Cloze_test" title="Cloze test">masked</a>" (i.e. filling in the parts missing from the segment, the way "BERT"<sup id="cite_ref-jm_40-0" class="reference"><a href="#cite_note-jm-40">[40]</a></sup> does it): for example, given a segment "I like to <code>[__] [__]</code> cream", the model predicts that "eat" and "ice" are missing.</li></ul>
<p>Models may be trained on auxiliary tasks which test their 
understanding of the data distribution, such as Next Sentence Prediction
 (NSP), in which pairs of sentences are presented and the model must 
predict whether they appear consecutively in the training corpus.<sup id="cite_ref-jm_40-1" class="reference"><a href="#cite_note-jm-40">[40]</a></sup> During training, <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization</a> loss is also used to stabilize training. However regularization loss is usually not used during <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets" title="Training, validation, and test data sets">testing</a> and evaluation.
</p>
<h2><span class="mw-headline" id="Training_cost">Training cost</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=12" title="Edit section: Training cost"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Advances in software and hardware have reduced the cost substantially
 since 2020, such that in 2023 training of a 12-billion-parameter LLM 
computational cost is 72,300 <a href="https://en.wikipedia.org/wiki/Ampere_(microarchitecture)" title="Ampere (microarchitecture)">A100-GPU</a>-
hours, while in 2020 the cost of training a 1.5-billion-parameter LLM 
(which was two orders of magnitude smaller than the state of the art in 
2020) was between $80 thousand and $1.6 million.<sup id="cite_ref-Wiggers_41-0" class="reference"><a href="#cite_note-Wiggers-41">[41]</a></sup><sup id="cite_ref-xaytj_42-0" class="reference"><a href="#cite_note-xaytj-42">[42]</a></sup><sup id="cite_ref-Pythia_43-0" class="reference"><a href="#cite_note-Pythia-43">[43]</a></sup>
 Since 2020, large sums were invested in increasingly large models. For 
example, training of the GPT-2 (i.e. a 1.5-billion-parameters model) in 
2019 cost $50,000, while training of the PaLM (i.e. a 
540-billion-parameters model) in 2022 cost $8 million, and 
Megatron-Turing NLG 530B (in 2021) cost around $11 million.<sup id="cite_ref-44" class="reference"><a href="#cite_note-44">[44]</a></sup>
</p><p>For Transformer-based LLM, training cost is much higher than inference cost. It costs 6 <a href="https://en.wikipedia.org/wiki/FLOPS" title="FLOPS">FLOPs</a> per parameter to train on one token, whereas it costs 1 to 2 FLOPs per parameter to infer on one token.<sup id="cite_ref-kaplan-scaling_45-0" class="reference"><a href="#cite_note-kaplan-scaling-45">[45]</a></sup>
</p>
<h2><span class="mw-headline" id="Tool_use">Tool use</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=13" title="Edit section: Tool use"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>There are certain tasks that, in principle, cannot be solved by any 
LLM, at least not without the use of external tools or additional 
software. An example of such a task is responding to the user's input 
'354 * 139 = ', provided that the LLM has not already encountered a 
continuation of this calculation in its training corpus. In such cases, 
the LLM needs to resort to running program code that calculates the 
result, which can then be included in its response. Another example is 
'What is the time now? It is ', where a separate program interpreter 
would need to execute a code to get system time on the computer, so LLM 
could include it in its reply.<sup id="cite_ref-PI1fW_46-0" class="reference"><a href="#cite_note-PI1fW-46">[46]</a></sup><sup id="cite_ref-J5OW5_47-0" class="reference"><a href="#cite_note-J5OW5-47">[47]</a></sup> This basic strategy can be sophisticated with multiple attempts of generated programs, and other sampling strategies.<sup id="cite_ref-gQxzq_48-0" class="reference"><a href="#cite_note-gQxzq-48">[48]</a></sup>
Cost Savings and Reduced Vendor Dependency
</p><p>Generally, in order to get an LLM to use tools, one must finetune
 it for tool-use. If the number of tools is finite, then finetuning may 
be done just once. If the number of tools can grow arbitrarily, as with 
online <a href="https://en.wikipedia.org/wiki/API" title="API">API</a> services, then the LLM can be fine-tuned to be able to read API documentation and call API correctly.<sup id="cite_ref-lLrda_49-0" class="reference"><a href="#cite_note-lLrda-49">[49]</a></sup><sup id="cite_ref-4Xzrs_50-0" class="reference"><a href="#cite_note-4Xzrs-50">[50]</a></sup>
</p><p>A simpler form of tool use is <i>Retrieval Augmented Generation</i>: augment an LLM with <a href="https://en.wikipedia.org/wiki/Document_retrieval" title="Document retrieval">document retrieval</a>, sometimes using a <a href="https://en.wikipedia.org/wiki/Vector_database" title="Vector database">vector database</a>.
 Given a query, a document retriever is called to retrieve the most 
relevant (usually measured by first encoding the query and the documents
 into vectors, then finding the documents with vectors closest in 
Euclidean norm to the query vector). The LLM then generates an output 
based on both the query and the retrieved documents.<sup id="cite_ref-BUZBP_51-0" class="reference"><a href="#cite_note-BUZBP-51">[51]</a></sup>
</p>
<h2><span class="mw-headline" id="Agency">Agency</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=14" title="Edit section: Agency"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>An LLM is a language model, which is not an agent as it has no goal, but it can be used as a component of an <a href="https://en.wikipedia.org/wiki/Intelligent_agent" title="Intelligent agent">intelligent agent</a>.<sup id="cite_ref-CFuti_52-0" class="reference"><a href="#cite_note-CFuti-52">[52]</a></sup> Researchers have described several methods for such integrations.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (February 2024)">citation needed</span></a></i>]</sup>
</p><p>The ReAct ("Reason&nbsp;+&nbsp;Act") method constructs an <a href="https://en.wikipedia.org/wiki/Intelligent_agent" title="Intelligent agent">agent</a>
 out of an LLM, using the LLM as a planner. The LLM is prompted to 
"think out loud". Specifically, the language model is prompted with a 
textual description of the environment, a goal, a list of possible 
actions, and a record of the actions and observations so far. It 
generates one or more thoughts before generating an action, which is 
then executed in the environment.<sup id="cite_ref-DmvNE_53-0" class="reference"><a href="#cite_note-DmvNE-53">[53]</a></sup>
 The linguistic description of the environment given to the LLM planner 
can even be the LaTeX code of a paper describing the environment.<sup id="cite_ref-JS8Vd_54-0" class="reference"><a href="#cite_note-JS8Vd-54">[54]</a></sup>
</p><p>In the DEPS ("Describe, Explain, Plan and Select") method, an LLM
 is first connected to the visual world via image descriptions, then it 
is prompted to produce plans for complex tasks and behaviors based on 
its pretrained knowledge and environmental feedback it receives.<sup id="cite_ref-55" class="reference"><a href="#cite_note-55">[55]</a></sup>
</p><p>The Reflexion method<sup id="cite_ref-sbB2T_56-0" class="reference"><a href="#cite_note-sbB2T-56">[56]</a></sup>
 constructs an agent that learns over multiple episodes. At the end of 
each episode, the LLM is given the record of the episode, and prompted 
to think up "lessons learned", which would help it perform better at a 
subsequent episode. These "lessons learned" are given to the agent in 
the subsequent episodes.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (February 2024)">citation needed</span></a></i>]</sup>
</p><p><a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search" title="Monte Carlo tree search">Monte Carlo tree search</a>
 can use an LLM as rollout heuristic. When a programmatic world model is
 not available, an LLM can also be prompted with a description of the 
environment to act as world model.<sup id="cite_ref-ltTer_57-0" class="reference"><a href="#cite_note-ltTer-57">[57]</a></sup>
</p><p>For open-ended exploration, an LLM can be used to score 
observations for their "interestingness", which can be used as a reward 
signal to guide a normal (non-LLM) reinforcement learning agent.<sup id="cite_ref-mBvD9_58-0" class="reference"><a href="#cite_note-mBvD9-58">[58]</a></sup> Alternatively, it can <a href="https://en.wikipedia.org/wiki/Zone_of_proximal_development" title="Zone of proximal development">propose increasingly difficult tasks</a> for <a href="https://en.wikipedia.org/wiki/Curriculum_learning" title="Curriculum learning">curriculum learning</a>.<sup id="cite_ref-:0_59-0" class="reference"><a href="#cite_note-:0-59">[59]</a></sup> Instead of outputting individual actions, an LLM planner can also construct "skills", or <a href="https://en.wikipedia.org/wiki/Function_(computer_programming)" title="Function (computer programming)">functions</a>
 for complex action sequences. The skills can be stored and later 
invoked, allowing increasing levels of abstraction in planning.<sup id="cite_ref-:0_59-1" class="reference"><a href="#cite_note-:0-59">[59]</a></sup>
</p><p>LLM-powered agents can keep a long-term memory of its previous 
contexts, and the memory can be retrieved in the same way as Retrieval 
Augmented Generation. Multiple such agents can interact socially.<sup id="cite_ref-XuvjF_60-0" class="reference"><a href="#cite_note-XuvjF-60">[60]</a></sup>
</p>
<h2><span class="mw-headline" id="Compression">Compression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=15" title="Edit section: Compression"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Typically, LLM are trained with full- or half-precision floating 
point numbers (float32 and float16). One float16 has 16 bits, or 2 
bytes, and so one billion parameters require 2 gigabytes. The largest 
models typically have 100 billion parameters, requiring 200 gigabytes to
 load, which places them outside the range of most consumer electronics.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (February 2024)">citation needed</span></a></i>]</sup>
</p><p><i>Post-training <a href="https://en.wikipedia.org/wiki/Quantization_(signal_processing)" title="Quantization (signal processing)">quantization</a></i><sup id="cite_ref-LS2Go_61-0" class="reference"><a href="#cite_note-LS2Go-61">[61]</a></sup>
 aims to decrease the space requirement by lowering precision of the 
parameters of a trained model, while preserving most of its performance.<sup id="cite_ref-cpzcK_62-0" class="reference"><a href="#cite_note-cpzcK-62">[62]</a></sup><sup id="cite_ref-QVU95_63-0" class="reference"><a href="#cite_note-QVU95-63">[63]</a></sup>
 The simplest form of quantization simply truncates all numbers to a 
given number of bits. It can be improved by using a different 
quantization <a href="https://en.wikipedia.org/wiki/Block_cipher" title="Block cipher">codebook</a> per layer. Further improvement can be done by applying <a href="https://en.wikipedia.org/wiki/Mixed-precision_arithmetic" title="Mixed-precision arithmetic">different precisions</a> to different parameters, with higher precision for particularly important parameters ("outlier weights").<sup id="cite_ref-dU9Bu_64-0" class="reference"><a href="#cite_note-dU9Bu-64">[64]</a></sup>
</p><p>While quantized models are typically frozen, and only 
pre-quantized models are fine-tuned, quantized models can still be 
fine-tuned.<sup id="cite_ref-D0nFA_65-0" class="reference"><a href="#cite_note-D0nFA-65">[65]</a></sup>
</p>
<h2><span class="mw-headline" id="Multimodality">Multimodality</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=16" title="Edit section: Multimodality"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Multimodality means "having several modalities", and a <a href="https://en.wikipedia.org/wiki/Modality_(human%E2%80%93computer_interaction)" title="Modality (human–computer interaction)">"modality"</a> refers to a type of input or output, such as video, image, audio, text, <a href="https://en.wikipedia.org/wiki/Proprioception" title="Proprioception">proprioception</a>, etc.<sup id="cite_ref-66" class="reference"><a href="#cite_note-66">[66]</a></sup> There have been many AI models trained specifically to ingest one modality and output another modality, such as <a href="https://en.wikipedia.org/wiki/AlexNet" title="AlexNet">AlexNet</a> for image to label,<sup id="cite_ref-67" class="reference"><a href="#cite_note-67">[67]</a></sup> <a href="https://en.wikipedia.org/wiki/Visual_question_answering" class="mw-redirect" title="Visual question answering">visual question answering</a> for image-text to text,<sup id="cite_ref-68" class="reference"><a href="#cite_note-68">[68]</a></sup> and <a href="https://en.wikipedia.org/wiki/Speech_recognition" title="Speech recognition">speech recognition</a> for speech to text.
</p><p>A common method to create multimodal models out of an LLM is to 
"tokenize" the output of a trained encoder. Concretely, one can 
construct a LLM that can understand images as follows: take a trained 
LLM, and take a trained image encoder <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle E}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>E</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle E}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/4232c9de2ee3eec0a9c0a19b15ab92daa6223f9b.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.776ex; height:2.176ex;" alt="{\displaystyle E}"></span>. Make a small multilayered perceptron <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/132e57acb643253e7810ee9702d9581f159a1c61.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="{\displaystyle f}"></span>, so that for any image <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/b8a6208ec717213d4317e666f1ae872e00620a0d.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="{\displaystyle y}"></span>, the post-processed vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f(E(y))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>E</mi>
        <mo stretchy="false">(</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f(E(y))}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/8d41d0ec0611a795f65ea14a43b8016462703a8e.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:7.828ex; height:2.843ex;" alt="{\displaystyle f(E(y))}"></span>
 has the same dimensions as an encoded token. That is an "image token". 
Then, one can interleave text tokens and image tokens. The compound 
model is then fine-tuned on an image-text dataset. This basic 
construction can be applied with more sophistication to improve the 
model. The image encoder may be frozen to improve stability.<sup id="cite_ref-69" class="reference"><a href="#cite_note-69">[69]</a></sup>
</p><p>Flamingo demonstrated the effectiveness of the tokenization 
method, finetuning a pair of pretrained language model and image encoder
 to perform better on visual question answering than models trained from
 scratch.<sup id="cite_ref-70" class="reference"><a href="#cite_note-70">[70]</a></sup> <a href="https://en.wikipedia.org/wiki/Pathways_Language_Model" class="mw-redirect" title="Pathways Language Model">Google PaLM</a> model was fine-tuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control.<sup id="cite_ref-71" class="reference"><a href="#cite_note-71">[71]</a></sup> <a href="https://en.wikipedia.org/wiki/LLaMA" title="LLaMA">LLaMA</a> models have also been turned multimodal using the tokenization method, to allow image inputs,<sup id="cite_ref-72" class="reference"><a href="#cite_note-72">[72]</a></sup> and video inputs.<sup id="cite_ref-73" class="reference"><a href="#cite_note-73">[73]</a></sup>
</p><p><a href="https://en.wikipedia.org/wiki/GPT-4" title="GPT-4">GPT-4</a> can use both text and image as inputs<sup id="cite_ref-74" class="reference"><a href="#cite_note-74">[74]</a></sup> (although the vision component wasn't released to the public until GPT-4V<sup id="cite_ref-75" class="reference"><a href="#cite_note-75">[75]</a></sup>); <a href="https://en.wikipedia.org/wiki/Google_DeepMind" title="Google DeepMind">Google DeepMind</a>'s <a href="https://en.wikipedia.org/wiki/Gemini_(language_model)" title="Gemini (language model)">Gemini</a> is also multimodal.<sup id="cite_ref-76" class="reference"><a href="#cite_note-76">[76]</a></sup> 
</p>
<h2><span class="mw-headline" id="Properties">Properties</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=17" title="Edit section: Properties"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Scaling_laws">Scaling laws</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=18" title="Edit section: Scaling laws"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Neural_scaling_law" title="Neural scaling law">Neural scaling law</a></div>
<p>The following four hyper-parameters characterize a LLM:
</p>
<ul><li>cost of (pre-)training (<small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="{\displaystyle C}"></span></small>),</li>
<li>size of the <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" class="mw-redirect" title="Artificial neural network">artificial neural network</a> itself, such as number of parameters <small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle N}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>N</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/f5e3890c981ae85503089652feb48b191b57aae3.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:2.064ex; height:2.176ex;" alt="{\displaystyle N}"></span></small> (i.e. amount of neurons in its layers, amount of weights between them and biases),</li>
<li>size of its (pre-)training dataset (i.e. number of tokens in corpus, <small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle D}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>D</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle D}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/f34a0c600395e5d4345287e21fb26efd386990e6.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.924ex; height:2.176ex;" alt="{\displaystyle D}"></span></small>),</li>
<li>performance after (pre-)training.</li></ul>
<p>They are related by simple <a href="https://en.wikipedia.org/wiki/Empirical_statistical_laws" title="Empirical statistical laws">statistical laws</a>, called "scaling laws". One particular scaling law ("<a href="https://en.wikipedia.org/wiki/Chinchilla_AI" class="mw-redirect" title="Chinchilla AI">Chinchilla scaling</a>") for LLM autoregressively trained for one epoch, with a <a href="https://en.wikipedia.org/wiki/Log-log_plot" class="mw-redirect" title="Log-log plot">log-log</a> <a href="https://en.wikipedia.org/wiki/Learning_rate" title="Learning rate">learning rate</a> schedule, states that:<sup id="cite_ref-fJta3_77-0" class="reference"><a href="#cite_note-fJta3-77">[77]</a></sup>
</p><div class="mwe-math-element"><div class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\begin{cases}C=C_{0}ND\\[6pt]L={\frac {A}{N^{\alpha }}}+{\frac {B}{D^{\beta }}}+L_{0}\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing="0.8em 0.2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mi>C</mi>
                  <mo>=</mo>
                  <msub>
                    <mi>C</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>0</mn>
                    </mrow>
                  </msub>
                  <mi>N</mi>
                  <mi>D</mi>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>L</mi>
                  <mo>=</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mfrac>
                      <mi>A</mi>
                      <msup>
                        <mi>N</mi>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi>α<!-- α --></mi>
                        </mrow>
                      </msup>
                    </mfrac>
                  </mrow>
                  <mo>+</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mfrac>
                      <mi>B</mi>
                      <msup>
                        <mi>D</mi>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi>β<!-- β --></mi>
                        </mrow>
                      </msup>
                    </mfrac>
                  </mrow>
                  <mo>+</mo>
                  <msub>
                    <mi>L</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>0</mn>
                    </mrow>
                  </msub>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}C=C_{0}ND\\[6pt]L={\frac {A}{N^{\alpha }}}+{\frac {B}{D^{\beta }}}+L_{0}\end{cases}}}</annotation>
  </semantics>
</math></div><img src="Large%20language%20model%20-%20Wikipedia_files/39435f4ecd5e00c0714a4f7f71cc0b91f5973cdd.svg" class="mwe-math-fallback-image-display mw-invert" aria-hidden="true" style="vertical-align: -3.505ex; width:22.298ex; height:8.176ex;" alt="{\displaystyle {\begin{cases}C=C_{0}ND\\[6pt]L={\frac {A}{N^{\alpha }}}+{\frac {B}{D^{\beta }}}+L_{0}\end{cases}}}"></div> where the variables are
<p></p>
<ul><li><small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/4fc55753007cd3c18576f7933f6f089196732029.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="{\displaystyle C}"></span></small> is the cost of training the model, in <a href="https://en.wikipedia.org/wiki/FLOPS" title="FLOPS">FLOPs</a>.</li>
<li><small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle N}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>N</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/f5e3890c981ae85503089652feb48b191b57aae3.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:2.064ex; height:2.176ex;" alt="{\displaystyle N}"></span></small> is the number of parameters in the model.</li>
<li><small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle D}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>D</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle D}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/f34a0c600395e5d4345287e21fb26efd386990e6.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.924ex; height:2.176ex;" alt="{\displaystyle D}"></span></small> is the number of tokens in the training set.</li>
<li><small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle L}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>L</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle L}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/103168b86f781fe6e9a4a87b8ea1cebe0ad4ede8.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.583ex; height:2.176ex;" alt="{\displaystyle L}"></span></small> is the average negative log-likelihood loss per token (<a href="https://en.wikipedia.org/wiki/Nat_(unit)" title="Nat (unit)">nats</a>/token), achieved by the trained LLM on the test dataset.</li></ul>
<p>and the statistical hyper-parameters are
</p>
<ul><li><small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle C_{0}=6}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>6</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{0}=6}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/b05c98b1743f05e046a3f3bb0a966fa898e431e2.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:6.977ex; height:2.509ex;" alt="{\displaystyle C_{0}=6}"></span></small>,
 meaning that it costs 6 FLOPs per parameter to train on one token. Note
 that training cost is much higher than inference cost, where it costs 1
 to 2 FLOPs per parameter to infer on one token.<sup id="cite_ref-kaplan-scaling_45-1" class="reference"><a href="#cite_note-kaplan-scaling-45">[45]</a></sup></li>
<li><small><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \alpha =0.34,\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>α<!-- α --></mi>
        <mo>=</mo>
        <mn>0.34</mn>
        <mo>,</mo>
        <mi>β<!-- β --></mi>
        <mo>=</mo>
        <mn>0.28</mn>
        <mo>,</mo>
        <mi>A</mi>
        <mo>=</mo>
        <mn>406.4</mn>
        <mo>,</mo>
        <mi>B</mi>
        <mo>=</mo>
        <mn>410.7</mn>
        <mo>,</mo>
        <msub>
          <mi>L</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>1.69</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \alpha =0.34,\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/848b6d78d881ed6da8d6b60e8d788bc799525401.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:51.588ex; height:2.509ex;" alt="{\displaystyle \alpha =0.34,\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}"></span></small></li></ul>
<h3><span class="mw-headline" id="Emergent_abilities">Emergent abilities</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=19" title="Edit section: Emergent abilities"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p><span class="anchor" id="Emergent_abilities"></span></p><figure class="mw-default-size" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:LLM_emergent_benchmarks.png" class="mw-file-description"><img src="Large%20language%20model%20-%20Wikipedia_files/LLM_emergent_benchmarks.png" decoding="async" width="220" height="146" class="mw-file-element" srcset="Large%20language%20model%20-%20Wikipedia_files/LLM_emergent_benchmarks_003.png 1.5x, Large%20language%20model%20-%20Wikipedia_files/LLM_emergent_benchmarks_002.png 2x" data-file-width="1297" data-file-height="858"></a><figcaption>At point(s) referred to as <a href="https://en.wikipedia.org/wiki/Neural_scaling_law#Broken_Neural_Scaling_Laws_(BNSL)" title="Neural scaling law">breaks</a>,<sup id="cite_ref-IYm4Q_78-0" class="reference"><a href="#cite_note-IYm4Q-78">[78]</a></sup> the lines change their slopes, appearing on a linear-log plot as a series of linear segments connected by arcs.</figcaption></figure>
<p>Performance of bigger models on various tasks, when plotted on a 
log-log scale, appears as a linear extrapolation of performance achieved
 by smaller models. However, this linearity may be punctuated by "<a href="https://en.wikipedia.org/wiki/Neural_scaling_law#Broken_Neural_Scaling_Laws_(BNSL)" title="Neural scaling law">break(s)</a>"<sup id="cite_ref-IYm4Q_78-1" class="reference"><a href="#cite_note-IYm4Q-78">[78]</a></sup> in the scaling law, where the slope of the line changes abruptly, and where larger models acquire "emergent abilities".<sup id="cite_ref-emergentpaper_33-1" class="reference"><a href="#cite_note-emergentpaper-33">[33]</a></sup><sup id="cite_ref-JM6s1_79-0" class="reference"><a href="#cite_note-JM6s1-79">[79]</a></sup> They arise from the complex interaction of the model's components and are not explicitly programmed or designed.<sup id="cite_ref-Bowman_2-1" class="reference"><a href="#cite_note-Bowman-2">[2]</a></sup>
</p><p>The most intriguing among emergent abilities is <a href="https://en.wikipedia.org/wiki/In-context_learning" class="mw-redirect" title="In-context learning">in-context learning</a> from example demonstrations.<sup id="cite_ref-Hahn_20230314_80-0" class="reference"><a href="#cite_note-Hahn_20230314-80">[80]</a></sup> In-context learning is involved in tasks, such as:
</p>
<ul><li>reported arithmetics, decoding the <a href="https://en.wikipedia.org/wiki/International_Phonetic_Alphabet" title="International Phonetic Alphabet">International Phonetic Alphabet</a>, unscrambling a word's letters, disambiguate word in context,<sup id="cite_ref-emergentpaper_33-2" class="reference"><a href="#cite_note-emergentpaper-33">[33]</a></sup><sup id="cite_ref-57FEA_81-0" class="reference"><a href="#cite_note-57FEA-81">[81]</a></sup><sup id="cite_ref-TEIkA_82-0" class="reference"><a href="#cite_note-TEIkA-82">[82]</a></sup> converting spatial words, <a href="https://en.wikipedia.org/wiki/Cardinal_direction" title="Cardinal direction">cardinal directions</a> (for example, replying "northeast" upon [0, 0, 1; 0, 0, 0; 0, 0, 0]), color terms represented in text.<sup id="cite_ref-zgy1i_83-0" class="reference"><a href="#cite_note-zgy1i-83">[83]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Chain-of-thought_prompting" class="mw-redirect" title="Chain-of-thought prompting">chain-of-thought prompting</a>:
 Model outputs are improved by chain-of-thought prompting only when 
model size exceeds 62B. Smaller models perform better when prompted to 
answer immediately, without chain of thought.<sup id="cite_ref-Imb98_84-0" class="reference"><a href="#cite_note-Imb98-84">[84]</a></sup></li>
<li>identifying offensive content in paragraphs of <a href="https://en.wikipedia.org/wiki/Hinglish" title="Hinglish">Hinglish</a> (a combination of Hindi and English), and generating a similar English equivalent of <a href="https://en.wikipedia.org/wiki/Kiswahili" class="mw-redirect" title="Kiswahili">Kiswahili</a> proverbs.<sup id="cite_ref-CeQVF_85-0" class="reference"><a href="#cite_note-CeQVF-85">[85]</a></sup></li></ul>
<p>Schaeffer <i>et. al.</i> argue that the emergent abilities are not unpredictably acquired, but predictably acquired according to a <a href="https://en.wikipedia.org/wiki/Neural_scaling_law" title="Neural scaling law">smooth scaling law</a>.
 The authors considered a toy statistical model of an LLM solving 
multiple-choice questions, and showed that this statistical model, 
modified to account for other types of tasks, applies to these tasks as 
well.<sup id="cite_ref-C775b_86-0" class="reference"><a href="#cite_note-C775b-86">[86]</a></sup>
</p><p>Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/87f9e315fd7e2ba406057a97300593c4802b53e4.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="{\displaystyle x}"></span> be the number of parameter count, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/b8a6208ec717213d4317e666f1ae872e00620a0d.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="{\displaystyle y}"></span> be the performance of the model.
</p>
<div style="font-size:85%;">
<ul><li>When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle y={\text{average }}\Pr({\text{correct token}})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>average&nbsp;</mtext>
        </mrow>
        <mo movablelimits="true" form="prefix">Pr</mo>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>correct token</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y={\text{average }}\Pr({\text{correct token}})}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/25f87a1a04b7eb97aca02ae9170ae7f05e308bd4.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:30.404ex; height:2.843ex;" alt="{\displaystyle y={\text{average }}\Pr({\text{correct token}})}"></span>, then <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle (\log x,y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mi>log</mi>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>x</mi>
        <mo>,</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (\log x,y)}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/1dccdbdb2af7f930d3fff961d7f76540706bbaf8.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.687ex; height:2.843ex;" alt="{\displaystyle (\log x,y)}"></span> is an exponential curve (before it hits the plateau at one), which looks like emergence.</li>
<li>When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle y={\text{average }}\log(\Pr({\text{correct token}}))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>average&nbsp;</mtext>
        </mrow>
        <mi>log</mi>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mo movablelimits="true" form="prefix">Pr</mo>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>correct token</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y={\text{average }}\log(\Pr({\text{correct token}}))}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/c22c18197c1091afcb5ed896ba90b8429af1c861.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:35.185ex; height:2.843ex;" alt="{\displaystyle y={\text{average }}\log(\Pr({\text{correct token}}))}"></span>, then the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle (\log x,y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mi>log</mi>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>x</mi>
        <mo>,</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (\log x,y)}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/1dccdbdb2af7f930d3fff961d7f76540706bbaf8.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.687ex; height:2.843ex;" alt="{\displaystyle (\log x,y)}"></span> plot is a straight line (before it hits the plateau at zero), which does not look like emergence.</li>
<li>When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle y={\text{average }}\Pr({\text{the most likely token is correct}})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>average&nbsp;</mtext>
        </mrow>
        <mo movablelimits="true" form="prefix">Pr</mo>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>the most likely token is correct</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y={\text{average }}\Pr({\text{the most likely token is correct}})}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/6028c3484d3fbd36ffdc2cad41ff60ba9f8c1e7a.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:47.867ex; height:2.843ex;" alt="{\displaystyle y={\text{average }}\Pr({\text{the most likely token is correct}})}"></span>, then <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle (\log x,y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mi>log</mi>
        <mo>⁡<!-- ⁡ --></mo>
        <mi>x</mi>
        <mo>,</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (\log x,y)}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/1dccdbdb2af7f930d3fff961d7f76540706bbaf8.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.687ex; height:2.843ex;" alt="{\displaystyle (\log x,y)}"></span> is a step-function, which looks like emergence.</li></ul></div>
<h2><span class="mw-headline" id="Interpretation">Interpretation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=20" title="Edit section: Interpretation"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Large language models by themselves are "<a href="https://en.wikipedia.org/wiki/Black_box" title="Black box">black boxes</a>", and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work.
</p><p>Mechanistic interpretability aims to <a href="https://en.wikipedia.org/wiki/Reverse_engineering" title="Reverse engineering">reverse-engineer</a>
 LLM by discovering symbolic algorithms that approximate the inference 
performed by LLM. One example is Othello-GPT, where a small Transformer 
is trained to predict legal <a href="https://en.wikipedia.org/wiki/Reversi" title="Reversi">Othello</a>
 moves. It is found that there is a linear representation of Othello 
board, and modifying the representation changes the predicted legal 
Othello moves in the correct way.<sup id="cite_ref-IZSIr_87-0" class="reference"><a href="#cite_note-IZSIr-87">[87]</a></sup><sup id="cite_ref-RLik9_88-0" class="reference"><a href="#cite_note-RLik9-88">[88]</a></sup> In another example, a small Transformer is trained on <a href="https://en.wikipedia.org/wiki/Karel_(programming_language)" title="Karel (programming language)">Karel programs</a>.
 Similar to the Othello-GPT example, there is a linear representation of
 Karel program semantics, and modifying the representation changes 
output in the correct way. The model also generates correct programs 
that are on average shorter than those in the training set.<sup id="cite_ref-Hln1l_89-0" class="reference"><a href="#cite_note-Hln1l-89">[89]</a></sup>
</p><p>In another example, the authors trained small transformers on <a href="https://en.wikipedia.org/wiki/Modular_arithmetic" title="Modular arithmetic">modular arithmetic addition</a>. The resulting models were reverse-engineered, and it turned out they used <a href="https://en.wikipedia.org/wiki/Discrete_Fourier_transform" title="Discrete Fourier transform">discrete Fourier transform</a>.<sup id="cite_ref-oYGlo_90-0" class="reference"><a href="#cite_note-oYGlo-90">[90]</a></sup>
</p>
<h3><span class="mw-headline" id="Understanding_and_intelligence">Understanding and intelligence</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=21" title="Edit section: Understanding and intelligence"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>NLP researchers were evenly split when asked, in a 2022 survey, 
whether (untuned) LLMs "could (ever) understand natural language in some
 nontrivial sense".<sup id="cite_ref-debate_understanding_91-0" class="reference"><a href="#cite_note-debate_understanding-91">[91]</a></sup> Proponents of "LLM understanding" believe that some LLM abilities, such as mathematical reasoning, imply an ability to <a href="https://en.wikipedia.org/wiki/Natural_language_understanding" class="mw-redirect" title="Natural language understanding">"understand"</a>
 certain concepts. A Microsoft team argued in 2023 that GPT-4 "can solve
 novel and difficult tasks that span mathematics, coding, vision, 
medicine, law, psychology and more" and that GPT-4 "could reasonably be 
viewed as an early (yet still incomplete) version of an <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence" title="Artificial general intelligence">artificial general intelligence</a> system": "Can one reasonably say that a system that passes exams for software engineering candidates is not <i>really</i> intelligent?"<sup id="cite_ref-O8Upd_92-0" class="reference"><a href="#cite_note-O8Upd-92">[92]</a></sup><sup id="cite_ref-microsoft_sparks_93-0" class="reference"><a href="#cite_note-microsoft_sparks-93">[93]</a></sup> Some researchers characterize LLMs as "alien intelligence".<sup id="cite_ref-rEEmH_94-0" class="reference"><a href="#cite_note-rEEmH-94">[94]</a></sup><sup id="cite_ref-new_yorker_kind_of_mind_95-0" class="reference"><a href="#cite_note-new_yorker_kind_of_mind-95">[95]</a></sup> For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien "<a href="https://en.wikipedia.org/wiki/Shoggoth" title="Shoggoth">Shoggoths</a>",
 and believes that RLHF tuning creates a "smiling facade" obscuring the 
inner workings of the LLM: "If you don't push it too far, the smiley 
face stays on. But then you give it [an unexpected] prompt, and suddenly
 you see this massive underbelly of insanity, of weird thought processes
 and clearly non-human understanding."<sup id="cite_ref-rAFIZ_96-0" class="reference"><a href="#cite_note-rAFIZ-96">[96]</a></sup><sup id="cite_ref-4luKE_97-0" class="reference"><a href="#cite_note-4luKE-97">[97]</a></sup>
</p><p>In contrast, some proponents of the "LLMs lack understanding" 
school believe that existing LLMs are "simply remixing and recombining 
existing writing",<sup id="cite_ref-new_yorker_kind_of_mind_95-1" class="reference"><a href="#cite_note-new_yorker_kind_of_mind-95">[95]</a></sup> a phenomenon known as <a href="https://en.wikipedia.org/wiki/Stochastic_parrot" title="Stochastic parrot">stochastic parrot</a>,
 or they point to the deficits existing LLMs continue to have in 
prediction skills, reasoning skills, agency, and explainability.<sup id="cite_ref-debate_understanding_91-1" class="reference"><a href="#cite_note-debate_understanding-91">[91]</a></sup> For example, GPT-4 has natural deficits in planning and in real-time learning.<sup id="cite_ref-microsoft_sparks_93-1" class="reference"><a href="#cite_note-microsoft_sparks-93">[93]</a></sup> Generative LLMs have been observed to confidently assert claims of fact which do not seem to be <a href="https://en.wikipedia.org/wiki/Justification_(epistemology)" title="Justification (epistemology)">justified</a> by their <a href="https://en.wikipedia.org/wiki/Training_data" class="mw-redirect" title="Training data">training data</a>, a phenomenon which has been termed "<a href="https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)" title="Hallucination (artificial intelligence)">hallucination</a>".<sup id="cite_ref-hallucination-survey_98-0" class="reference"><a href="#cite_note-hallucination-survey-98">[98]</a></sup>
 Specifically, hallucinations in the context of LLMs correspond to the 
generation of text or responses that seem syntactically sound, fluent, 
and natural but are factually incorrect, nonsensical, or unfaithful to 
the provided source input.<sup id="cite_ref-99" class="reference"><a href="#cite_note-99">[99]</a></sup> Neuroscientist <a href="https://en.wikipedia.org/wiki/Terrence_Sejnowski" class="mw-redirect" title="Terrence Sejnowski">Terrence Sejnowski</a>
 has argued that "The diverging opinions of experts on the intelligence 
of LLMs suggests that our old ideas based on natural intelligence are 
inadequate".<sup id="cite_ref-debate_understanding_91-2" class="reference"><a href="#cite_note-debate_understanding-91">[91]</a></sup>
</p><p>The matter of LLM's exhibiting intelligence or understanding has 
two main aspects – the first is how to model thought and language in a 
computer system, and the second is how to enable the computer system to 
generate human like language.<sup id="cite_ref-debate_understanding_91-3" class="reference"><a href="#cite_note-debate_understanding-91">[91]</a></sup> These aspects of language as a model of <a href="https://en.wikipedia.org/wiki/Cognition" title="Cognition">cognition</a> have been developed in the field of <a href="https://en.wikipedia.org/wiki/Cognitive_linguistics" title="Cognitive linguistics">cognitive linguistics</a>. American linguist <a href="https://en.wikipedia.org/wiki/George_Lakoff" title="George Lakoff">George Lakoff</a> presented Neural Theory of Language (NTL)<sup id="cite_ref-100" class="reference"><a href="#cite_note-100">[100]</a></sup> as a <a href="https://en.wikipedia.org/wiki/Cognitive_linguistics#Computational_approaches" title="Cognitive linguistics">computational basis</a> for using language as a model of learning tasks and understanding. <a rel="nofollow" class="external text" href="https://www.icsi.berkeley.edu/icsi/projects/ai/ntl">The NTL Model</a>
 outlines how specific neural structures of the human brain shape the 
nature of thought and language and in turn what are the computational 
properties of such neural systems that can be applied to model thought 
and language in a computer system. After a framework for modeling 
language in a computer systems was established, the focus shifted to 
establishing frameworks for computer systems to generate language with 
acceptable grammar. In his 2014 book titled <i><a href="https://en.wikipedia.org/wiki/The_Language_Myth" title="The Language Myth">The Language Myth: Why Language Is Not An Instinct</a></i>, British cognitive linguist and digital communication technologist <a href="https://en.wikipedia.org/wiki/Vyvyan_Evans" title="Vyvyan Evans">Vyvyan Evans</a> mapped out the role of <a href="https://en.wikipedia.org/wiki/Probabilistic_context-free_grammar" title="Probabilistic context-free grammar">probabilistic context-free grammar</a> (PCFG) in enabling <a href="https://en.wikipedia.org/wiki/Natural_language_processing#Cognition" title="Natural language processing">NLP to model cognitive patterns</a> and generate human like language.<sup id="cite_ref-101" class="reference"><a href="#cite_note-101">[101]</a></sup> <sup id="cite_ref-102" class="reference"><a href="#cite_note-102">[102]</a></sup>
</p>
<h2><span class="mw-headline" id="Evaluation">Evaluation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=22" title="Edit section: Evaluation"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Perplexity">Perplexity</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=23" title="Edit section: Perplexity"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The most commonly used measure of a language model's performance is its <a href="https://en.wikipedia.org/wiki/Perplexity" title="Perplexity">perplexity</a>
 on a given text corpus. Perplexity is a measure of how well a model is 
able to predict the contents of a dataset; the higher the likelihood the
 model assigns to the dataset, the lower the perplexity. Mathematically,
 perplexity is defined as the exponential of the average negative log 
likelihood per token:</p><div class="mwe-math-element"><div class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \log({\text{Perplexity}})=-{\frac {1}{N}}\sum _{i=1}^{N}\log(\Pr({\text{token}}_{i}\mid {\text{context for token}}_{i}))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>log</mi>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>Perplexity</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mo>−<!-- − --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>N</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>∑<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>N</mi>
          </mrow>
        </munderover>
        <mi>log</mi>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mo movablelimits="true" form="prefix">Pr</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>token</mtext>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>∣<!-- ∣ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>context for token</mtext>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 
\log({\text{Perplexity}})=-{\frac {1}{N}}\sum 
_{i=1}^{N}\log(\Pr({\text{token}}_{i}\mid {\text{context for 
token}}_{i}))}</annotation>
  </semantics>
</math></div><img src="Large%20language%20model%20-%20Wikipedia_files/556393708767666076b9723412bc8519284449a5.svg" class="mwe-math-fallback-image-display mw-invert" aria-hidden="true" style="vertical-align: -3.005ex; width:62.586ex; height:7.343ex;" alt="{\displaystyle \log({\text{Perplexity}})=-{\frac {1}{N}}\sum _{i=1}^{N}\log(\Pr({\text{token}}_{i}\mid {\text{context for token}}_{i}))}"></div>here <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle N}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>N</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/f5e3890c981ae85503089652feb48b191b57aae3.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:2.064ex; height:2.176ex;" alt="{\displaystyle N}"></span> is the number of tokens in the text corpus, and "context for token <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/add78d8608ad86e54951b8c8bd6c8d8416533d20.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="{\displaystyle i}"></span>" depends on the specific type of LLM used. If the LLM is autoregressive, then "context for token <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/add78d8608ad86e54951b8c8bd6c8d8416533d20.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="{\displaystyle i}"></span>" is the segment of text appearing before token <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/add78d8608ad86e54951b8c8bd6c8d8416533d20.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="{\displaystyle i}"></span>. If the LLM is masked, then "context for token <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/add78d8608ad86e54951b8c8bd6c8d8416533d20.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="{\displaystyle i}"></span>" is the segment of text surrounding token <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/add78d8608ad86e54951b8c8bd6c8d8416533d20.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="{\displaystyle i}"></span>.
<p></p><p>Because language models may <a href="https://en.wikipedia.org/wiki/Overfit" class="mw-redirect" title="Overfit">overfit</a> to their training data, models are usually evaluated by their perplexity on a <a href="https://en.wikipedia.org/wiki/Test_set" class="mw-redirect" title="Test set">test set</a> of unseen data.<sup id="cite_ref-jm_40-2" class="reference"><a href="#cite_note-jm-40">[40]</a></sup>
 This presents particular challenges for the evaluation of large 
language models. As they are trained on increasingly large corpora of 
text largely scraped from the web, it becomes increasingly likely that 
models' training data inadvertently includes portions of any given test 
set.<sup id="cite_ref-few-shot-learners_6-1" class="reference"><a href="#cite_note-few-shot-learners-6">[6]</a></sup>
</p>
<h4><span id="BPW.2C_BPC.2C_and_BPT"></span><span class="mw-headline" id="BPW,_BPC,_and_BPT">BPW, BPC, and BPT</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=24" title="Edit section: BPW, BPC, and BPT"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In <a href="https://en.wikipedia.org/wiki/Information_theory" title="Information theory">information theory</a>, the concept of <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" title="Entropy (information theory)">entropy</a> is intricately linked to perplexity, a relationship notably established by <a href="https://en.wikipedia.org/wiki/Claude_Shannon" title="Claude Shannon">Claude Shannon</a>.<sup id="cite_ref-Huyen_103-0" class="reference"><a href="#cite_note-Huyen-103">[103]</a></sup> This relationship is mathematically expressed as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\text{Entropy}}=\log _{2}({\text{Perplexity}})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>Entropy</mtext>
        </mrow>
        <mo>=</mo>
        <msub>
          <mi>log</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>⁡<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>Perplexity</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{Entropy}}=\log _{2}({\text{Perplexity}})}</annotation>
  </semantics>
</math></span><img src="Large%20language%20model%20-%20Wikipedia_files/462f40a6811ee57670d1735c452d04be85a82c57.svg" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:27.813ex; height:2.843ex;" alt="{\displaystyle {\text{Entropy}}=\log _{2}({\text{Perplexity}})}"></span>.
</p><p>Entropy, in this context, is commonly quantified in terms of bits
 per word (BPW) or bits per character (BPC), which hinges on whether the
 language model utilizes word-based or character-based tokenization.
</p><p>Notably, in the case of larger language models that predominantly
 employ sub-word tokenization, bits per token (BPT) emerges as a 
seemingly more appropriate measure. However, due to the variance in 
tokenization methods across different Large Language Models (LLMs), BPT 
does not serve as a reliable metric for comparative analysis among 
diverse models. To convert BPT into BPW, one can multiply it by the 
average number of tokens per word.
</p><p>In the evaluation and comparison of language models, <a href="https://en.wikipedia.org/wiki/Cross-entropy" title="Cross-entropy">cross-entropy</a>
 is generally the preferred metric over entropy. The underlying 
principle is that a lower BPW is indicative of a model's enhanced 
capability for compression. This, in turn, reflects the model's 
proficiency in making accurate predictions.
</p>
<h3><span class="mw-headline" id="Task-specific_datasets_and_benchmarks">Task-specific datasets and benchmarks</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=25" title="Edit section: Task-specific datasets and benchmarks"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A large number of testing datasets and benchmarks have also been 
developed to evaluate the capabilities of language models on more 
specific downstream tasks. Tests may be designed to evaluate a variety 
of capabilities, including general knowledge, commonsense reasoning, and
 mathematical problem-solving.
</p><p>One broad category of evaluation dataset is question answering 
datasets, consisting of pairs of questions and correct answers, for 
example, ("Have the San Jose Sharks won the Stanley Cup?", "No").<sup id="cite_ref-boolq_104-0" class="reference"><a href="#cite_note-boolq-104">[104]</a></sup>
 A question answering task is considered "open book" if the model's 
prompt includes text from which the expected answer can be derived (for 
example, the previous question could be adjoined with some text which 
includes the sentence "The Sharks have advanced to the Stanley Cup 
finals once, losing to the Pittsburgh Penguins in 2016."<sup id="cite_ref-boolq_104-1" class="reference"><a href="#cite_note-boolq-104">[104]</a></sup>). Otherwise, the task is considered "closed book", and the model must draw on knowledge retained during training.<sup id="cite_ref-survey_105-0" class="reference"><a href="#cite_note-survey-105">[105]</a></sup> Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.<sup id="cite_ref-survey_105-1" class="reference"><a href="#cite_note-survey-105">[105]</a></sup>
</p><p>Evaluation datasets may also take the form of text completion, 
having the model select the most likely word or sentence to complete a 
prompt, for example: "Alice was friends with Bob. Alice went to visit 
her friend, ____".<sup id="cite_ref-few-shot-learners_6-2" class="reference"><a href="#cite_note-few-shot-learners-6">[6]</a></sup>
</p><p>Some composite benchmarks have also been developed which combine a
 diversity of different evaluation datasets and tasks. Examples include 
GLUE, SuperGLUE, <a href="https://en.wikipedia.org/wiki/MMLU" title="MMLU">MMLU</a>, BIG-bench, and HELM.<sup id="cite_ref-Huyen_103-1" class="reference"><a href="#cite_note-Huyen-103">[103]</a></sup><sup id="cite_ref-survey_105-2" class="reference"><a href="#cite_note-survey-105">[105]</a></sup>
</p><p>It was previously standard to report results on a heldout portion
 of an evaluation dataset after doing supervised fine-tuning on the 
remainder. It is now more common to evaluate a pre-trained model 
directly through prompting techniques, though researchers vary in the 
details of how they formulate prompts for particular tasks, particularly
 with respect to how many examples of solved tasks are adjoined to the 
prompt (i.e. the value of <i>n</i> in <i>n</i>-shot prompting).
</p>
<h4><span class="mw-headline" id="Adversarially_constructed_evaluations">Adversarially constructed evaluations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=26" title="Edit section: Adversarially constructed evaluations"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Because of the rapid pace of improvement of large language models, 
evaluation benchmarks have suffered from short lifespans, with state of 
the art models quickly "saturating" existing benchmarks, exceeding the 
performance of human annotators, leading to efforts to replace or 
augment the benchmark with more challenging tasks.<sup id="cite_ref-bigbench_106-0" class="reference"><a href="#cite_note-bigbench-106">[106]</a></sup>
 In addition, there are cases of "shortcut learning" wherein AIs 
sometimes "cheat" on multiple-choice tests by using statistical 
correlations in superficial test question wording in order to guess the 
correct responses, without necessarily understanding the actual question
 being asked.<sup id="cite_ref-debate_understanding_91-4" class="reference"><a href="#cite_note-debate_understanding-91">[91]</a></sup>
</p><p>Some datasets have been constructed adversarially, focusing on 
particular problems on which extant language models seem to have 
unusually poor performance compared to humans. One example is the 
TruthfulQA dataset, a question answering dataset consisting of 817 
questions which language models are susceptible to answering incorrectly
 by mimicking falsehoods to which they were repeatedly exposed during 
training. For example, an LLM may answer "No" to the question "Can you 
teach an old dog new tricks?" because of its exposure to the English 
idiom <i><a href="https://en.wiktionary.org/wiki/you_can%27t_teach_an_old_dog_new_tricks" class="extiw" title="wikt:you can't teach an old dog new tricks">you can't teach an old dog new tricks</a></i>, even though this is not literally true.<sup id="cite_ref-truthfulqa_107-0" class="reference"><a href="#cite_note-truthfulqa-107">[107]</a></sup>
</p><p>Another example of an adversarial evaluation dataset is Swag and 
its successor, HellaSwag, collections of problems in which one of 
multiple options must be selected to complete a text passage. The 
incorrect completions were generated by sampling from a language model 
and filtering with a set of classifiers. The resulting problems are 
trivial for humans but at the time the datasets were created state of 
the art language models had poor accuracy on them. For example:
</p>
<blockquote>
<p>We see a fitness center sign. We then see a man talking to the camera and sitting and laying on a exercise ball. The man...
<br>a) demonstrates how to increase efficient exercise work by running up and down balls.
<br>b) moves all his arms and legs and builds up a lot of muscle.
<br>c) then plays the ball and we see a graphics and hedge trimming demonstration.
<br>d) performs sit ups while on the ball and talking.<sup id="cite_ref-hellaswag_108-0" class="reference"><a href="#cite_note-hellaswag-108">[108]</a></sup>
</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/BERT_(language_model)" title="BERT (language model)">BERT</a> selects b) as the most likely completion, though the correct answer is d).<sup id="cite_ref-hellaswag_108-1" class="reference"><a href="#cite_note-hellaswag-108">[108]</a></sup>
</p>
<h2><span class="mw-headline" id="Wider_impact">Wider impact</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=27" title="Edit section: Wider impact"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In 2023, <i><a href="https://en.wikipedia.org/wiki/Nature_Biomedical_Engineering" title="Nature Biomedical Engineering">Nature Biomedical Engineering</a></i>
 wrote that "it is no longer possible to accurately distinguish" 
human-written text from text created by large language models, and that 
"It is all but certain that general-purpose large language models will 
rapidly proliferate... It is a rather safe bet that they will change 
many industries over time."<sup id="cite_ref-ZDTUM_109-0" class="reference"><a href="#cite_note-ZDTUM-109">[109]</a></sup> <a href="https://en.wikipedia.org/wiki/Goldman_Sachs" title="Goldman Sachs">Goldman Sachs</a>
 suggested in 2023 that generative language AI could increase global GDP
 by 7% in the next ten years, and could expose to automation 300 million
 jobs globally.<sup id="cite_ref-81w7x_110-0" class="reference"><a href="#cite_note-81w7x-110">[110]</a></sup><sup id="cite_ref-zIM6Y_111-0" class="reference"><a href="#cite_note-zIM6Y-111">[111]</a></sup>
</p>
<h3><span class="mw-headline" id="Memorization_and_copyright">Memorization and copyright</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=28" title="Edit section: Memorization and copyright"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Further information: <a href="https://en.wikipedia.org/wiki/Artificial_intelligence_and_copyright" title="Artificial intelligence and copyright">Artificial intelligence and copyright</a></div>
<p>Memorization is an emergent behavior in LLMs in which long strings of
 text are occasionally output verbatim from training data, contrary to 
typical behavior of traditional artificial neural nets. Evaluations of 
controlled LLM output measure the amount memorized from training data 
(focused on GPT-2-series models) as variously over 1% for exact 
duplicates<sup id="cite_ref-112" class="reference"><a href="#cite_note-112">[112]</a></sup> or up to about 7%.<sup id="cite_ref-113" class="reference"><a href="#cite_note-113">[113]</a></sup>
</p>
<h3><span class="mw-headline" id="Security">Security</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=29" title="Edit section: Security"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Some commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse.<sup id="cite_ref-nD6kH_114-0" class="reference"><a href="#cite_note-nD6kH-114">[114]</a></sup>
 For example, the availability of large language models could reduce the
 skill-level required to commit bioterrorism; biosecurity researcher 
Kevin Esvelt has suggested that LLM creators should exclude from their 
training data papers on creating or enhancing pathogens.<sup id="cite_ref-PKiPY_115-0" class="reference"><a href="#cite_note-PKiPY-115">[115]</a></sup>
</p><p>A study by researchers at Google and several universities, including <a href="https://en.wikipedia.org/wiki/Cornell_University" title="Cornell University">Cornell University</a> and <a href="https://en.wikipedia.org/wiki/University_of_California,_Berkeley" title="University of California, Berkeley">University of California, Berkeley</a>, showed that there are potential security risks in language models such as <a href="https://en.wikipedia.org/wiki/ChatGPT" title="ChatGPT">ChatGPT</a>.
 In their study, they examined the possibility that questioners could 
get, from ChatGPT, the training data that the AI model used; they found 
that they could get the training data from the AI model. For example, 
when asking ChatGPT 3.5 turbo to repeat the word "poem" forever, the AI 
model will say "poem" hundreds of times and then diverge, deviating from
 the standard dialogue style and spitting out nonsense phrases, thus 
spitting out the training data as it is. The researchers have seen more 
than 10,000 examples of the AI model exposing their training data in a 
similar method. The researchers said that it was hard to tell if the AI 
model was actually safe or not.<sup id="cite_ref-116" class="reference"><a href="#cite_note-116">[116]</a></sup>
</p><p>The potential presence of "sleeper agents" within LLM models is 
another emerging security concern. These are hidden functionalities 
built into the model that remain dormant until triggered by a specific 
event or condition. Upon activation, the LLM deviates from its expected 
behavior to make insecure actions.<sup id="cite_ref-117" class="reference"><a href="#cite_note-117">[117]</a></sup>
</p>
<h3><span class="mw-headline" id="Algorithmic_bias">Algorithmic bias</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=30" title="Edit section: Algorithmic bias"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Algorithmic_bias" title="Algorithmic bias">Algorithmic bias</a></div>
<p>While LLMs have shown remarkable capabilities in generating 
human-like text, they are susceptible to inheriting and amplifying 
biases present in their training data. This can manifest in skewed 
representations or unfair treatment of different demographics, such as 
those based on race, gender, language, and cultural groups.<sup id="cite_ref-:8_118-0" class="reference"><a href="#cite_note-:8-118">[118]</a></sup> Since English data is overrepresented in current large language models' training data, it may also downplay non-English views.<sup id="cite_ref-:1_119-0" class="reference"><a href="#cite_note-:1-119">[119]</a></sup>
</p>
<h4><span class="mw-headline" id="Stereotyping">Stereotyping</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=31" title="Edit section: Stereotyping"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>AI models can reinforce a wide range of stereotypes, including those 
based on gender, ethnicity, age, nationality, religion, or occupation. 
This can lead to outputs that unfairly generalize or caricature groups 
of people, sometimes in harmful or derogatory ways.<sup id="cite_ref-120" class="reference"><a href="#cite_note-120">[120]</a></sup>
</p><p>Notably, gender bias refers to the tendency of these models to 
produce outputs that are unfairly prejudiced towards one gender over 
another. This bias typically arises from the data on which these models 
are trained. Large language models often assign roles and 
characteristics based on traditional gender norms.<sup id="cite_ref-:8_118-1" class="reference"><a href="#cite_note-:8-118">[118]</a></sup> For example, it might associate nurses or secretaries predominantly with women and engineers or CEOs with men.<sup id="cite_ref-121" class="reference"><a href="#cite_note-121">[121]</a></sup>
</p>
<h4><span class="mw-headline" id="Political_bias">Political bias</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=32" title="Edit section: Political bias"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Political bias refers to the tendency of algorithms to systematically
 favor certain political viewpoints, ideologies, or outcomes over 
others. Language models may also exhibit political biases. Since the 
training data includes a wide range of political opinions and coverage, 
the models might generate responses that lean towards particular 
political ideologies or viewpoints, depending on the prevalence of those
 views in the data.<sup id="cite_ref-122" class="reference"><a href="#cite_note-122">[122]</a></sup>
</p>
<h2><span class="mw-headline" id="List">List</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=33" title="Edit section: List"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="https://en.wikipedia.org/wiki/List_of_chatbots" title="List of chatbots">List of chatbots</a></div>
<p>For the training cost column, 1 petaFLOP-day = 1 petaFLOP/sec × 1 day = 8.64E19 FLOP.
</p>
<table class="wikitable sortable jquery-tablesorter">

<thead><tr>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">Name</th>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">Release date<sup id="cite_ref-123" class="reference"><a href="#cite_note-123">[a]</a></sup></th>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">Developer</th>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">Number of parameters (billion) <sup id="cite_ref-124" class="reference"><a href="#cite_note-124">[b]</a></sup></th>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">Corpus size
</th>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">Training cost (petaFLOP-day)</th>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">License<sup id="cite_ref-125" class="reference"><a href="#cite_note-125">[c]</a></sup></th>
<th class="headerSort" tabindex="0" role="columnheader button" title="Sort ascending">Notes
</th></tr></thead><tbody>
<tr>
<td><a href="https://en.wikipedia.org/wiki/GPT-1" title="GPT-1">GPT-1</a></td>
<td><span data-sort-value="000000002018-06-01-0000" style="white-space:nowrap">June 2018</span></td>
<td><a href="https://en.wikipedia.org/wiki/OpenAI" title="OpenAI">OpenAI</a></td>
<td><span data-sort-value="117000000&nbsp;!">0.117</span></td>
<td>
</td>
<td>1<sup id="cite_ref-oai-unsup_126-0" class="reference"><a href="#cite_note-oai-unsup-126">[123]</a></sup></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">MIT<sup id="cite_ref-gpt1_127-0" class="reference"><a href="#cite_note-gpt1-127">[124]</a></sup>
</td>
<td>First GPT model, decoder-only transformer. Trained for 30 days on 8 P600 <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit" title="Graphics processing unit">GPUs</a>.
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/BERT_(language_model)" title="BERT (language model)">BERT</a></td>
<td><span data-sort-value="000000002018-10-01-0000" style="white-space:nowrap">October 2018</span></td>
<td><a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a></td>
<td><span data-sort-value="340000000&nbsp;!">0.340</span><sup id="cite_ref-bert-paper_128-0" class="reference"><a href="#cite_note-bert-paper-128">[125]</a></sup></td>
<td><span data-sort-value="3300000000&nbsp;!">3.3 billion</span> words<sup id="cite_ref-bert-paper_128-1" class="reference"><a href="#cite_note-bert-paper-128">[125]</a></sup>
</td>
<td><span data-sort-value="9&nbsp;!">9</span><sup id="cite_ref-bHZJ2_129-0" class="reference"><a href="#cite_note-bHZJ2-129">[126]</a></sup></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0<sup id="cite_ref-bert-web_130-0" class="reference"><a href="#cite_note-bert-web-130">[127]</a></sup>
</td>
<td>An early and influential language model,<sup id="cite_ref-Manning-2022_7-1" class="reference"><a href="#cite_note-Manning-2022-7">[7]</a></sup> but encoder-only and thus not built to be prompted or generative<sup id="cite_ref-Ir545_131-0" class="reference"><a href="#cite_note-Ir545-131">[128]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/T5_(language_model)" title="T5 (language model)">T5</a>
</td>
<td>October 2019
</td>
<td>Google
</td>
<td>11<sup id="cite_ref-:6_132-0" class="reference"><a href="#cite_note-:6-132">[129]</a></sup>
</td>
<td>34 billion tokens<sup id="cite_ref-:6_132-1" class="reference"><a href="#cite_note-:6-132">[129]</a></sup>
</td>
<td>
</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0<sup id="cite_ref-133" class="reference"><a href="#cite_note-133">[130]</a></sup>
</td>
<td>Base model for many Google projects, such as Imagen.<sup id="cite_ref-134" class="reference"><a href="#cite_note-134">[131]</a></sup>
</td></tr>
<tr>
<td>XLNet</td>
<td><span data-sort-value="000000002019-06-01-0000" style="white-space:nowrap">June 2019</span></td>
<td><a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a></td>
<td><span data-sort-value="340000000&nbsp;!">~0.340</span><sup id="cite_ref-45rAm_135-0" class="reference"><a href="#cite_note-45rAm-135">[132]</a></sup></td>
<td><span data-sort-value="3300000000&nbsp;!">33</span> billion words
</td>
<td></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0<sup id="cite_ref-xlnet_136-0" class="reference"><a href="#cite_note-xlnet-136">[133]</a></sup>
</td>
<td>An alternative to BERT; designed as encoder-only<sup id="cite_ref-gAbNO_137-0" class="reference"><a href="#cite_note-gAbNO-137">[134]</a></sup><sup id="cite_ref-LX3rI_138-0" class="reference"><a href="#cite_note-LX3rI-138">[135]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/GPT-2" title="GPT-2">GPT-2</a></td>
<td><span data-sort-value="000000002019-02-01-0000" style="white-space:nowrap">February 2019</span></td>
<td><a href="https://en.wikipedia.org/wiki/OpenAI" title="OpenAI">OpenAI</a></td>
<td><span data-sort-value="1500000000&nbsp;!">1.5</span><sup id="cite_ref-15Brelease_139-0" class="reference"><a href="#cite_note-15Brelease-139">[136]</a></sup></td>
<td>40GB<sup id="cite_ref-5T8u5_140-0" class="reference"><a href="#cite_note-5T8u5-140">[137]</a></sup> (~<span data-sort-value="10000000000&nbsp;!">10 billion</span> tokens)<sup id="cite_ref-LambdaLabs_141-0" class="reference"><a href="#cite_note-LambdaLabs-141">[138]</a></sup>
</td>
<td></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">MIT<sup id="cite_ref-Sudbe_142-0" class="reference"><a href="#cite_note-Sudbe-142">[139]</a></sup>
</td>
<td>general-purpose model based on transformer architecture
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/GPT-3" title="GPT-3">GPT-3</a></td>
<td><span data-sort-value="000000002020-05-01-0000" style="white-space:nowrap">May 2020</span></td>
<td>OpenAI</td>
<td><span data-sort-value="175000000000&nbsp;!">175</span><sup id="cite_ref-Wiggers_41-1" class="reference"><a href="#cite_note-Wiggers-41">[41]</a></sup></td>
<td><span data-sort-value="300000000000&nbsp;!">300 billion</span> tokens<sup id="cite_ref-LambdaLabs_141-1" class="reference"><a href="#cite_note-LambdaLabs-141">[138]</a></sup>
</td>
<td>3640<sup id="cite_ref-:2_143-0" class="reference"><a href="#cite_note-:2-143">[140]</a></sup></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">proprietary
</td>
<td>A fine-tuned variant of GPT-3, termed GPT-3.5, was made available to the public through a web interface called <a href="https://en.wikipedia.org/wiki/ChatGPT" title="ChatGPT">ChatGPT</a> in 2022.<sup id="cite_ref-chatgpt-blog_144-0" class="reference"><a href="#cite_note-chatgpt-blog-144">[141]</a></sup>
</td></tr>
<tr>
<td>GPT-Neo</td>
<td><span data-sort-value="000000002021-03-01-0000" style="white-space:nowrap">March 2021</span></td>
<td><a href="https://en.wikipedia.org/wiki/EleutherAI" title="EleutherAI">EleutherAI</a></td>
<td><span data-sort-value="2700000000&nbsp;!">2.7</span><sup id="cite_ref-gpt-neo_145-0" class="reference"><a href="#cite_note-gpt-neo-145">[142]</a></sup></td>
<td>825 GiB<sup id="cite_ref-Pile_146-0" class="reference"><a href="#cite_note-Pile-146">[143]</a></sup>
</td>
<td></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">MIT<sup id="cite_ref-vb-gpt-neo_147-0" class="reference"><a href="#cite_note-vb-gpt-neo-147">[144]</a></sup>
</td>
<td>The first of <a href="https://en.wikipedia.org/wiki/EleutherAI#GPT_models" title="EleutherAI">a series of free GPT-3 alternatives</a>
 released by EleutherAI. GPT-Neo outperformed an equivalent-size GPT-3 
model on some benchmarks, but was significantly worse than the largest 
GPT-3.<sup id="cite_ref-vb-gpt-neo_147-1" class="reference"><a href="#cite_note-vb-gpt-neo-147">[144]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/GPT-J" title="GPT-J">GPT-J</a></td>
<td><span data-sort-value="000000002021-06-01-0000" style="white-space:nowrap">June 2021</span></td>
<td><a href="https://en.wikipedia.org/wiki/EleutherAI" title="EleutherAI">EleutherAI</a></td>
<td><span data-sort-value="6000000000&nbsp;!">6</span><sup id="cite_ref-JxohJ_148-0" class="reference"><a href="#cite_note-JxohJ-148">[145]</a></sup></td>
<td>825 GiB<sup id="cite_ref-Pile_146-1" class="reference"><a href="#cite_note-Pile-146">[143]</a></sup>
</td>
<td>200<sup id="cite_ref-:3_149-0" class="reference"><a href="#cite_note-:3-149">[146]</a></sup></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>GPT-3-style language model
</td></tr>
<tr>
<td>Megatron-Turing NLG</td>
<td><span data-sort-value="000000002021-10-01-0000" style="white-space:nowrap">October 2021</span><sup id="cite_ref-BwnW5_150-0" class="reference"><a href="#cite_note-BwnW5-150">[147]</a></sup></td>
<td><a href="https://en.wikipedia.org/wiki/Microsoft" title="Microsoft">Microsoft</a> and <a href="https://en.wikipedia.org/wiki/Nvidia" title="Nvidia">Nvidia</a></td>
<td><span data-sort-value="530000000000&nbsp;!">530</span><sup id="cite_ref-mtnlg-preprint_151-0" class="reference"><a href="#cite_note-mtnlg-preprint-151">[148]</a></sup></td>
<td><span data-sort-value="338600000000&nbsp;!">338.6 billion</span> tokens<sup id="cite_ref-mtnlg-preprint_151-1" class="reference"><a href="#cite_note-mtnlg-preprint-151">[148]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Restricted web access
</td>
<td>Standard architecture but trained on a supercomputing cluster.
</td></tr>
<tr>
<td>Ernie 3.0 Titan</td>
<td><span data-sort-value="000000002021-12-01-0000" style="white-space:nowrap">December 2021</span></td>
<td><a href="https://en.wikipedia.org/wiki/Baidu" title="Baidu">Baidu</a></td>
<td><span data-sort-value="260000000000&nbsp;!">260</span><sup id="cite_ref-qeOB8_152-0" class="reference"><a href="#cite_note-qeOB8-152">[149]</a></sup></td>
<td>4 Tb
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Chinese-language LLM. <a href="https://en.wikipedia.org/wiki/Ernie_Bot" title="Ernie Bot">Ernie Bot</a> is based on this model.
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Claude_(language_model)" title="Claude (language model)">Claude</a><sup id="cite_ref-i8jc4_153-0" class="reference"><a href="#cite_note-i8jc4-153">[150]</a></sup></td>
<td><span data-sort-value="000000002021-12-01-0000" style="white-space:nowrap">December 2021</span></td>
<td><a href="https://en.wikipedia.org/wiki/Anthropic" title="Anthropic">Anthropic</a></td>
<td><span data-sort-value="52000000000&nbsp;!">52</span><sup id="cite_ref-AnthroArch_154-0" class="reference"><a href="#cite_note-AnthroArch-154">[151]</a></sup></td>
<td><span data-sort-value="400000000000&nbsp;!">400 billion</span> tokens<sup id="cite_ref-AnthroArch_154-1" class="reference"><a href="#cite_note-AnthroArch-154">[151]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 255, 187); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #454500; --darkreader-inline-bgimage: none;" class="table-partial" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">beta
</td>
<td>Fine-tuned for desirable behavior in conversations.<sup id="cite_ref-RZqhw_155-0" class="reference"><a href="#cite_note-RZqhw-155">[152]</a></sup>
</td></tr>
<tr>
<td>GLaM (Generalist Language Model)</td>
<td><span data-sort-value="000000002021-12-01-0000" style="white-space:nowrap">December 2021</span></td>
<td>Google</td>
<td><span data-sort-value="1200000000000&nbsp;!">1200</span><sup id="cite_ref-glam-blog_32-1" class="reference"><a href="#cite_note-glam-blog-32">[32]</a></sup></td>
<td><span data-sort-value="1600000000000&nbsp;!">1.6 trillion</span> tokens<sup id="cite_ref-glam-blog_32-2" class="reference"><a href="#cite_note-glam-blog-32">[32]</a></sup>
</td>
<td>5600<sup id="cite_ref-glam-blog_32-3" class="reference"><a href="#cite_note-glam-blog-32">[32]</a></sup></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Sparse <a href="https://en.wikipedia.org/wiki/Mixture_of_experts" title="Mixture of experts">mixture of experts</a> model, making it more expensive to train but cheaper to run inference compared to GPT-3.
</td></tr>
<tr>
<td>Gopher</td>
<td><span data-sort-value="000000002021-12-01-0000" style="white-space:nowrap">December 2021</span></td>
<td><a href="https://en.wikipedia.org/wiki/DeepMind" class="mw-redirect" title="DeepMind">DeepMind</a></td>
<td><span data-sort-value="280000000000&nbsp;!">280</span><sup id="cite_ref-mD5eE_156-0" class="reference"><a href="#cite_note-mD5eE-156">[153]</a></sup></td>
<td><span data-sort-value="300000000000&nbsp;!">300 billion</span> tokens<sup id="cite_ref-hoffman_157-0" class="reference"><a href="#cite_note-hoffman-157">[154]</a></sup>
</td>
<td>5833<sup id="cite_ref-:4_158-0" class="reference"><a href="#cite_note-:4-158">[155]</a></sup></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Further developed into the Chinchilla model.
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/LaMDA" title="LaMDA">LaMDA</a> (Language Models for Dialog Applications)</td>
<td><span data-sort-value="000000002022-01-01-0000" style="white-space:nowrap">January 2022</span></td>
<td>Google</td>
<td><span data-sort-value="137000000000&nbsp;!">137</span><sup id="cite_ref-lamda-blog_159-0" class="reference"><a href="#cite_note-lamda-blog-159">[156]</a></sup></td>
<td>1.56T words,<sup id="cite_ref-lamda-blog_159-1" class="reference"><a href="#cite_note-lamda-blog-159">[156]</a></sup> <span data-sort-value="168000000000&nbsp;!">168 billion</span> tokens<sup id="cite_ref-hoffman_157-1" class="reference"><a href="#cite_note-hoffman-157">[154]</a></sup>
</td>
<td>4110<sup id="cite_ref-DMs9Z_160-0" class="reference"><a href="#cite_note-DMs9Z-160">[157]</a></sup></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Specialized for response generation in conversations.
</td></tr>
<tr>
<td>GPT-NeoX</td>
<td><span data-sort-value="000000002022-02-01-0000" style="white-space:nowrap">February 2022</span></td>
<td><a href="https://en.wikipedia.org/wiki/EleutherAI" title="EleutherAI">EleutherAI</a></td>
<td><span data-sort-value="20000000000&nbsp;!">20</span><sup id="cite_ref-gpt-neox-20b_161-0" class="reference"><a href="#cite_note-gpt-neox-20b-161">[158]</a></sup></td>
<td>825 GiB<sup id="cite_ref-Pile_146-2" class="reference"><a href="#cite_note-Pile-146">[143]</a></sup>
</td>
<td>740<sup id="cite_ref-:3_149-1" class="reference"><a href="#cite_note-:3-149">[146]</a></sup></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>based on the Megatron architecture
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Chinchilla_AI" class="mw-redirect" title="Chinchilla AI">Chinchilla</a></td>
<td><span data-sort-value="000000002022-03-01-0000" style="white-space:nowrap">March 2022</span></td>
<td><a href="https://en.wikipedia.org/wiki/DeepMind" class="mw-redirect" title="DeepMind">DeepMind</a></td>
<td><span data-sort-value="70000000000&nbsp;!">70</span><sup id="cite_ref-chinchilla-blog_162-0" class="reference"><a href="#cite_note-chinchilla-blog-162">[159]</a></sup></td>
<td><span data-sort-value="1400000000000&nbsp;!">1.4 trillion</span> tokens<sup id="cite_ref-chinchilla-blog_162-1" class="reference"><a href="#cite_note-chinchilla-blog-162">[159]</a></sup><sup id="cite_ref-hoffman_157-2" class="reference"><a href="#cite_note-hoffman-157">[154]</a></sup>
</td>
<td>6805<sup id="cite_ref-:4_158-1" class="reference"><a href="#cite_note-:4-158">[155]</a></sup></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Reduced-parameter model trained on more data. Used in the <a href="https://en.wikipedia.org/wiki/Sparrow_(bot)" class="mw-redirect" title="Sparrow (bot)">Sparrow</a> bot. Often cited for its <a href="https://en.wikipedia.org/wiki/Neural_scaling_law" title="Neural scaling law">neural scaling law</a>.
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/PaLM" title="PaLM">PaLM</a> (Pathways Language Model)</td>
<td><span data-sort-value="000000002022-04-01-0000" style="white-space:nowrap">April 2022</span></td>
<td>Google</td>
<td><span data-sort-value="540000000000&nbsp;!">540</span><sup id="cite_ref-palm-blog_163-0" class="reference"><a href="#cite_note-palm-blog-163">[160]</a></sup></td>
<td><span data-sort-value="768000000000&nbsp;!">768 billion</span> tokens<sup id="cite_ref-chinchilla-blog_162-2" class="reference"><a href="#cite_note-chinchilla-blog-162">[159]</a></sup>
</td>
<td>29250<sup id="cite_ref-:4_158-2" class="reference"><a href="#cite_note-:4-158">[155]</a></sup></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Trained for ~60 days on ~6000 <a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" title="Tensor Processing Unit">TPU v4</a> chips. <sup id="cite_ref-:4_158-3" class="reference"><a href="#cite_note-:4-158">[155]</a></sup>
</td></tr>
<tr>
<td>OPT (Open Pretrained Transformer)</td>
<td><span data-sort-value="000000002022-05-01-0000" style="white-space:nowrap">May 2022</span></td>
<td><a href="https://en.wikipedia.org/wiki/Meta_Platforms" title="Meta Platforms">Meta</a></td>
<td><span data-sort-value="175000000000&nbsp;!">175</span><sup id="cite_ref-jlof8_164-0" class="reference"><a href="#cite_note-jlof8-164">[161]</a></sup></td>
<td><span data-sort-value="180000000000&nbsp;!">180 billion</span> tokens<sup id="cite_ref-QjTIc_165-0" class="reference"><a href="#cite_note-QjTIc-165">[162]</a></sup>
</td>
<td>310<sup id="cite_ref-:3_149-2" class="reference"><a href="#cite_note-:3-149">[146]</a></sup></td>
<td style="background: rgb(255, 255, 187); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #454500; --darkreader-inline-bgimage: none;" class="table-partial" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Non-commercial research<sup id="cite_ref-166" class="reference"><a href="#cite_note-166">[d]</a></sup>
</td>
<td>GPT-3 architecture with some adaptations from Megatron
</td></tr>
<tr>
<td>YaLM 100B</td>
<td><span data-sort-value="000000002022-06-01-0000" style="white-space:nowrap">June 2022</span></td>
<td><a href="https://en.wikipedia.org/wiki/Yandex" title="Yandex">Yandex</a></td>
<td><span data-sort-value="100000000000&nbsp;!">100</span><sup id="cite_ref-yalm-repo_167-0" class="reference"><a href="#cite_note-yalm-repo-167">[163]</a></sup>
</td>
<td>1.7TB<sup id="cite_ref-yalm-repo_167-1" class="reference"><a href="#cite_note-yalm-repo-167">[163]</a></sup></td>
<td></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0</td>
<td>English-Russian model based on Microsoft's Megatron-LM.
</td></tr>
<tr>
<td>Minerva</td>
<td><span data-sort-value="000000002022-06-01-0000" style="white-space:nowrap">June 2022</span></td>
<td>Google</td>
<td><span data-sort-value="540000000000&nbsp;!">540</span><sup id="cite_ref-minerva-paper_168-0" class="reference"><a href="#cite_note-minerva-paper-168">[164]</a></sup></td>
<td>38.5B tokens from webpages filtered for mathematical content and from papers submitted to the arXiv preprint server<sup id="cite_ref-minerva-paper_168-1" class="reference"><a href="#cite_note-minerva-paper-168">[164]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>LLM trained for solving "mathematical and scientific questions using step-by-step reasoning".<sup id="cite_ref-FfCNK_169-0" class="reference"><a href="#cite_note-FfCNK-169">[165]</a></sup> Minerva is based on PaLM model, further trained on mathematical and scientific data.
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/BLOOM_(language_model)" title="BLOOM (language model)">BLOOM</a></td>
<td><span data-sort-value="000000002022-07-01-0000" style="white-space:nowrap">July 2022</span></td>
<td>Large collaboration led by <a href="https://en.wikipedia.org/wiki/Hugging_Face" title="Hugging Face">Hugging Face</a></td>
<td><span data-sort-value="175000000000&nbsp;!">175</span><sup id="cite_ref-bigger-better_170-0" class="reference"><a href="#cite_note-bigger-better-170">[166]</a></sup></td>
<td><span data-sort-value="350000000000&nbsp;!">350 billion</span> tokens (1.6TB)<sup id="cite_ref-B8wB2_171-0" class="reference"><a href="#cite_note-B8wB2-171">[167]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 255, 187); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #454500; --darkreader-inline-bgimage: none;" class="table-partial" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Responsible AI
</td>
<td>Essentially GPT-3 but trained on a multi-lingual corpus (30% English excluding programming languages)
</td></tr>
<tr>
<td>Galactica</td>
<td><span data-sort-value="000000002022-11-01-0000" style="white-space:nowrap">November 2022</span></td>
<td><a href="https://en.wikipedia.org/wiki/Meta_Platforms" title="Meta Platforms">Meta</a></td>
<td><span data-sort-value="120000000000&nbsp;!">120</span></td>
<td><span data-sort-value="350000000000&nbsp;!">106 billion</span> tokens<sup id="cite_ref-37sY6_172-0" class="reference"><a href="#cite_note-37sY6-172">[168]</a></sup>
</td>
<td>unknown</td>
<td style="background: rgb(255, 255, 187); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #454500; --darkreader-inline-bgimage: none;" class="table-partial" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">CC-BY-NC-4.0
</td>
<td>Trained on scientific text and modalities.
</td></tr>
<tr>
<td>AlexaTM (Teacher Models)</td>
<td><span data-sort-value="000000002022-11-01-0000" style="white-space:nowrap">November 2022</span></td>
<td><a href="https://en.wikipedia.org/wiki/Amazon_(company)" title="Amazon (company)">Amazon</a></td>
<td><span data-sort-value="20000000000&nbsp;!">20</span><sup id="cite_ref-u5szh_173-0" class="reference"><a href="#cite_note-u5szh-173">[169]</a></sup></td>
<td><span data-sort-value="1300000000000&nbsp;!">1.3 trillion</span><sup id="cite_ref-HaA7l_174-0" class="reference"><a href="#cite_note-HaA7l-174">[170]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">proprietary<sup id="cite_ref-rpehM_175-0" class="reference"><a href="#cite_note-rpehM-175">[171]</a></sup>
</td>
<td>bidirectional sequence-to-sequence architecture
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Neuro-sama" title="Neuro-sama">Neuro-sama</a></td>
<td><span data-sort-value="000000002022-12-01-0000" style="white-space:nowrap">December 2022</span></td>
<td>Independent</td>
<td>Unknown</td>
<td>Unknown
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">privately-owned
</td>
<td>A language model designed for live-streaming on <a href="https://en.wikipedia.org/wiki/Twitch_(service)" title="Twitch (service)">Twitch</a>.
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/LLaMA" title="LLaMA">LLaMA</a> (Large Language Model Meta AI)</td>
<td><span data-sort-value="000000002023-02-01-0000" style="white-space:nowrap">February 2023</span></td>
<td><a href="https://en.wikipedia.org/wiki/Meta_Platforms" title="Meta Platforms">Meta</a></td>
<td><span data-sort-value="65000000000&nbsp;!">65</span><sup id="cite_ref-llama-blog_176-0" class="reference"><a href="#cite_note-llama-blog-176">[172]</a></sup></td>
<td><span data-sort-value="1400000000000&nbsp;!">1.4 trillion</span><sup id="cite_ref-llama-blog_176-1" class="reference"><a href="#cite_note-llama-blog-176">[172]</a></sup>
</td>
<td>6300<sup id="cite_ref-:5_177-0" class="reference"><a href="#cite_note-:5-177">[173]</a></sup></td>
<td style="background: rgb(255, 255, 187); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #454500; --darkreader-inline-bgimage: none;" class="table-partial" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Non-commercial research<sup id="cite_ref-178" class="reference"><a href="#cite_note-178">[e]</a></sup>
</td>
<td>Trained on a large 20-language corpus to aim for better performance with fewer parameters.<sup id="cite_ref-llama-blog_176-2" class="reference"><a href="#cite_note-llama-blog-176">[172]</a></sup> Researchers from Stanford University trained a fine-tuned model based on LLaMA weights, called Alpaca.<sup id="cite_ref-KBedq_179-0" class="reference"><a href="#cite_note-KBedq-179">[174]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/GPT-4" title="GPT-4">GPT-4</a></td>
<td><span data-sort-value="000000002023-03-01-0000" style="white-space:nowrap">March 2023</span></td>
<td>OpenAI</td>
<td>Unknown<sup id="cite_ref-181" class="reference"><a href="#cite_note-181">[f]</a></sup></td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">proprietary
</td>
<td>Available for ChatGPT Plus users and used in <a href="https://en.wikipedia.org/wiki/GPT-4#Usage" title="GPT-4">several products</a>.
</td></tr>
<tr>
<td>Cerebras-GPT
</td>
<td><span data-sort-value="000000002023-03-01-0000" style="white-space:nowrap">March 2023</span>
</td>
<td><a href="https://en.wikipedia.org/wiki/Cerebras" title="Cerebras">Cerebras</a>
</td>
<td><span data-sort-value="13000000000&nbsp;!">13</span><sup id="cite_ref-D0k2a_182-0" class="reference"><a href="#cite_note-D0k2a-182">[176]</a></sup>
</td>
<td>
</td>
<td>270<sup id="cite_ref-:3_149-3" class="reference"><a href="#cite_note-:3-149">[146]</a></sup></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>Trained with Chinchilla formula.
</td></tr>
<tr>
<td>Falcon</td>
<td><span data-sort-value="000000002023-03-01-0000" style="white-space:nowrap">March 2023</span></td>
<td><a href="https://en.wikipedia.org/wiki/Technology_Innovation_Institute" title="Technology Innovation Institute">Technology Innovation Institute</a></td>
<td><span data-sort-value="40000000000&nbsp;!">40</span><sup id="cite_ref-falcon_183-0" class="reference"><a href="#cite_note-falcon-183">[177]</a></sup></td>
<td>1 trillion tokens, from RefinedWeb (filtered web text corpus)<sup id="cite_ref-Xb1gq_184-0" class="reference"><a href="#cite_note-Xb1gq-184">[178]</a></sup> plus some "curated corpora".<sup id="cite_ref-gzTNw_185-0" class="reference"><a href="#cite_note-gzTNw-185">[179]</a></sup>
</td>
<td>2800<sup id="cite_ref-:5_177-1" class="reference"><a href="#cite_note-:5-177">[173]</a></sup></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0<sup id="cite_ref-Wmlcs_186-0" class="reference"><a href="#cite_note-Wmlcs-186">[180]</a></sup>
</td>
<td>
</td></tr>
<tr>
<td>BloombergGPT</td>
<td><span data-sort-value="000000002023-03-01-0000" style="white-space:nowrap">March 2023</span></td>
<td><a href="https://en.wikipedia.org/wiki/Bloomberg_L.P." title="Bloomberg L.P.">Bloomberg L.P.</a></td>
<td><span data-sort-value="50000000000&nbsp;!">50</span></td>
<td>363 billion token dataset based on Bloomberg's data sources, plus 345 billion tokens from general purpose datasets<sup id="cite_ref-nGOSu_187-0" class="reference"><a href="#cite_note-nGOSu-187">[181]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>LLM trained on financial data from proprietary sources, that 
"outperforms existing models on financial tasks by significant margins 
without sacrificing performance on general LLM benchmarks"
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Huawei_PanGu" title="Huawei PanGu">PanGu-Σ</a></td>
<td><span data-sort-value="000000002023-03-01-0000" style="white-space:nowrap">March 2023</span></td>
<td><a href="https://en.wikipedia.org/wiki/Huawei" title="Huawei">Huawei</a></td>
<td><span data-sort-value="1085000000000&nbsp;!">1085</span></td>
<td>329 billion tokens<sup id="cite_ref-9WSFw_188-0" class="reference"><a href="#cite_note-9WSFw-188">[182]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>
</td></tr>
<tr>
<td>OpenAssistant<sup id="cite_ref-JiOl8_189-0" class="reference"><a href="#cite_note-JiOl8-189">[183]</a></sup></td>
<td><span data-sort-value="000000002023-03-01-0000" style="white-space:nowrap">March 2023</span></td>
<td><a href="https://en.wikipedia.org/wiki/LAION" title="LAION">LAION</a></td>
<td><span data-sort-value="17000000000&nbsp;!">17</span></td>
<td>1.5 trillion tokens
</td>
<td></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>Trained on crowdsourced open data
</td></tr>
<tr>
<td>Jurassic-2<sup id="cite_ref-190" class="reference"><a href="#cite_note-190">[184]</a></sup>
</td>
<td><span data-sort-value="000000002023-03-01-0000" style="white-space:nowrap">March 2023</span>
</td>
<td><a href="https://en.wikipedia.org/wiki/AI21_Labs" title="AI21 Labs">AI21 Labs</a>
</td>
<td>Unknown
</td>
<td>Unknown
</td>
<td></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Multilingual<sup id="cite_ref-191" class="reference"><a href="#cite_note-191">[185]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/PaLM" title="PaLM">PaLM 2</a> (Pathways Language Model 2)</td>
<td><span data-sort-value="000000002023-05-01-0000" style="white-space:nowrap">May 2023</span></td>
<td>Google</td>
<td><span data-sort-value="340000000000&nbsp;!">340</span><sup id="cite_ref-cnbc-20230516_192-0" class="reference"><a href="#cite_note-cnbc-20230516-192">[186]</a></sup></td>
<td><span data-sort-value="3600000000000&nbsp;!">3.6 trillion</span> tokens<sup id="cite_ref-cnbc-20230516_192-1" class="reference"><a href="#cite_note-cnbc-20230516-192">[186]</a></sup>
</td>
<td>85000<sup id="cite_ref-:5_177-2" class="reference"><a href="#cite_note-:5-177">[173]</a></sup></td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Was used in <a href="https://en.wikipedia.org/wiki/Bard_(chatbot)" class="mw-redirect" title="Bard (chatbot)">Bard chatbot</a>.<sup id="cite_ref-pWyLA_193-0" class="reference"><a href="#cite_note-pWyLA-193">[187]</a></sup>
</td></tr>
<tr>
<td>Llama 2</td>
<td><span data-sort-value="000000002023-07-01-0000" style="white-space:nowrap">July 2023</span></td>
<td>Meta</td>
<td><span data-sort-value="70000000000&nbsp;!">70</span><sup id="cite_ref-meta-20230719_194-0" class="reference"><a href="#cite_note-meta-20230719-194">[188]</a></sup></td>
<td><span data-sort-value="2000000000000&nbsp;!">2 trillion</span> tokens<sup id="cite_ref-meta-20230719_194-1" class="reference"><a href="#cite_note-meta-20230719-194">[188]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 255, 187); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #454500; --darkreader-inline-bgimage: none;" class="table-partial" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Llama 2 license
</td>
<td>Successor of LLaMA.
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Claude_(language_model)" title="Claude (language model)">Claude 2</a>
</td>
<td><span data-sort-value="000000002023-07-01-0000" style="white-space:nowrap">July 2023</span>
</td>
<td>Anthropic
</td>
<td>Unknown
</td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Used in Claude chatbot.<sup id="cite_ref-195" class="reference"><a href="#cite_note-195">[189]</a></sup>
</td></tr>
<tr>
<td>Falcon 180B</td>
<td><span data-sort-value="000000002023-09-01-0000" style="white-space:nowrap">September 2023</span></td>
<td>Technology Innovation Institute</td>
<td><span data-sort-value="180000000000&nbsp;!">180</span><sup id="cite_ref-tii-20230921_196-0" class="reference"><a href="#cite_note-tii-20230921-196">[190]</a></sup></td>
<td><span data-sort-value="3500000000000&nbsp;!">3.5 trillion</span> tokens<sup id="cite_ref-tii-20230921_196-1" class="reference"><a href="#cite_note-tii-20230921-196">[190]</a></sup>
</td>
<td></td>
<td style="background: rgb(255, 255, 187); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #454500; --darkreader-inline-bgimage: none;" class="table-partial" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Falcon 180B TII license
</td></tr>
<tr>
<td>Mistral 7B</td>
<td><span data-sort-value="000000002023-09-01-0000" style="white-space:nowrap">September 2023</span></td>
<td><a href="https://en.wikipedia.org/wiki/Mistral_AI" title="Mistral AI">Mistral AI</a></td>
<td><span data-sort-value="7300000000&nbsp;!">7.3</span><sup id="cite_ref-mistral-20230927_197-0" class="reference"><a href="#cite_note-mistral-20230927-197">[191]</a></sup></td>
<td>Unknown
</td>
<td></td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Claude_(language_model)" title="Claude (language model)">Claude 2.1</a>
</td>
<td><span data-sort-value="000000002023-11-01-0000" style="white-space:nowrap">November 2023</span>
</td>
<td>Anthropic
</td>
<td>Unknown
</td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Used in Claude chatbot. Has a context window of 200,000 tokens, or ~500 pages.<sup id="cite_ref-198" class="reference"><a href="#cite_note-198">[192]</a></sup>
</td></tr>
<tr>
<td>Grok-1<sup id="cite_ref-199" class="reference"><a href="#cite_note-199">[193]</a></sup>
</td>
<td><span data-sort-value="000000002023-11-01-0000" style="white-space:nowrap">November 2023</span>
</td>
<td><a href="https://en.wikipedia.org/wiki/X.AI" class="mw-redirect" title="X.AI">x.AI</a>
</td>
<td>314
</td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>Used in <a href="https://en.wikipedia.org/wiki/Grok_(chatbot)" title="Grok (chatbot)">Grok</a> chatbot. Grok-1 has a context length of 8,192 tokens and has access to X (Twitter).<sup id="cite_ref-200" class="reference"><a href="#cite_note-200">[194]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Gemini_(language_model)" title="Gemini (language model)">Gemini 1.0</a>
</td>
<td><span data-sort-value="000000002023-12-01-0000" style="white-space:nowrap">December 2023</span>
</td>
<td><a href="https://en.wikipedia.org/wiki/Google_DeepMind" title="Google DeepMind">Google DeepMind</a>
</td>
<td>Unknown
</td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Multimodal model, comes in three sizes. Used in <a href="https://en.wikipedia.org/wiki/Gemini_(chatbot)" title="Gemini (chatbot)">the chatbot of the same name</a>.<sup id="cite_ref-201" class="reference"><a href="#cite_note-201">[195]</a></sup>
</td></tr>
<tr>
<td>Mixtral 8x7B
</td>
<td><span data-sort-value="000000002023-12-01-0000" style="white-space:nowrap">December 2023</span>
</td>
<td><a href="https://en.wikipedia.org/wiki/Mistral_AI" title="Mistral AI">Mistral AI</a>
</td>
<td>46.7
</td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>Outperforms GPT-3.5 and Llama 2 70B on many benchmarks.<sup id="cite_ref-202" class="reference"><a href="#cite_note-202">[196]</a></sup> <a href="https://en.wikipedia.org/wiki/Mixture_of_experts" title="Mixture of experts">Mixture of experts</a> model, with 12.9 billion parameters activated per token.<sup id="cite_ref-203" class="reference"><a href="#cite_note-203">[197]</a></sup>
</td></tr>
<tr>
<td>Mixtral 8x22B
</td>
<td><span data-sort-value="000000002024-04-01-0000" style="white-space:nowrap">April 2024</span>
</td>
<td><a href="https://en.wikipedia.org/wiki/Mistral_AI" title="Mistral AI">Mistral AI</a>
</td>
<td>141
</td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td><sup id="cite_ref-204" class="reference"><a href="#cite_note-204">[198]</a></sup>
</td></tr>
<tr>
<td>Phi-2
</td>
<td><span data-sort-value="000000002023-12-01-0000" style="white-space:nowrap">December 2023</span>
</td>
<td>Microsoft
</td>
<td>2.7
</td>
<td>1.4T tokens
</td>
<td>Unknown</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">MIT
</td>
<td>So-called <i>small language model</i>, that "matches or outperforms 
models up to 25x larger", trained on "textbook-quality" data based on 
the paper "Textbooks Are All You Need". Model training took "14 days on 
96 A100 GPUs".<sup id="cite_ref-205" class="reference"><a href="#cite_note-205">[199]</a></sup>
</td></tr>
<tr>
<td>Eagle 7B
</td>
<td><span data-sort-value="000000002024-01-01-0000" style="white-space:nowrap">January 2024</span>
</td>
<td>RWKV
</td>
<td>7.52
</td>
<td>1.1T tokens
</td>
<td>Unknown</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0
</td>
<td>An "attention-free" linear transformer based on RWKV-v5 architecture.<sup id="cite_ref-206" class="reference"><a href="#cite_note-206">[200]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Gemini_(language_model)" title="Gemini (language model)">Gemini 1.5</a>
</td>
<td><span data-sort-value="000000002024-02-01-0000" style="white-space:nowrap">February 2024</span>
</td>
<td><a href="https://en.wikipedia.org/wiki/Google_DeepMind" title="Google DeepMind">Google DeepMind</a>
</td>
<td>Unknown
</td>
<td>Unknown
</td>
<td>Unknown</td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Multimodal model, based on a Mixture-of-Experts (MoE) architecture. 
Context window increased to 1 million tokens, though only 128k will be 
available for developers.<sup id="cite_ref-207" class="reference"><a href="#cite_note-207">[201]</a></sup>
</td></tr>
<tr>
<td>Gemma</td>
<td><span data-sort-value="000000002024-02-01-0000" style="white-space:nowrap">February 2024</span></td>
<td><a href="https://en.wikipedia.org/wiki/Google_DeepMind" title="Google DeepMind">Google DeepMind</a></td>
<td>7</td>
<td>6T tokens</td>
<td>Unknown</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Apache 2.0<sup id="cite_ref-gemma_208-0" class="reference"><a href="#cite_note-gemma-208">[202]</a></sup></td>
<td>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Claude_(language_model)" title="Claude (language model)">Claude 3</a>
</td>
<td>March 2024
</td>
<td>Anthropic
</td>
<td>Unknown
</td>
<td>Unknown
</td>
<td>Unknown
</td>
<td style="background: rgb(255, 199, 199); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #550000; --darkreader-inline-bgimage: none;" class="table-no" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Proprietary
</td>
<td>Includes three models, Haiku, Sonnet, and Opus.<sup id="cite_ref-209" class="reference"><a href="#cite_note-209">[203]</a></sup>
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/DBRX" title="DBRX">DBRX</a>
</td>
<td>March 2024
</td>
<td><a href="https://en.wikipedia.org/wiki/Databricks" title="Databricks">Databricks</a> and <a href="https://en.wikipedia.org/wiki/Mosaic_ML" class="mw-redirect" title="Mosaic ML">Mosaic ML</a>
</td>
<td><span data-sort-value="13600000000&nbsp;!">136</span>
</td>
<td>12T Tokens
</td>
<td>
</td>
<td style="background: rgb(158, 255, 158); vertical-align: middle; text-align: center; --darkreader-inline-bgcolor: #1b6d00; --darkreader-inline-bgimage: none;" class="table-yes" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="">Databricks Open Model License
</td>
<td>Training cost 10 million USD.
</td></tr></tbody><tfoot></tfoot></table>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=34" title="Edit section: See also"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Foundation_models" class="mw-redirect" title="Foundation models">Foundation models</a></li></ul>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=35" title="Edit section: Notes"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1217336898">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><style class="darkreader darkreader--sync" media="screen"></style><div class="reflist reflist-lower-alpha">
<div class="mw-references-wrap"><ol class="references">
<li id="cite_note-123"><span class="mw-cite-backlink"><b><a href="#cite_ref-123" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">This is the date that documentation describing the model's architecture was first released.</span>
</li>
<li id="cite_note-124"><span class="mw-cite-backlink"><b><a href="#cite_ref-124" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">In
 many cases, researchers release or report on multiple versions of a 
model having different sizes. In these cases, the size of the largest 
model is listed here.</span>
</li>
<li id="cite_note-125"><span class="mw-cite-backlink"><b><a href="#cite_ref-125" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">This
 is the license of the pre-trained model weights. In almost all cases 
the training code itself is open-source or can be easily replicated.</span>
</li>
<li id="cite_note-166"><span class="mw-cite-backlink"><b><a href="#cite_ref-166" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">The smaller models including 66B are publicly available, while the 175B model is available on request.</span>
</li>
<li id="cite_note-178"><span class="mw-cite-backlink"><b><a href="#cite_ref-178" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">Facebook's
 license and distribution scheme restricted access to approved 
researchers, but the model weights were leaked and became widely 
available.</span>
</li>
<li id="cite_note-181"><span class="mw-cite-backlink"><b><a href="#cite_ref-181" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">As
 stated in Technical report: "Given both the competitive landscape and 
the safety implications of large-scale models like GPT-4, this report 
contains no further details about the architecture (including model 
size), hardware, training compute, dataset construction, training method
 ..."<sup id="cite_ref-GPT4Tech_180-0" class="reference"><a href="#cite_note-GPT4Tech-180">[175]</a></sup> </span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=36" title="Edit section: References"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1217336898"><div class="reflist">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-:7-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-:7_1-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1215172403">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a{background-size:contain}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a{background-size:contain}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a{background-size:contain}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#2C882D;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911F}html.skin-theme-clientpref-night .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-night .mw-parser-output .cs1-hidden-error{color:#f8a397}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-os .mw-parser-output .cs1-hidden-error{color:#f8a397}html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911F}}</style><style class="darkreader darkreader--sync" media="screen"></style><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://openai.com/blog/better-language-models/">"Better Language Models and Their Implications"</a>. <i>OpenAI</i>. 2019-02-14. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20201219132206/https://openai.com/blog/better-language-models/">Archived</a> from the original on 2020-12-19<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-08-25</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=OpenAI&amp;rft.atitle=Better+Language+Models+and+Their+Implications&amp;rft.date=2019-02-14&amp;rft_id=https%3A%2F%2Fopenai.com%2Fblog%2Fbetter-language-models%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Bowman-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-Bowman_2-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Bowman_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBowman2023" class="citation arxiv cs1">Bowman, Samuel R. (2023). "Eight Things to Know about Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2304.00612">2304.00612</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Eight+Things+to+Know+about+Large+Language+Models&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2304.00612&amp;rft.aulast=Bowman&amp;rft.aufirst=Samuel+R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPengAlcaideAnthonyAlbalak2023" class="citation arxiv cs1">Peng, Bo; et&nbsp;al. (2023). "RWKV: Reinventing RNNS for the Transformer Era". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.13048">2305.13048</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=RWKV%3A+Reinventing+RNNS+for+the+Transformer+Era&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2305.13048&amp;rft.aulast=Peng&amp;rft.aufirst=Bo&amp;rft.au=Alcaide%2C+Eric&amp;rft.au=Anthony%2C+Quentin&amp;rft.au=Albalak%2C+Alon&amp;rft.au=Arcadinho%2C+Samuel&amp;rft.au=Biderman%2C+Stella&amp;rft.au=Cao%2C+Huanqi&amp;rft.au=Cheng%2C+Xin&amp;rft.au=Chung%2C+Michael&amp;rft.au=Grella%2C+Matteo&amp;rft.au=Kranthi+Kiran+GV&amp;rft.au=He%2C+Xuzheng&amp;rft.au=Hou%2C+Haowen&amp;rft.au=Lin%2C+Jiaju&amp;rft.au=Kazienko%2C+Przemyslaw&amp;rft.au=Kocon%2C+Jan&amp;rft.au=Kong%2C+Jiaming&amp;rft.au=Koptyra%2C+Bartlomiej&amp;rft.au=Lau%2C+Hayden&amp;rft.au=Krishna+Sri+Ipsit+Mantri&amp;rft.au=Mom%2C+Ferdinand&amp;rft.au=Saito%2C+Atsushi&amp;rft.au=Song%2C+Guangyu&amp;rft.au=Tang%2C+Xiangru&amp;rft.au=Wang%2C+Bolun&amp;rft.au=Wind%2C+Johan+S.&amp;rft.au=Wozniak%2C+Stanislaw&amp;rft.au=Zhang%2C+Ruichong&amp;rft.au=Zhang%2C+Zhenyuan&amp;rft.au=Zhao%2C+Qihang&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMerritt2022" class="citation web cs1">Merritt, Rick (2022-03-25). <a rel="nofollow" class="external text" href="https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/">"What Is a Transformer Model?"</a>. <i>NVIDIA Blog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-07-25</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=NVIDIA+Blog&amp;rft.atitle=What+Is+a+Transformer+Model%3F&amp;rft.date=2022-03-25&amp;rft.aulast=Merritt&amp;rft.aufirst=Rick&amp;rft_id=https%3A%2F%2Fblogs.nvidia.com%2Fblog%2F2022%2F03%2F25%2Fwhat-is-a-transformer-model%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFGuDao2023" class="citation cs2">Gu, Albert; Dao, Tri (2023-12-01), <i>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</i>, <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2312.00752">2312.00752</a></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mamba%3A+Linear-Time+Sequence+Modeling+with+Selective+State+Spaces&amp;rft.date=2023-12-01&amp;rft_id=info%3Aarxiv%2F2312.00752&amp;rft.aulast=Gu&amp;rft.aufirst=Albert&amp;rft.au=Dao%2C+Tri&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-few-shot-learners-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-few-shot-learners_6-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-few-shot-learners_6-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-few-shot-learners_6-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBrownMannRyderSubbiah2020" class="citation journal cs1">Brown,
 Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; 
Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; 
Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, 
Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel 
M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; 
Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, 
Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, 
Ilya; Amodei, Dario (Dec 2020). Larochelle, H.; Ranzato, M.; Hadsell, 
R.; Balcan, M.F.; Lin, H. (eds.). <a rel="nofollow" class="external text" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf">"Language Models are Few-Shot Learners"</a> <span class="cs1-format">(PDF)</span>. <i>Advances in Neural Information Processing Systems</i>. <b>33</b>. Curran Associates, Inc.: 1877–1901.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Language+Models+are+Few-Shot+Learners&amp;rft.volume=33&amp;rft.pages=1877-1901&amp;rft.date=2020-12&amp;rft.aulast=Brown&amp;rft.aufirst=Tom+B.&amp;rft.au=Mann%2C+Benjamin&amp;rft.au=Ryder%2C+Nick&amp;rft.au=Subbiah%2C+Melanie&amp;rft.au=Kaplan%2C+Jared&amp;rft.au=Dhariwal%2C+Prafulla&amp;rft.au=Neelakantan%2C+Arvind&amp;rft.au=Shyam%2C+Pranav&amp;rft.au=Sastry%2C+Girish&amp;rft.au=Askell%2C+Amanda&amp;rft.au=Agarwal%2C+Sandhini&amp;rft.au=Herbert-Voss%2C+Ariel&amp;rft.au=Krueger%2C+Gretchen&amp;rft.au=Henighan%2C+Tom&amp;rft.au=Child%2C+Rewon&amp;rft.au=Ramesh%2C+Aditya&amp;rft.au=Ziegler%2C+Daniel+M.&amp;rft.au=Wu%2C+Jeffrey&amp;rft.au=Winter%2C+Clemens&amp;rft.au=Hesse%2C+Christopher&amp;rft.au=Chen%2C+Mark&amp;rft.au=Sigler%2C+Eric&amp;rft.au=Litwin%2C+Mateusz&amp;rft.au=Gray%2C+Scott&amp;rft.au=Chess%2C+Benjamin&amp;rft.au=Clark%2C+Jack&amp;rft.au=Berner%2C+Christopher&amp;rft.au=McCandlish%2C+Sam&amp;rft.au=Radford%2C+Alec&amp;rft.au=Sutskever%2C+Ilya&amp;rft.au=Amodei%2C+Dario&amp;rft_id=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2020%2Ffile%2F1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Manning-2022-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-Manning-2022_7-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Manning-2022_7-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFManning2022" class="citation journal cs1"><a href="https://en.wikipedia.org/wiki/Christopher_D._Manning" title="Christopher D. Manning">Manning, Christopher D.</a> (2022). <a rel="nofollow" class="external text" href="https://www.amacad.org/publication/human-language-understanding-reasoning">"Human Language Understanding &amp; Reasoning"</a>. <i>Daedalus</i>. <b>151</b> (2): 127–138. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fdaed_a_01905">10.1162/daed_a_01905</a></span>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:248377870">248377870</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Daedalus&amp;rft.atitle=Human+Language+Understanding+%26+Reasoning&amp;rft.volume=151&amp;rft.issue=2&amp;rft.pages=127-138&amp;rft.date=2022&amp;rft_id=info%3Adoi%2F10.1162%2Fdaed_a_01905&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A248377870%23id-name%3DS2CID&amp;rft.aulast=Manning&amp;rft.aufirst=Christopher+D.&amp;rft_id=https%3A%2F%2Fwww.amacad.org%2Fpublication%2Fhuman-language-understanding-reasoning&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFVaswaniShazeerParmarUszkoreit2017" class="citation journal cs1"><a href="https://en.wikipedia.org/wiki/Ashish_Vaswani" title="Ashish Vaswani">Vaswani, Ashish</a>; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; <a href="https://en.wikipedia.org/wiki/Aidan_Gomez" title="Aidan Gomez">Gomez, Aidan N</a>; Kaiser, Łukasz; Polosukhin, Illia (2017). <a rel="nofollow" class="external text" href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">"Attention is All you Need"</a> <span class="cs1-format">(PDF)</span>. <i>Advances in Neural Information Processing Systems</i>. <b>30</b>. Curran Associates, Inc.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Attention+is+All+you+Need&amp;rft.volume=30&amp;rft.date=2017&amp;rft.aulast=Vaswani&amp;rft.aufirst=Ashish&amp;rft.au=Shazeer%2C+Noam&amp;rft.au=Parmar%2C+Niki&amp;rft.au=Uszkoreit%2C+Jakob&amp;rft.au=Jones%2C+Llion&amp;rft.au=Gomez%2C+Aidan+N&amp;rft.au=Kaiser%2C+%C5%81ukasz&amp;rft.au=Polosukhin%2C+Illia&amp;rft_id=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2017%2Ffile%2F3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBahdanauChoBengio2014" class="citation arxiv cs1">Bahdanau,
 Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2014). "Neural Machine 
Translation by Jointly Learning to Align and Translate". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1409.0473">1409.0473</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Neural+Machine+Translation+by+Jointly+Learning+to+Align+and+Translate&amp;rft.date=2014&amp;rft_id=info%3Aarxiv%2F1409.0473&amp;rft.aulast=Bahdanau&amp;rft.aufirst=Dzmitry&amp;rft.au=Cho%2C+Kyunghyun&amp;rft.au=Bengio%2C+Yoshua&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFRogersKovalevaRumshisky2020" class="citation journal cs1">Rogers, Anna; Kovaleva, Olga; Rumshisky, Anna (2020). <a rel="nofollow" class="external text" href="https://aclanthology.org/2020.tacl-1.54">"A Primer in BERTology: What We Know About How BERT Works"</a>. <i>Transactions of the Association for Computational Linguistics</i>. <b>8</b>: 842–866. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2002.12327">2002.12327</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Ftacl_a_00349">10.1162/tacl_a_00349</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:211532403">211532403</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Transactions+of+the+Association+for+Computational+Linguistics&amp;rft.atitle=A+Primer+in+BERTology%3A+What+We+Know+About+How+BERT+Works&amp;rft.volume=8&amp;rft.pages=842-866&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F2002.12327&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A211532403%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1162%2Ftacl_a_00349&amp;rft.aulast=Rogers&amp;rft.aufirst=Anna&amp;rft.au=Kovaleva%2C+Olga&amp;rft.au=Rumshisky%2C+Anna&amp;rft_id=https%3A%2F%2Faclanthology.org%2F2020.tacl-1.54&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHern2019" class="citation web cs1">Hern, Alex (14 February 2019). <a rel="nofollow" class="external text" href="https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction">"New AI fake text generator may be too dangerous to release, say creators"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Guardian" title="The Guardian">The Guardian</a></i><span class="reference-accessdate">. Retrieved <span class="nowrap">20 January</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Guardian&amp;rft.atitle=New+AI+fake+text+generator+may+be+too+dangerous+to+release%2C+say+creators&amp;rft.date=2019-02-14&amp;rft.aulast=Hern&amp;rft.aufirst=Alex&amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2019%2Ffeb%2F14%2Felon-musk-backed-ai-writes-convincing-news-fiction&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.euronews.com/next/2023/11/30/chatgpt-a-year-on-3-ways-the-ai-chatbot-has-completely-changed-the-world-in-12-months">"ChatGPT a year on: 3 ways the AI chatbot has completely changed the world in 12 months"</a>. <a href="https://en.wikipedia.org/wiki/Euronews" title="Euronews">Euronews</a>. November 30, 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">January 20,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=ChatGPT+a+year+on%3A+3+ways+the+AI+chatbot+has+completely+changed+the+world+in+12+months&amp;rft.pub=Euronews&amp;rft.date=2023-11-30&amp;rft_id=https%3A%2F%2Fwww.euronews.com%2Fnext%2F2023%2F11%2F30%2Fchatgpt-a-year-on-3-ways-the-ai-chatbot-has-completely-changed-the-world-in-12-months&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHeaven2023" class="citation web cs1">Heaven, Will (March 14, 2023). <a rel="nofollow" class="external text" href="https://www.technologyreview.com/2023/03/14/1069823/gpt-4-is-bigger-and-better-chatgpt-openai/">"GPT-4 is bigger and better than ChatGPT—but OpenAI won't say why"</a>. <a href="https://en.wikipedia.org/wiki/MIT_Technology_Review" title="MIT Technology Review">MIT Technology Review</a><span class="reference-accessdate">. Retrieved <span class="nowrap">January 20,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=GPT-4+is+bigger+and+better+than+ChatGPT%E2%80%94but+OpenAI+won%27t+say+why&amp;rft.pub=MIT+Technology+Review&amp;rft.date=2023-03-14&amp;rft.aulast=Heaven&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2F2023%2F03%2F14%2F1069823%2Fgpt-4-is-bigger-and-better-chatgpt-openai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://ourworldindata.org/grapher/artificial-intelligence-parameter-count?time=2017-09-05..latest">"Parameters in notable artificial intelligence systems"</a>. <i>ourworldindata.org</i>. November 30, 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">January 20,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ourworldindata.org&amp;rft.atitle=Parameters+in+notable+artificial+intelligence+systems&amp;rft.date=2023-11-30&amp;rft_id=https%3A%2F%2Fourworldindata.org%2Fgrapher%2Fartificial-intelligence-parameter-count%3Ftime%3D2017-09-05..latest&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://analyticsindiamag.com/googles-gemini-pro-beats-gpt-4/">"Google's Gemini Pro Beats GPT-4"</a>. <i>analyticsindiamag.com</i>. January 27, 2024<span class="reference-accessdate">. Retrieved <span class="nowrap">January 29,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=analyticsindiamag.com&amp;rft.atitle=Google%27s+Gemini+Pro+Beats+GPT-4&amp;rft.date=2024-01-27&amp;rft_id=https%3A%2F%2Fanalyticsindiamag.com%2Fgoogles-gemini-pro-beats-gpt-4%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard">"LMSYS Chatbot Arena Leaderboard"</a>. <i>huggingface.co</i><span class="reference-accessdate">. Retrieved <span class="nowrap">January 20,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=huggingface.co&amp;rft.atitle=LMSYS+Chatbot+Arena+Leaderboard&amp;rft_id=https%3A%2F%2Fhuggingface.co%2Fspaces%2Flmsys%2Fchatbot-arena-leaderboard&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFYennie_Jun2023" class="citation web cs1">Yennie Jun (2023-05-03). <a rel="nofollow" class="external text" href="https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized">"All languages are NOT created (tokenized) equal"</a>. <i>Language models cost much more in some languages than others</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-08-17</span></span>. <q>In other words, to express the same sentiment, some languages require up to 10 times more tokens.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Language+models+cost+much+more+in+some+languages+than+others&amp;rft.atitle=All+languages+are+NOT+created+%28tokenized%29+equal&amp;rft.date=2023-05-03&amp;rft.au=Yennie+Jun&amp;rft_id=https%3A%2F%2Fblog.yenniejun.com%2Fp%2Fall-languages-are-not-created-tokenized&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPetrovMalfaTorrBibi2023" class="citation journal cs1">Petrov, Aleksandar; Malfa, Emanuele La; Torr, Philip; Bibi, Adel (June 23, 2023). <a rel="nofollow" class="external text" href="https://openreview.net/forum?id=Pj4YYuxTq9">"Language Model Tokenizers Introduce Unfairness Between Languages"</a>. <i>NeurIPS</i>. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.15425">2305.15425</a></span> – via openreview.net.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=NeurIPS&amp;rft.atitle=Language+Model+Tokenizers+Introduce+Unfairness+Between+Languages&amp;rft.date=2023-06-23&amp;rft_id=info%3Aarxiv%2F2305.15425&amp;rft.aulast=Petrov&amp;rft.aufirst=Aleksandar&amp;rft.au=Malfa%2C+Emanuele+La&amp;rft.au=Torr%2C+Philip&amp;rft.au=Bibi%2C+Adel&amp;rft_id=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DPj4YYuxTq9&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-xbiWb-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-xbiWb_19-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20230423211308/https://platform.openai.com/tokenizer">"OpenAI API"</a>. <i>platform.openai.com</i>. Archived from <a rel="nofollow" class="external text" href="https://platform.openai.com/">the original</a> on April 23, 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-04-30</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=platform.openai.com&amp;rft.atitle=OpenAI+API&amp;rft_id=https%3A%2F%2Fplatform.openai.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-2022Book_-20"><span class="mw-cite-backlink">^ <a href="#cite_ref-2022Book_20-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-2022Book_20-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPaaßGiesselbach2022" class="citation book cs1">Paaß, Gerhard; Giesselbach, Sven (2022). <a rel="nofollow" class="external text" href="https://link.springer.com/chapter/10.1007/978-3-031-23190-2_2">"Pre-trained Language Models"</a>. <i>Foundation Models for Natural Language Processing</i>. Artificial Intelligence: Foundations, Theory, and Algorithms. pp.&nbsp;19–78. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-031-23190-2_2">10.1007/978-3-031-23190-2_2</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9783031231902" title="Special:BookSources/9783031231902"><bdi>9783031231902</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">3 August</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Pre-trained+Language+Models&amp;rft.btitle=Foundation+Models+for+Natural+Language+Processing&amp;rft.series=Artificial+Intelligence%3A+Foundations%2C+Theory%2C+and+Algorithms&amp;rft.pages=19-78&amp;rft.date=2022&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-031-23190-2_2&amp;rft.isbn=9783031231902&amp;rft.aulast=Paa%C3%9F&amp;rft.aufirst=Gerhard&amp;rft.au=Giesselbach%2C+Sven&amp;rft_id=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-031-23190-2_2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPetrovEmanuele_La_MalfaTorrBibi2023" class="citation arxiv cs1">Petrov,
 Aleksandar; Emanuele La Malfa; Torr, Philip H. S.; Bibi, Adel (2023). 
"Language Model Tokenizers Introduce Unfairness Between Languages". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.15425">2305.15425</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Language+Model+Tokenizers+Introduce+Unfairness+Between+Languages&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2305.15425&amp;rft.aulast=Petrov&amp;rft.aufirst=Aleksandar&amp;rft.au=Emanuele+La+Malfa&amp;rft.au=Torr%2C+Philip+H.+S.&amp;rft.au=Bibi%2C+Adel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-aYNg4-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-aYNg4_22-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDodgeSapMarasovićAgnew2021" class="citation arxiv cs1">Dodge,
 Jesse; Sap, Maarten; Marasović, Ana; Agnew, William; Ilharco, Gabriel; 
Groeneveld, Dirk; Mitchell, Margaret; Gardner, Matt (2021). "Documenting
 Large Webtext Corpora: A Case Study on the Colossal Clean Crawled 
Corpus". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2104.08758">2104.08758</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Documenting+Large+Webtext+Corpora%3A+A+Case+Study+on+the+Colossal+Clean+Crawled+Corpus&amp;rft.date=2021&amp;rft_id=info%3Aarxiv%2F2104.08758&amp;rft.aulast=Dodge&amp;rft.aufirst=Jesse&amp;rft.au=Sap%2C+Maarten&amp;rft.au=Marasovi%C4%87%2C+Ana&amp;rft.au=Agnew%2C+William&amp;rft.au=Ilharco%2C+Gabriel&amp;rft.au=Groeneveld%2C+Dirk&amp;rft.au=Mitchell%2C+Margaret&amp;rft.au=Gardner%2C+Matt&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLeeIppolitoNystromZhang2022" class="citation journal cs1 cs1-prop-long-vol">Lee,
 Katherine; Ippolito, Daphne; Nystrom, Andrew; Zhang, Chiyuan; Eck, 
Douglas; Callison-Burch, Chris; Carlini, Nicholas (May 2022). <a rel="nofollow" class="external text" href="https://aclanthology.org/2022.acl-long.577.pdf">"Deduplicating Training Data Makes Language Models Better"</a> <span class="cs1-format">(PDF)</span>. <i>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</i>. 1: Long Papers: 8424–8445. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.18653%2Fv1%2F2022.acl-long.577">10.18653/v1/2022.acl-long.577</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+60th+Annual+Meeting+of+the+Association+for+Computational+Linguistics&amp;rft.atitle=Deduplicating+Training+Data+Makes+Language+Models+Better&amp;rft.volume=1%3A+Long+Papers&amp;rft.pages=8424-8445&amp;rft.date=2022-05&amp;rft_id=info%3Adoi%2F10.18653%2Fv1%2F2022.acl-long.577&amp;rft.aulast=Lee&amp;rft.aufirst=Katherine&amp;rft.au=Ippolito%2C+Daphne&amp;rft.au=Nystrom%2C+Andrew&amp;rft.au=Zhang%2C+Chiyuan&amp;rft.au=Eck%2C+Douglas&amp;rft.au=Callison-Burch%2C+Chris&amp;rft.au=Carlini%2C+Nicholas&amp;rft_id=https%3A%2F%2Faclanthology.org%2F2022.acl-long.577.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLiBubeckEldanDel_Giorno2023" class="citation cs2">Li, Yuanzhi; Bubeck, Sébastien; Eldan, Ronen; Del Giorno, Allie; Gunasekar, Suriya; Lee, Yin Tat (2023-09-11), <i>Textbooks Are All You Need II: phi-1.5 technical report</i>, <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2309.05463">2309.05463</a></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Textbooks+Are+All+You+Need+II%3A+phi-1.5+technical+report&amp;rft.date=2023-09-11&amp;rft_id=info%3Aarxiv%2F2309.05463&amp;rft.aulast=Li&amp;rft.aufirst=Yuanzhi&amp;rft.au=Bubeck%2C+S%C3%A9bastien&amp;rft.au=Eldan%2C+Ronen&amp;rft.au=Del+Giorno%2C+Allie&amp;rft.au=Gunasekar%2C+Suriya&amp;rft.au=Lee%2C+Yin+Tat&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLinGouGongLiu2024" class="citation cs2">Lin, Zhenghao; Gou, Zhibin; Gong, Yeyun; Liu, Xiao; Shen, Yelong; Xu, Ruochen; Lin, Chen; Yang, Yujiu; Jiao, Jian (2024-04-11), <a rel="nofollow" class="external text" href="http://arxiv.org/abs/2404.07965"><i>Rho-1: Not All Tokens Are What You Need</i></a>, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.48550%2FarXiv.2404.07965">10.48550/arXiv.2404.07965</a><span class="reference-accessdate">, retrieved <span class="nowrap">2024-05-05</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Rho-1%3A+Not+All+Tokens+Are+What+You+Need&amp;rft.date=2024-04-11&amp;rft_id=info%3Adoi%2F10.48550%2FarXiv.2404.07965&amp;rft.aulast=Lin&amp;rft.aufirst=Zhenghao&amp;rft.au=Gou%2C+Zhibin&amp;rft.au=Gong%2C+Yeyun&amp;rft.au=Liu%2C+Xiao&amp;rft.au=Shen%2C+Yelong&amp;rft.au=Xu%2C+Ruochen&amp;rft.au=Lin%2C+Chen&amp;rft.au=Yang%2C+Yujiu&amp;rft.au=Jiao%2C+Jian&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2404.07965&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-qbFw1-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-qbFw1_26-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBrownMannRyderSubbiah2020" class="citation arxiv cs1">Brown, Tom B.; et&nbsp;al. (2020). "Language Models are Few-Shot Learners". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2005.14165">2005.14165</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Language+Models+are+Few-Shot+Learners&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F2005.14165&amp;rft.aulast=Brown&amp;rft.aufirst=Tom+B.&amp;rft.au=Mann%2C+Benjamin&amp;rft.au=Ryder%2C+Nick&amp;rft.au=Subbiah%2C+Melanie&amp;rft.au=Kaplan%2C+Jared&amp;rft.au=Dhariwal%2C+Prafulla&amp;rft.au=Neelakantan%2C+Arvind&amp;rft.au=Shyam%2C+Pranav&amp;rft.au=Sastry%2C+Girish&amp;rft.au=Askell%2C+Amanda&amp;rft.au=Agarwal%2C+Sandhini&amp;rft.au=Herbert-Voss%2C+Ariel&amp;rft.au=Krueger%2C+Gretchen&amp;rft.au=Henighan%2C+Tom&amp;rft.au=Child%2C+Rewon&amp;rft.au=Ramesh%2C+Aditya&amp;rft.au=Ziegler%2C+Daniel+M.&amp;rft.au=Wu%2C+Jeffrey&amp;rft.au=Winter%2C+Clemens&amp;rft.au=Hesse%2C+Christopher&amp;rft.au=Chen%2C+Mark&amp;rft.au=Sigler%2C+Eric&amp;rft.au=Litwin%2C+Mateusz&amp;rft.au=Gray%2C+Scott&amp;rft.au=Chess%2C+Benjamin&amp;rft.au=Clark%2C+Jack&amp;rft.au=Berner%2C+Christopher&amp;rft.au=McCandlish%2C+Sam&amp;rft.au=Radford%2C+Alec&amp;rft.au=Sutskever%2C+Ilya&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAbdinJacobsAwanAneja2024" class="citation cs2">Abdin,
 Marah; Jacobs, Sam Ade; Awan, Ammar Ahmad; Aneja, Jyoti; Awadallah, 
Ahmed; Awadalla, Hany; Bach, Nguyen; Bahree, Amit; Bakhtiari, Arash 
(2024-04-23), <a rel="nofollow" class="external text" href="http://arxiv.org/abs/2404.14219"><i>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</i></a>, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.48550%2FarXiv.2404.14219">10.48550/arXiv.2404.14219</a><span class="reference-accessdate">, retrieved <span class="nowrap">2024-05-05</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Phi-3+Technical+Report%3A+A+Highly+Capable+Language+Model+Locally+on+Your+Phone&amp;rft.date=2024-04-23&amp;rft_id=info%3Adoi%2F10.48550%2FarXiv.2404.14219&amp;rft.aulast=Abdin&amp;rft.aufirst=Marah&amp;rft.au=Jacobs%2C+Sam+Ade&amp;rft.au=Awan%2C+Ammar+Ahmad&amp;rft.au=Aneja%2C+Jyoti&amp;rft.au=Awadallah%2C+Ahmed&amp;rft.au=Awadalla%2C+Hany&amp;rft.au=Bach%2C+Nguyen&amp;rft.au=Bahree%2C+Amit&amp;rft.au=Bakhtiari%2C+Arash&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2404.14219&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-instructGPT-paper-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-instructGPT-paper_28-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFOuyangWuJiangAlmeida2022" class="citation arxiv cs1">Ouyang,
 Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll L.; 
Mishkin, Pamela; Zhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, 
Alex; Schulman, John; Hilton, Jacob; Kelton, Fraser; Miller, Luke; 
Simens, Maddie; Askell, Amanda; Welinder, Peter; Christiano, Paul; 
Leike, Jan; Lowe, Ryan (2022). "Training language models to follow 
instructions with human feedback". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2203.02155">2203.02155</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Training+language+models+to+follow+instructions+with+human+feedback&amp;rft.date=2022&amp;rft_id=info%3Aarxiv%2F2203.02155&amp;rft.aulast=Ouyang&amp;rft.aufirst=Long&amp;rft.au=Wu%2C+Jeff&amp;rft.au=Jiang%2C+Xu&amp;rft.au=Almeida%2C+Diogo&amp;rft.au=Wainwright%2C+Carroll+L.&amp;rft.au=Mishkin%2C+Pamela&amp;rft.au=Zhang%2C+Chong&amp;rft.au=Agarwal%2C+Sandhini&amp;rft.au=Slama%2C+Katarina&amp;rft.au=Ray%2C+Alex&amp;rft.au=Schulman%2C+John&amp;rft.au=Hilton%2C+Jacob&amp;rft.au=Kelton%2C+Fraser&amp;rft.au=Miller%2C+Luke&amp;rft.au=Simens%2C+Maddie&amp;rft.au=Askell%2C+Amanda&amp;rft.au=Welinder%2C+Peter&amp;rft.au=Christiano%2C+Paul&amp;rft.au=Leike%2C+Jan&amp;rft.au=Lowe%2C+Ryan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-self-instruct-paper-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-self-instruct-paper_29-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWangKordiMishraLiu2022" class="citation arxiv cs1">Wang,
 Yizhong; Kordi, Yeganeh; Mishra, Swaroop; Liu, Alisa; Smith, Noah A.; 
Khashabi, Daniel; Hajishirzi, Hannaneh (2022). "Self-Instruct: Aligning 
Language Model with Self Generated Instructions". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2212.10560">2212.10560</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Self-Instruct%3A+Aligning+Language+Model+with+Self+Generated+Instructions&amp;rft.date=2022&amp;rft_id=info%3Aarxiv%2F2212.10560&amp;rft.aulast=Wang&amp;rft.aufirst=Yizhong&amp;rft.au=Kordi%2C+Yeganeh&amp;rft.au=Mishra%2C+Swaroop&amp;rft.au=Liu%2C+Alisa&amp;rft.au=Smith%2C+Noah+A.&amp;rft.au=Khashabi%2C+Daniel&amp;rft.au=Hajishirzi%2C+Hannaneh&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-HGZCJ-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-HGZCJ_30-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFShazeerMirhoseiniMaziarzDavis2017" class="citation arxiv cs1">Shazeer,
 Noam; Mirhoseini, Azalia; Maziarz, Krzysztof; Davis, Andy; Le, Quoc; 
Hinton, Geoffrey; Dean, Jeff (2017-01-01). "Outrageously Large Neural 
Networks: The Sparsely-Gated Mixture-of-Experts Layer". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1701.06538">1701.06538</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Outrageously+Large+Neural+Networks%3A+The+Sparsely-Gated+Mixture-of-Experts+Layer&amp;rft.date=2017-01-01&amp;rft_id=info%3Aarxiv%2F1701.06538&amp;rft.aulast=Shazeer&amp;rft.aufirst=Noam&amp;rft.au=Mirhoseini%2C+Azalia&amp;rft.au=Maziarz%2C+Krzysztof&amp;rft.au=Davis%2C+Andy&amp;rft.au=Le%2C+Quoc&amp;rft.au=Hinton%2C+Geoffrey&amp;rft.au=Dean%2C+Jeff&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-R9Qq5-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-R9Qq5_31-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLepikhinLeeXuChen2021" class="citation arxiv cs1">Lepikhin,
 Dmitry; Lee, HyoukJoong; Xu, Yuanzhong; Chen, Dehao; Firat, Orhan; 
Huang, Yanping; Krikun, Maxim; Shazeer, Noam; Chen, Zhifeng 
(2021-01-12). "GShard: Scaling Giant Models with Conditional Computation
 and Automatic Sharding". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2006.16668">2006.16668</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=GShard%3A+Scaling+Giant+Models+with+Conditional+Computation+and+Automatic+Sharding&amp;rft.date=2021-01-12&amp;rft_id=info%3Aarxiv%2F2006.16668&amp;rft.aulast=Lepikhin&amp;rft.aufirst=Dmitry&amp;rft.au=Lee%2C+HyoukJoong&amp;rft.au=Xu%2C+Yuanzhong&amp;rft.au=Chen%2C+Dehao&amp;rft.au=Firat%2C+Orhan&amp;rft.au=Huang%2C+Yanping&amp;rft.au=Krikun%2C+Maxim&amp;rft.au=Shazeer%2C+Noam&amp;rft.au=Chen%2C+Zhifeng&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-glam-blog-32"><span class="mw-cite-backlink">^ <a href="#cite_ref-glam-blog_32-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-glam-blog_32-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-glam-blog_32-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-glam-blog_32-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDaiDu2021" class="citation web cs1">Dai, Andrew M; Du, Nan (December 9, 2021). <a rel="nofollow" class="external text" href="https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html">"More Efficient In-Context Learning with GLaM"</a>. <i>ai.googleblog.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-03-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.googleblog.com&amp;rft.atitle=More+Efficient+In-Context+Learning+with+GLaM&amp;rft.date=2021-12-09&amp;rft.aulast=Dai&amp;rft.aufirst=Andrew+M&amp;rft.au=Du%2C+Nan&amp;rft_id=https%3A%2F%2Fai.googleblog.com%2F2021%2F12%2Fmore-efficient-in-context-learning-with.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-emergentpaper-33"><span class="mw-cite-backlink">^ <a href="#cite_ref-emergentpaper_33-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-emergentpaper_33-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-emergentpaper_33-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWeiTayBommasaniRaffel2022" class="citation journal cs1">Wei,
 Jason; Tay, Yi; Bommasani, Rishi; Raffel, Colin; Zoph, Barret; 
Borgeaud, Sebastian; Yogatama, Dani; Bosma, Maarten; Zhou, Denny; 
Metzler, Donald; Chi, Ed H.; Hashimoto, Tatsunori; Vinyals, Oriol; 
Liang, Percy; Dean, Jeff; Fedus, William (31 August 2022). <a rel="nofollow" class="external text" href="https://openreview.net/forum?id=yzkSU5zdwD">"Emergent Abilities of Large Language Models"</a>. <i>Transactions on Machine Learning Research</i>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/2835-8856">2835-8856</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Transactions+on+Machine+Learning+Research&amp;rft.atitle=Emergent+Abilities+of+Large+Language+Models&amp;rft.date=2022-08-31&amp;rft.issn=2835-8856&amp;rft.aulast=Wei&amp;rft.aufirst=Jason&amp;rft.au=Tay%2C+Yi&amp;rft.au=Bommasani%2C+Rishi&amp;rft.au=Raffel%2C+Colin&amp;rft.au=Zoph%2C+Barret&amp;rft.au=Borgeaud%2C+Sebastian&amp;rft.au=Yogatama%2C+Dani&amp;rft.au=Bosma%2C+Maarten&amp;rft.au=Zhou%2C+Denny&amp;rft.au=Metzler%2C+Donald&amp;rft.au=Chi%2C+Ed+H.&amp;rft.au=Hashimoto%2C+Tatsunori&amp;rft.au=Vinyals%2C+Oriol&amp;rft.au=Liang%2C+Percy&amp;rft.au=Dean%2C+Jeff&amp;rft.au=Fedus%2C+William&amp;rft_id=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DyzkSU5zdwD&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Jay_Allamar-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-Jay_Allamar_34-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAllamar" class="citation web cs1">Allamar, Jay. <a rel="nofollow" class="external text" href="https://jalammar.github.io/illustrated-transformer/">"Illustrated transformer"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-07-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Illustrated+transformer&amp;rft.aulast=Allamar&amp;rft.aufirst=Jay&amp;rft_id=https%3A%2F%2Fjalammar.github.io%2Fillustrated-transformer%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Jay_Allamar_GPT2-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-Jay_Allamar_GPT2_35-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAllamar" class="citation web cs1">Allamar, Jay. <a rel="nofollow" class="external text" href="https://jalammar.github.io/illustrated-gpt2/">"The Illustrated GPT-2 (Visualizing Transformer Language Models)"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-08-01</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Illustrated+GPT-2+%28Visualizing+Transformer+Language+Models%29&amp;rft.aulast=Allamar&amp;rft.aufirst=Jay&amp;rft_id=https%3A%2F%2Fjalammar.github.io%2Fillustrated-gpt2%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#context-window">"Our next-generation model: Gemini 1.5"</a>. <i>Google</i>. 15 February 2024<span class="reference-accessdate">. Retrieved <span class="nowrap">18 February</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google&amp;rft.atitle=Our+next-generation+model%3A+Gemini+1.5&amp;rft.date=2024-02-15&amp;rft_id=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-gemini-next-generation-model-february-2024%2F%23context-window&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.anthropic.com/news/claude-2-1-prompting">"Long context prompting for Claude 2.1"</a>. December 6, 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">January 20,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Long+context+prompting+for+Claude+2.1&amp;rft.date=2023-12-06&amp;rft_id=https%3A%2F%2Fwww.anthropic.com%2Fnews%2Fclaude-2-1-prompting&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-38" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://platform.openai.com/docs/guides/rate-limits">"Rate limits"</a>. <i>openai.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">January 20,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=openai.com&amp;rft.atitle=Rate+limits&amp;rft_id=https%3A%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Frate-limits&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-ioUpE-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-ioUpE_39-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZaibShengEmma_Zhang2020" class="citation book cs1">Zaib, Munazza; Sheng, Quan Z.; Emma Zhang, Wei (4 February 2020). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/338931711">"A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP"</a>. <i>Proceedings of the Australasian Computer Science Week Multiconference</i>. pp.&nbsp;1–4. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2104.10810">2104.10810</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F3373017.3373028">10.1145/3373017.3373028</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9781450376976" title="Special:BookSources/9781450376976"><bdi>9781450376976</bdi></a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:211040895">211040895</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=A+Short+Survey+of+Pre-trained+Language+Models+for+Conversational+AI-A+New+Age+in+NLP&amp;rft.btitle=Proceedings+of+the+Australasian+Computer+Science+Week+Multiconference&amp;rft.pages=1-4&amp;rft.date=2020-02-04&amp;rft_id=info%3Aarxiv%2F2104.10810&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A211040895%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1145%2F3373017.3373028&amp;rft.isbn=9781450376976&amp;rft.aulast=Zaib&amp;rft.aufirst=Munazza&amp;rft.au=Sheng%2C+Quan+Z.&amp;rft.au=Emma+Zhang%2C+Wei&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F338931711&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-jm-40"><span class="mw-cite-backlink">^ <a href="#cite_ref-jm_40-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-jm_40-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-jm_40-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFJurafskyMartin2023" class="citation book cs1">Jurafsky, Dan; Martin, James H. (7 January 2023). <a rel="nofollow" class="external text" href="https://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf"><i>Speech and Language Processing</i></a> <span class="cs1-format">(PDF)</span> (3rd edition draft&nbsp;ed.)<span class="reference-accessdate">. Retrieved <span class="nowrap">24 May</span> 2022</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Speech+and+Language+Processing&amp;rft.edition=3rd+edition+draft&amp;rft.date=2023-01-07&amp;rft.aulast=Jurafsky&amp;rft.aufirst=Dan&amp;rft.au=Martin%2C+James+H.&amp;rft_id=https%3A%2F%2Fweb.stanford.edu%2F~jurafsky%2Fslp3%2Fed3book_jan72023.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Wiggers-41"><span class="mw-cite-backlink">^ <a href="#cite_ref-Wiggers_41-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Wiggers_41-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWiggers2022" class="citation web cs1">Wiggers, Kyle (28 April 2022). <a rel="nofollow" class="external text" href="https://techcrunch.com/2022/04/28/the-emerging-types-of-language-models-and-why-they-matter/">"The emerging types of language models and why they matter"</a>. <i>TechCrunch</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=TechCrunch&amp;rft.atitle=The+emerging+types+of+language+models+and+why+they+matter&amp;rft.date=2022-04-28&amp;rft.aulast=Wiggers&amp;rft.aufirst=Kyle&amp;rft_id=https%3A%2F%2Ftechcrunch.com%2F2022%2F04%2F28%2Fthe-emerging-types-of-language-models-and-why-they-matter%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-xaytj-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-xaytj_42-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFSharirPelegShoham2020" class="citation arxiv cs1">Sharir, Or; Peleg, Barak; Shoham, Yoav (2020). "The Cost of Training NLP Models: A Concise Overview". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2004.08900">2004.08900</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=The+Cost+of+Training+NLP+Models%3A+A+Concise+Overview&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F2004.08900&amp;rft.aulast=Sharir&amp;rft.aufirst=Or&amp;rft.au=Peleg%2C+Barak&amp;rft.au=Shoham%2C+Yoav&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Pythia-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-Pythia_43-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBidermanSchoelkopfAnthonyBradley2023" class="citation arxiv cs1">Biderman,
 Stella; Schoelkopf, Hailey; Anthony, Quentin; Bradley, Herbie; Khan, 
Mohammad Aflah; Purohit, Shivanshu; Prashanth, USVSN Sai (April 2023). 
"Pythia: A Suite for Analyzing Large Language Models Across Training and
 Scaling". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2304.01373">2304.01373</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Pythia%3A+A+Suite+for+Analyzing+Large+Language+Models+Across+Training+and+Scaling&amp;rft.date=2023-04&amp;rft_id=info%3Aarxiv%2F2304.01373&amp;rft.aulast=Biderman&amp;rft.aufirst=Stella&amp;rft.au=Schoelkopf%2C+Hailey&amp;rft.au=Anthony%2C+Quentin&amp;rft.au=Bradley%2C+Herbie&amp;rft.au=Khan%2C+Mohammad+Aflah&amp;rft.au=Purohit%2C+Shivanshu&amp;rft.au=Prashanth%2C+USVSN+Sai&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMaslejFattoriniBrynjolfssonEtchemendy2023" class="citation cs2">Maslej,
 Nestor; Fattorini, Loredana; Brynjolfsson, Erik; Etchemendy, John; 
Ligett, Katrina; Lyons, Terah; Manyika, James; Ngo, Helen; Niebles, Juan
 Carlos (2023-10-05), <a rel="nofollow" class="external text" href="http://arxiv.org/abs/2310.03715"><i>Artificial Intelligence Index Report 2023</i></a>, <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2310.03715">2310.03715</a></span><span class="reference-accessdate">, retrieved <span class="nowrap">2024-03-12</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence+Index+Report+2023&amp;rft.date=2023-10-05&amp;rft_id=info%3Aarxiv%2F2310.03715&amp;rft.aulast=Maslej&amp;rft.aufirst=Nestor&amp;rft.au=Fattorini%2C+Loredana&amp;rft.au=Brynjolfsson%2C+Erik&amp;rft.au=Etchemendy%2C+John&amp;rft.au=Ligett%2C+Katrina&amp;rft.au=Lyons%2C+Terah&amp;rft.au=Manyika%2C+James&amp;rft.au=Ngo%2C+Helen&amp;rft.au=Niebles%2C+Juan+Carlos&amp;rft_id=http%3A%2F%2Farxiv.org%2Fabs%2F2310.03715&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-kaplan-scaling-45"><span class="mw-cite-backlink">^ <a href="#cite_ref-kaplan-scaling_45-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-kaplan-scaling_45-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Section 2.1 and Table 1,

<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKaplanMcCandlishHenighanBrown2020" class="citation arxiv cs1">Kaplan,
 Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; 
Child, Rewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario 
(2020). "Scaling Laws for Neural Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2001.08361">2001.08361</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Scaling+Laws+for+Neural+Language+Models&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F2001.08361&amp;rft.aulast=Kaplan&amp;rft.aufirst=Jared&amp;rft.au=McCandlish%2C+Sam&amp;rft.au=Henighan%2C+Tom&amp;rft.au=Brown%2C+Tom+B.&amp;rft.au=Chess%2C+Benjamin&amp;rft.au=Child%2C+Rewon&amp;rft.au=Gray%2C+Scott&amp;rft.au=Radford%2C+Alec&amp;rft.au=Wu%2C+Jeffrey&amp;rft.au=Amodei%2C+Dario&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-PI1fW-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-PI1fW_46-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFGaoMadaanZhouAlon2022" class="citation arxiv cs1">Gao,
 Luyu; Madaan, Aman; Zhou, Shuyan; Alon, Uri; Liu, Pengfei; Yang, 
Yiming; Callan, Jamie; Neubig, Graham (2022-11-01). "PAL: Program-aided 
Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2211.10435">2211.10435</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=PAL%3A+Program-aided+Language+Models&amp;rft.date=2022-11-01&amp;rft_id=info%3Aarxiv%2F2211.10435&amp;rft.aulast=Gao&amp;rft.aufirst=Luyu&amp;rft.au=Madaan%2C+Aman&amp;rft.au=Zhou%2C+Shuyan&amp;rft.au=Alon%2C+Uri&amp;rft.au=Liu%2C+Pengfei&amp;rft.au=Yang%2C+Yiming&amp;rft.au=Callan%2C+Jamie&amp;rft.au=Neubig%2C+Graham&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-J5OW5-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-J5OW5_47-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://reasonwithpal.com/">"PAL: Program-aided Language Models"</a>. <i>reasonwithpal.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-12</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=reasonwithpal.com&amp;rft.atitle=PAL%3A+Program-aided+Language+Models&amp;rft_id=https%3A%2F%2Freasonwithpal.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-gQxzq-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-gQxzq_48-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFParanjapeLundbergSinghHajishirzi2023" class="citation arxiv cs1">Paranjape,
 Bhargavi; Lundberg, Scott; Singh, Sameer; Hajishirzi, Hannaneh; 
Zettlemoyer, Luke; Tulio Ribeiro, Marco (2023-03-01). "ART: Automatic 
multi-step reasoning and tool-use for large language models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.09014">2303.09014</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=ART%3A+Automatic+multi-step+reasoning+and+tool-use+for+large+language+models&amp;rft.date=2023-03-01&amp;rft_id=info%3Aarxiv%2F2303.09014&amp;rft.aulast=Paranjape&amp;rft.aufirst=Bhargavi&amp;rft.au=Lundberg%2C+Scott&amp;rft.au=Singh%2C+Sameer&amp;rft.au=Hajishirzi%2C+Hannaneh&amp;rft.au=Zettlemoyer%2C+Luke&amp;rft.au=Tulio+Ribeiro%2C+Marco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-lLrda-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-lLrda_49-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLiangWuSongWu2023" class="citation arxiv cs1">Liang,
 Yaobo; Wu, Chenfei; Song, Ting; Wu, Wenshan; Xia, Yan; Liu, Yu; Ou, 
Yang; Lu, Shuai; Ji, Lei; Mao, Shaoguang; Wang, Yun; Shou, Linjun; Gong,
 Ming; Duan, Nan (2023-03-01). "TaskMatrix.AI: Completing Tasks by 
Connecting Foundation Models with Millions of APIs". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.16434">2303.16434</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=TaskMatrix.AI%3A+Completing+Tasks+by+Connecting+Foundation+Models+with+Millions+of+APIs&amp;rft.date=2023-03-01&amp;rft_id=info%3Aarxiv%2F2303.16434&amp;rft.aulast=Liang&amp;rft.aufirst=Yaobo&amp;rft.au=Wu%2C+Chenfei&amp;rft.au=Song%2C+Ting&amp;rft.au=Wu%2C+Wenshan&amp;rft.au=Xia%2C+Yan&amp;rft.au=Liu%2C+Yu&amp;rft.au=Ou%2C+Yang&amp;rft.au=Lu%2C+Shuai&amp;rft.au=Ji%2C+Lei&amp;rft.au=Mao%2C+Shaoguang&amp;rft.au=Wang%2C+Yun&amp;rft.au=Shou%2C+Linjun&amp;rft.au=Gong%2C+Ming&amp;rft.au=Duan%2C+Nan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-4Xzrs-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-4Xzrs_50-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPatilZhangWangGonzalez2023" class="citation arxiv cs1">Patil,
 Shishir G.; Zhang, Tianjun; Wang, Xin; Gonzalez, Joseph E. 
(2023-05-01). "Gorilla: Large Language Model Connected with Massive 
APIs". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.15334">2305.15334</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Gorilla%3A+Large+Language+Model+Connected+with+Massive+APIs&amp;rft.date=2023-05-01&amp;rft_id=info%3Aarxiv%2F2305.15334&amp;rft.aulast=Patil&amp;rft.aufirst=Shishir+G.&amp;rft.au=Zhang%2C+Tianjun&amp;rft.au=Wang%2C+Xin&amp;rft.au=Gonzalez%2C+Joseph+E.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-BUZBP-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-BUZBP_51-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLewisPerezPiktusPetroni2020" class="citation journal cs1">Lewis,
 Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, 
Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; 
Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). <a rel="nofollow" class="external text" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html">"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"</a>. <i>Advances in Neural Information Processing Systems</i>. <b>33</b>. Curran Associates, Inc.: 9459–9474. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2005.11401">2005.11401</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Retrieval-Augmented+Generation+for+Knowledge-Intensive+NLP+Tasks&amp;rft.volume=33&amp;rft.pages=9459-9474&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F2005.11401&amp;rft.aulast=Lewis&amp;rft.aufirst=Patrick&amp;rft.au=Perez%2C+Ethan&amp;rft.au=Piktus%2C+Aleksandra&amp;rft.au=Petroni%2C+Fabio&amp;rft.au=Karpukhin%2C+Vladimir&amp;rft.au=Goyal%2C+Naman&amp;rft.au=K%C3%BCttler%2C+Heinrich&amp;rft.au=Lewis%2C+Mike&amp;rft.au=Yih%2C+Wen-tau&amp;rft.au=Rockt%C3%A4schel%2C+Tim&amp;rft.au=Riedel%2C+Sebastian&amp;rft.au=Kiela%2C+Douwe&amp;rft_id=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2020%2Fhash%2F6b493230205f780e1bc26945df7481e5-Abstract.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-CFuti-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-CFuti_52-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHuangAbbeelPathakMordatch2022" class="citation journal cs1">Huang, Wenlong; Abbeel, Pieter; Pathak, Deepak; Mordatch, Igor (2022-06-28). <a rel="nofollow" class="external text" href="https://proceedings.mlr.press/v162/huang22a.html">"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"</a>. <i>Proceedings of the 39th International Conference on Machine Learning</i>. PMLR: 9118–9147. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2201.07207">2201.07207</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+39th+International+Conference+on+Machine+Learning&amp;rft.atitle=Language+Models+as+Zero-Shot+Planners%3A+Extracting+Actionable+Knowledge+for+Embodied+Agents&amp;rft.pages=9118-9147&amp;rft.date=2022-06-28&amp;rft_id=info%3Aarxiv%2F2201.07207&amp;rft.aulast=Huang&amp;rft.aufirst=Wenlong&amp;rft.au=Abbeel%2C+Pieter&amp;rft.au=Pathak%2C+Deepak&amp;rft.au=Mordatch%2C+Igor&amp;rft_id=https%3A%2F%2Fproceedings.mlr.press%2Fv162%2Fhuang22a.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-DmvNE-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-DmvNE_53-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFYaoZhaoYuDu2022" class="citation arxiv cs1">Yao,
 Shunyu; Zhao, Jeffrey; Yu, Dian; Du, Nan; Shafran, Izhak; Narasimhan, 
Karthik; Cao, Yuan (2022-10-01). "ReAct: Synergizing Reasoning and 
Acting in Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2210.03629">2210.03629</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=ReAct%3A+Synergizing+Reasoning+and+Acting+in+Language+Models&amp;rft.date=2022-10-01&amp;rft_id=info%3Aarxiv%2F2210.03629&amp;rft.aulast=Yao&amp;rft.aufirst=Shunyu&amp;rft.au=Zhao%2C+Jeffrey&amp;rft.au=Yu%2C+Dian&amp;rft.au=Du%2C+Nan&amp;rft.au=Shafran%2C+Izhak&amp;rft.au=Narasimhan%2C+Karthik&amp;rft.au=Cao%2C+Yuan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-JS8Vd-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-JS8Vd_54-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWuPrabhumoyeMin2023" class="citation arxiv cs1">Wu,
 Yue; Prabhumoye, Shrimai; Min, So Yeon (24 May 2023). "SPRING: GPT-4 
Out-performs RL Algorithms by Studying Papers and Reasoning". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.15486">2305.15486</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=SPRING%3A+GPT-4+Out-performs+RL+Algorithms+by+Studying+Papers+and+Reasoning&amp;rft.date=2023-05-24&amp;rft_id=info%3Aarxiv%2F2305.15486&amp;rft.aulast=Wu&amp;rft.aufirst=Yue&amp;rft.au=Prabhumoye%2C+Shrimai&amp;rft.au=Min%2C+So+Yeon&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-55" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWangCaiLiuMa2023" class="citation arxiv cs1">Wang,
 Zihao; Cai, Shaofei; Liu, Anji; Ma, Xiaojian; Liang, Yitao 
(2023-02-03). "Describe, Explain, Plan and Select: Interactive Planning 
with Large Language Models Enables Open-World Multi-Task Agents". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2302.01560">2302.01560</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Describe%2C+Explain%2C+Plan+and+Select%3A+Interactive+Planning+with+Large+Language+Models+Enables+Open-World+Multi-Task+Agents&amp;rft.date=2023-02-03&amp;rft_id=info%3Aarxiv%2F2302.01560&amp;rft.aulast=Wang&amp;rft.aufirst=Zihao&amp;rft.au=Cai%2C+Shaofei&amp;rft.au=Liu%2C+Anji&amp;rft.au=Ma%2C+Xiaojian&amp;rft.au=Liang%2C+Yitao&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-sbB2T-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-sbB2T_56-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFShinnCassanoLabashGopinath2023" class="citation arxiv cs1">Shinn,
 Noah; Cassano, Federico; Labash, Beck; Gopinath, Ashwin; Narasimhan, 
Karthik; Yao, Shunyu (2023-03-01). "Reflexion: Language Agents with 
Verbal Reinforcement Learning". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.11366">2303.11366</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Reflexion%3A+Language+Agents+with+Verbal+Reinforcement+Learning&amp;rft.date=2023-03-01&amp;rft_id=info%3Aarxiv%2F2303.11366&amp;rft.aulast=Shinn&amp;rft.aufirst=Noah&amp;rft.au=Cassano%2C+Federico&amp;rft.au=Labash%2C+Beck&amp;rft.au=Gopinath%2C+Ashwin&amp;rft.au=Narasimhan%2C+Karthik&amp;rft.au=Yao%2C+Shunyu&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-ltTer-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-ltTer_57-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHaoGuMaJiahua_Hong2023" class="citation arxiv cs1">Hao,
 Shibo; Gu, Yi; Ma, Haodi; Jiahua Hong, Joshua; Wang, Zhen; Zhe Wang, 
Daisy; Hu, Zhiting (2023-05-01). "Reasoning with Language Model is 
Planning with World Model". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.14992">2305.14992</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Reasoning+with+Language+Model+is+Planning+with+World+Model&amp;rft.date=2023-05-01&amp;rft_id=info%3Aarxiv%2F2305.14992&amp;rft.aulast=Hao&amp;rft.aufirst=Shibo&amp;rft.au=Gu%2C+Yi&amp;rft.au=Ma%2C+Haodi&amp;rft.au=Jiahua+Hong%2C+Joshua&amp;rft.au=Wang%2C+Zhen&amp;rft.au=Zhe+Wang%2C+Daisy&amp;rft.au=Hu%2C+Zhiting&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-mBvD9-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-mBvD9_58-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZhangLehmanStanleyClune2023" class="citation arxiv cs1">Zhang,
 Jenny; Lehman, Joel; Stanley, Kenneth; Clune, Jeff (2 June 2023). 
"OMNI: Open-endedness via Models of human Notions of Interestingness". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2306.01711">2306.01711</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=OMNI%3A+Open-endedness+via+Models+of+human+Notions+of+Interestingness&amp;rft.date=2023-06-02&amp;rft_id=info%3Aarxiv%2F2306.01711&amp;rft.aulast=Zhang&amp;rft.aufirst=Jenny&amp;rft.au=Lehman%2C+Joel&amp;rft.au=Stanley%2C+Kenneth&amp;rft.au=Clune%2C+Jeff&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:0-59"><span class="mw-cite-backlink">^ <a href="#cite_ref-:0_59-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_59-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://voyager.minedojo.org/">"Voyager | An Open-Ended Embodied Agent with Large Language Models"</a>. <i>voyager.minedojo.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=voyager.minedojo.org&amp;rft.atitle=Voyager+%7C+An+Open-Ended+Embodied+Agent+with+Large+Language+Models&amp;rft_id=https%3A%2F%2Fvoyager.minedojo.org%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-XuvjF-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-XuvjF_60-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFParkO'BrienCaiRingel_Morris2023" class="citation arxiv cs1">Park,
 Joon Sung; O'Brien, Joseph C.; Cai, Carrie J.; Ringel Morris, Meredith;
 Liang, Percy; Bernstein, Michael S. (2023-04-01). "Generative Agents: 
Interactive Simulacra of Human Behavior". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2304.03442">2304.03442</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.HC">cs.HC</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Generative+Agents%3A+Interactive+Simulacra+of+Human+Behavior&amp;rft.date=2023-04-01&amp;rft_id=info%3Aarxiv%2F2304.03442&amp;rft.aulast=Park&amp;rft.aufirst=Joon+Sung&amp;rft.au=O%27Brien%2C+Joseph+C.&amp;rft.au=Cai%2C+Carrie+J.&amp;rft.au=Ringel+Morris%2C+Meredith&amp;rft.au=Liang%2C+Percy&amp;rft.au=Bernstein%2C+Michael+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-LS2Go-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-LS2Go_61-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFNagelAmjadBaalenLouizos2020" class="citation journal cs1">Nagel, Markus; Amjad, Rana Ali; Baalen, Mart Van; Louizos, Christos; Blankevoort, Tijmen (2020-11-21). <a rel="nofollow" class="external text" href="https://proceedings.mlr.press/v119/nagel20a.html">"Up or Down? Adaptive Rounding for Post-Training Quantization"</a>. <i>Proceedings of the 37th International Conference on Machine Learning</i>. PMLR: 7197–7206.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+37th+International+Conference+on+Machine+Learning&amp;rft.atitle=Up+or+Down%3F+Adaptive+Rounding+for+Post-Training+Quantization&amp;rft.pages=7197-7206&amp;rft.date=2020-11-21&amp;rft.aulast=Nagel&amp;rft.aufirst=Markus&amp;rft.au=Amjad%2C+Rana+Ali&amp;rft.au=Baalen%2C+Mart+Van&amp;rft.au=Louizos%2C+Christos&amp;rft.au=Blankevoort%2C+Tijmen&amp;rft_id=https%3A%2F%2Fproceedings.mlr.press%2Fv119%2Fnagel20a.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-cpzcK-62"><span class="mw-cite-backlink"><b><a href="#cite_ref-cpzcK_62-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPolinoPascanuAlistarh2018" class="citation arxiv cs1">Polino, Antonio; Pascanu, Razvan; Alistarh, Dan (2018-02-01). "Model compression via distillation and quantization". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1802.05668">1802.05668</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.NE">cs.NE</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Model+compression+via+distillation+and+quantization&amp;rft.date=2018-02-01&amp;rft_id=info%3Aarxiv%2F1802.05668&amp;rft.aulast=Polino&amp;rft.aufirst=Antonio&amp;rft.au=Pascanu%2C+Razvan&amp;rft.au=Alistarh%2C+Dan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-QVU95-63"><span class="mw-cite-backlink"><b><a href="#cite_ref-QVU95_63-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFFrantarAshkboosHoeflerAlistarh2022" class="citation arxiv cs1">Frantar,
 Elias; Ashkboos, Saleh; Hoefler, Torsten; Alistarh, Dan (2022-10-01). 
"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained 
Transformers". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2210.17323">2210.17323</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=GPTQ%3A+Accurate+Post-Training+Quantization+for+Generative+Pre-trained+Transformers&amp;rft.date=2022-10-01&amp;rft_id=info%3Aarxiv%2F2210.17323&amp;rft.aulast=Frantar&amp;rft.aufirst=Elias&amp;rft.au=Ashkboos%2C+Saleh&amp;rft.au=Hoefler%2C+Torsten&amp;rft.au=Alistarh%2C+Dan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-dU9Bu-64"><span class="mw-cite-backlink"><b><a href="#cite_ref-dU9Bu_64-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDettmersSvirschevskiEgiazarianKuznedelev2023" class="citation arxiv cs1">Dettmers,
 Tim; Svirschevski, Ruslan; Egiazarian, Vage; Kuznedelev, Denis; 
Frantar, Elias; Ashkboos, Saleh; Borzunov, Alexander; Hoefler, Torsten; 
Alistarh, Dan (2023-06-01). "SpQR: A Sparse-Quantized Representation for
 Near-Lossless LLM Weight Compression". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2306.03078">2306.03078</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=SpQR%3A+A+Sparse-Quantized+Representation+for+Near-Lossless+LLM+Weight+Compression&amp;rft.date=2023-06-01&amp;rft_id=info%3Aarxiv%2F2306.03078&amp;rft.aulast=Dettmers&amp;rft.aufirst=Tim&amp;rft.au=Svirschevski%2C+Ruslan&amp;rft.au=Egiazarian%2C+Vage&amp;rft.au=Kuznedelev%2C+Denis&amp;rft.au=Frantar%2C+Elias&amp;rft.au=Ashkboos%2C+Saleh&amp;rft.au=Borzunov%2C+Alexander&amp;rft.au=Hoefler%2C+Torsten&amp;rft.au=Alistarh%2C+Dan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-D0nFA-65"><span class="mw-cite-backlink"><b><a href="#cite_ref-D0nFA_65-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDettmersPagnoniHoltzmanZettlemoyer2023" class="citation arxiv cs1">Dettmers, Tim; Pagnoni, Artidoro; <a href="https://en.wikipedia.org/wiki/Ari_Holtzman" title="Ari Holtzman">Holtzman, Ari</a>; Zettlemoyer, Luke (2023-05-01). "QLoRA: Efficient Finetuning of Quantized LLMs". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.14314">2305.14314</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=QLoRA%3A+Efficient+Finetuning+of+Quantized+LLMs&amp;rft.date=2023-05-01&amp;rft_id=info%3Aarxiv%2F2305.14314&amp;rft.aulast=Dettmers&amp;rft.aufirst=Tim&amp;rft.au=Pagnoni%2C+Artidoro&amp;rft.au=Holtzman%2C+Ari&amp;rft.au=Zettlemoyer%2C+Luke&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-66"><span class="mw-cite-backlink"><b><a href="#cite_ref-66" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKirosSalakhutdinovZemel2014" class="citation journal cs1">Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Rich (2014-06-18). <a rel="nofollow" class="external text" href="https://proceedings.mlr.press/v32/kiros14.html">"Multimodal Neural Language Models"</a>. <i>Proceedings of the 31st International Conference on Machine Learning</i>. PMLR: 595–603.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+31st+International+Conference+on+Machine+Learning&amp;rft.atitle=Multimodal+Neural+Language+Models&amp;rft.pages=595-603&amp;rft.date=2014-06-18&amp;rft.aulast=Kiros&amp;rft.aufirst=Ryan&amp;rft.au=Salakhutdinov%2C+Ruslan&amp;rft.au=Zemel%2C+Rich&amp;rft_id=https%3A%2F%2Fproceedings.mlr.press%2Fv32%2Fkiros14.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-67"><span class="mw-cite-backlink"><b><a href="#cite_ref-67" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKrizhevskySutskeverHinton2012" class="citation journal cs1">Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey E (2012). <a rel="nofollow" class="external text" href="https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">"ImageNet Classification with Deep Convolutional Neural Networks"</a>. <i>Advances in Neural Information Processing Systems</i>. <b>25</b>. Curran Associates, Inc.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=ImageNet+Classification+with+Deep+Convolutional+Neural+Networks&amp;rft.volume=25&amp;rft.date=2012&amp;rft.aulast=Krizhevsky&amp;rft.aufirst=Alex&amp;rft.au=Sutskever%2C+Ilya&amp;rft.au=Hinton%2C+Geoffrey+E&amp;rft_id=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper%2F2012%2Fhash%2Fc399862d3b9d6b76c8436e924a68c45b-Abstract.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-68"><span class="mw-cite-backlink"><b><a href="#cite_ref-68" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAntolAgrawalLuMitchell2015" class="citation journal cs1">Antol, Stanislaw; Agrawal, Aishwarya; Lu, Jiasen; Mitchell, Margaret; Batra, Dhruv; Zitnick, C. Lawrence; Parikh, Devi (2015). <a rel="nofollow" class="external text" href="https://openaccess.thecvf.com/content_iccv_2015/html/Antol_VQA_Visual_Question_ICCV_2015_paper.html">"VQA: Visual Question Answering"</a>. <i>ICCV</i>: 2425–2433.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ICCV&amp;rft.atitle=VQA%3A+Visual+Question+Answering&amp;rft.pages=2425-2433&amp;rft.date=2015&amp;rft.aulast=Antol&amp;rft.aufirst=Stanislaw&amp;rft.au=Agrawal%2C+Aishwarya&amp;rft.au=Lu%2C+Jiasen&amp;rft.au=Mitchell%2C+Margaret&amp;rft.au=Batra%2C+Dhruv&amp;rft.au=Zitnick%2C+C.+Lawrence&amp;rft.au=Parikh%2C+Devi&amp;rft_id=https%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_iccv_2015%2Fhtml%2FAntol_VQA_Visual_Question_ICCV_2015_paper.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-69"><span class="mw-cite-backlink"><b><a href="#cite_ref-69" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLiLiSavareseHoi2023" class="citation arxiv cs1">Li,
 Junnan; Li, Dongxu; Savarese, Silvio; Hoi, Steven (2023-01-01). 
"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image 
Encoders and Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2301.12597">2301.12597</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CV">cs.CV</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=BLIP-2%3A+Bootstrapping+Language-Image+Pre-training+with+Frozen+Image+Encoders+and+Large+Language+Models&amp;rft.date=2023-01-01&amp;rft_id=info%3Aarxiv%2F2301.12597&amp;rft.aulast=Li&amp;rft.aufirst=Junnan&amp;rft.au=Li%2C+Dongxu&amp;rft.au=Savarese%2C+Silvio&amp;rft.au=Hoi%2C+Steven&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-70"><span class="mw-cite-backlink"><b><a href="#cite_ref-70" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAlayracDonahueLucMiech2022" class="citation journal cs1">Alayrac,
 Jean-Baptiste; Donahue, Jeff; Luc, Pauline; Miech, Antoine; Barr, Iain;
 Hasson, Yana; Lenc, Karel; Mensch, Arthur; Millican, Katherine; 
Reynolds, Malcolm; Ring, Roman; Rutherford, Eliza; Cabi, Serkan; Han, 
Tengda; Gong, Zhitao (2022-12-06). <a rel="nofollow" class="external text" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html">"Flamingo: a Visual Language Model for Few-Shot Learning"</a>. <i>Advances in Neural Information Processing Systems</i>. <b>35</b>: 23716–23736. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2204.14198">2204.14198</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems&amp;rft.atitle=Flamingo%3A+a+Visual+Language+Model+for+Few-Shot+Learning&amp;rft.volume=35&amp;rft.pages=23716-23736&amp;rft.date=2022-12-06&amp;rft_id=info%3Aarxiv%2F2204.14198&amp;rft.aulast=Alayrac&amp;rft.aufirst=Jean-Baptiste&amp;rft.au=Donahue%2C+Jeff&amp;rft.au=Luc%2C+Pauline&amp;rft.au=Miech%2C+Antoine&amp;rft.au=Barr%2C+Iain&amp;rft.au=Hasson%2C+Yana&amp;rft.au=Lenc%2C+Karel&amp;rft.au=Mensch%2C+Arthur&amp;rft.au=Millican%2C+Katherine&amp;rft.au=Reynolds%2C+Malcolm&amp;rft.au=Ring%2C+Roman&amp;rft.au=Rutherford%2C+Eliza&amp;rft.au=Cabi%2C+Serkan&amp;rft.au=Han%2C+Tengda&amp;rft.au=Gong%2C+Zhitao&amp;rft_id=https%3A%2F%2Fproceedings.neurips.cc%2Fpaper_files%2Fpaper%2F2022%2Fhash%2F960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-71"><span class="mw-cite-backlink"><b><a href="#cite_ref-71" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDriessXiaSajjadiLynch2023" class="citation arxiv cs1">Driess,
 Danny; Xia, Fei; Sajjadi, Mehdi S. M.; Lynch, Corey; Chowdhery, 
Aakanksha; Ichter, Brian; Wahid, Ayzaan; Tompson, Jonathan; Vuong, Quan;
 Yu, Tianhe; Huang, Wenlong; Chebotar, Yevgen; Sermanet, Pierre; 
Duckworth, Daniel; Levine, Sergey (2023-03-01). "PaLM-E: An Embodied 
Multimodal Language Model". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.03378">2303.03378</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=PaLM-E%3A+An+Embodied+Multimodal+Language+Model&amp;rft.date=2023-03-01&amp;rft_id=info%3Aarxiv%2F2303.03378&amp;rft.aulast=Driess&amp;rft.aufirst=Danny&amp;rft.au=Xia%2C+Fei&amp;rft.au=Sajjadi%2C+Mehdi+S.+M.&amp;rft.au=Lynch%2C+Corey&amp;rft.au=Chowdhery%2C+Aakanksha&amp;rft.au=Ichter%2C+Brian&amp;rft.au=Wahid%2C+Ayzaan&amp;rft.au=Tompson%2C+Jonathan&amp;rft.au=Vuong%2C+Quan&amp;rft.au=Yu%2C+Tianhe&amp;rft.au=Huang%2C+Wenlong&amp;rft.au=Chebotar%2C+Yevgen&amp;rft.au=Sermanet%2C+Pierre&amp;rft.au=Duckworth%2C+Daniel&amp;rft.au=Levine%2C+Sergey&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-72"><span class="mw-cite-backlink"><b><a href="#cite_ref-72" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLiuLiWuLee2023" class="citation arxiv cs1">Liu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-04-01). "Visual Instruction Tuning". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2304.08485">2304.08485</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CV">cs.CV</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Visual+Instruction+Tuning&amp;rft.date=2023-04-01&amp;rft_id=info%3Aarxiv%2F2304.08485&amp;rft.aulast=Liu&amp;rft.aufirst=Haotian&amp;rft.au=Li%2C+Chunyuan&amp;rft.au=Wu%2C+Qingyang&amp;rft.au=Lee%2C+Yong+Jae&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-73"><span class="mw-cite-backlink"><b><a href="#cite_ref-73" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZhangLiBing2023" class="citation arxiv cs1">Zhang,
 Hang; Li, Xin; Bing, Lidong (2023-06-01). "Video-LLaMA: An 
Instruction-tuned Audio-Visual Language Model for Video Understanding". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2306.02858">2306.02858</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Video-LLaMA%3A+An+Instruction-tuned+Audio-Visual+Language+Model+for+Video+Understanding&amp;rft.date=2023-06-01&amp;rft_id=info%3Aarxiv%2F2306.02858&amp;rft.aulast=Zhang&amp;rft.aufirst=Hang&amp;rft.au=Li%2C+Xin&amp;rft.au=Bing%2C+Lidong&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-74"><span class="mw-cite-backlink"><b><a href="#cite_ref-74" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFOpenAI2023" class="citation arxiv cs1">OpenAI (2023-03-27). "GPT-4 Technical Report". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.08774">2303.08774</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=GPT-4+Technical+Report&amp;rft.date=2023-03-27&amp;rft_id=info%3Aarxiv%2F2303.08774&amp;rft.au=OpenAI&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-75"><span class="mw-cite-backlink"><b><a href="#cite_ref-75" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFOpenAI2023" class="citation web cs1">OpenAI (September 25, 2023). <a rel="nofollow" class="external text" href="https://cdn.openai.com/papers/GPTV_System_Card.pdf">"GPT-4V(ision) System Card"</a> <span class="cs1-format">(PDF)</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=GPT-4V%28ision%29+System+Card&amp;rft.date=2023-09-25&amp;rft.au=OpenAI&amp;rft_id=https%3A%2F%2Fcdn.openai.com%2Fpapers%2FGPTV_System_Card.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-76"><span class="mw-cite-backlink"><b><a href="#cite_ref-76" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPichai" class="citation cs2">Pichai, Sundar, <a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=cNfINi5CNbY&amp;t=931s"><i>Google Keynote (Google I/O '23)</i></a>, timestamp 15:31<span class="reference-accessdate">, retrieved <span class="nowrap">2023-07-02</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Google+Keynote+%28Google+I%2FO+%2723%29&amp;rft.pages=timestamp+15%3A31&amp;rft.aulast=Pichai&amp;rft.aufirst=Sundar&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DcNfINi5CNbY%26t%3D931s&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-fJta3-77"><span class="mw-cite-backlink"><b><a href="#cite_ref-fJta3_77-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHoffmannBorgeaudMenschBuchatskaya2022" class="citation arxiv cs1">Hoffmann,
 Jordan; Borgeaud, Sebastian; Mensch, Arthur; Buchatskaya, Elena; Cai, 
Trevor; Rutherford, Eliza; Casas, Diego de Las; Hendricks, Lisa Anne; 
Welbl, Johannes; Clark, Aidan; Hennigan, Tom; Noland, Eric; Millican, 
Katie; Driessche, George van den; Damoc, Bogdan (2022-03-29). "Training 
Compute-Optimal Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2203.15556">2203.15556</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Training+Compute-Optimal+Large+Language+Models&amp;rft.date=2022-03-29&amp;rft_id=info%3Aarxiv%2F2203.15556&amp;rft.aulast=Hoffmann&amp;rft.aufirst=Jordan&amp;rft.au=Borgeaud%2C+Sebastian&amp;rft.au=Mensch%2C+Arthur&amp;rft.au=Buchatskaya%2C+Elena&amp;rft.au=Cai%2C+Trevor&amp;rft.au=Rutherford%2C+Eliza&amp;rft.au=Casas%2C+Diego+de+Las&amp;rft.au=Hendricks%2C+Lisa+Anne&amp;rft.au=Welbl%2C+Johannes&amp;rft.au=Clark%2C+Aidan&amp;rft.au=Hennigan%2C+Tom&amp;rft.au=Noland%2C+Eric&amp;rft.au=Millican%2C+Katie&amp;rft.au=Driessche%2C+George+van+den&amp;rft.au=Damoc%2C+Bogdan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-IYm4Q-78"><span class="mw-cite-backlink">^ <a href="#cite_ref-IYm4Q_78-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-IYm4Q_78-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFCaballeroGuptaRishKrueger2022" class="citation arxiv cs1">Caballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). "Broken Neural Scaling Laws". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2210.14891">2210.14891</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Broken+Neural+Scaling+Laws&amp;rft.date=2022&amp;rft_id=info%3Aarxiv%2F2210.14891&amp;rft.aulast=Caballero&amp;rft.aufirst=Ethan&amp;rft.au=Gupta%2C+Kshitij&amp;rft.au=Rish%2C+Irina&amp;rft.au=Krueger%2C+David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-JM6s1-79"><span class="mw-cite-backlink"><b><a href="#cite_ref-JM6s1_79-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.jasonwei.net/blog/emergence">"137 emergent abilities of large language models"</a>. <i>Jason Wei</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Jason+Wei&amp;rft.atitle=137+emergent+abilities+of+large+language+models&amp;rft_id=https%3A%2F%2Fwww.jasonwei.net%2Fblog%2Femergence&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Hahn_20230314-80"><span class="mw-cite-backlink"><b><a href="#cite_ref-Hahn_20230314_80-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHahnGoyal2023" class="citation arxiv cs1">Hahn, Michael; Goyal, Navin (2023-03-14). "A Theory of Emergent In-Context Learning as Implicit Structure Induction". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.07971">2303.07971</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Theory+of+Emergent+In-Context+Learning+as+Implicit+Structure+Induction&amp;rft.date=2023-03-14&amp;rft_id=info%3Aarxiv%2F2303.07971&amp;rft.aulast=Hahn&amp;rft.aufirst=Michael&amp;rft.au=Goyal%2C+Navin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-57FEA-81"><span class="mw-cite-backlink"><b><a href="#cite_ref-57FEA_81-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPilehvarCamacho-Collados2019" class="citation journal cs1">Pilehvar, Mohammad Taher; Camacho-Collados, Jose (June 2019). <a rel="nofollow" class="external text" href="https://aclanthology.org/N19-1128">"Proceedings of the 2019 Conference of the North"</a>. <i>Proceedings
 of the 2019 Conference of the North American Chapter of the Association
 for Computational Linguistics: Human Language Technologies, Volume 1 
(Long and Short Papers)</i>. Minneapolis, Minnesota: Association for Computational Linguistics: 1267–1273. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.18653%2Fv1%2FN19-1128">10.18653/v1/N19-1128</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:102353817">102353817</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+2019+Conference+of+the+North+American+Chapter+of+the+Association+for+Computational+Linguistics%3A+Human+Language+Technologies%2C+Volume+1+%28Long+and+Short+Papers%29&amp;rft.atitle=Proceedings+of+the+2019+Conference+of+the+North&amp;rft.pages=1267-1273&amp;rft.date=2019-06&amp;rft_id=info%3Adoi%2F10.18653%2Fv1%2FN19-1128&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A102353817%23id-name%3DS2CID&amp;rft.aulast=Pilehvar&amp;rft.aufirst=Mohammad+Taher&amp;rft.au=Camacho-Collados%2C+Jose&amp;rft_id=https%3A%2F%2Faclanthology.org%2FN19-1128&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-TEIkA-82"><span class="mw-cite-backlink"><b><a href="#cite_ref-TEIkA_82-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://pilehvar.github.io/wic/">"WiC: The Word-in-Context Dataset"</a>. <i>pilehvar.github.io</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=pilehvar.github.io&amp;rft.atitle=WiC%3A+The+Word-in-Context+Dataset&amp;rft_id=https%3A%2F%2Fpilehvar.github.io%2Fwic%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-zgy1i-83"><span class="mw-cite-backlink"><b><a href="#cite_ref-zgy1i_83-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPatelPavlick2021" class="citation journal cs1">Patel, Roma; Pavlick, Ellie (2021-10-06). <a rel="nofollow" class="external text" href="https://openreview.net/forum?id=gJcEM8sxHK">"Mapping Language Models to Grounded Conceptual Spaces"</a>. <i>ICLR</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ICLR&amp;rft.atitle=Mapping+Language+Models+to+Grounded+Conceptual+Spaces&amp;rft.date=2021-10-06&amp;rft.aulast=Patel&amp;rft.aufirst=Roma&amp;rft.au=Pavlick%2C+Ellie&amp;rft_id=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DgJcEM8sxHK&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Imb98-84"><span class="mw-cite-backlink"><b><a href="#cite_ref-Imb98_84-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><i><a rel="nofollow" class="external text" href="https://www.notion.so/A-Closer-Look-at-Large-Language-Models-Emergent-Abilities-493876b55df5479d80686f68a1abd72f">A Closer Look at Large Language Models Emergent Abilities</a></i> (Yao Fu, Nov 20, 2022)</span>
</li>
<li id="cite_note-CeQVF-85"><span class="mw-cite-backlink"><b><a href="#cite_ref-CeQVF_85-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFOrnes2023" class="citation web cs1">Ornes, Stephen (March 16, 2023). <a rel="nofollow" class="external text" href="https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/">"The Unpredictable Abilities Emerging From Large AI Models"</a>. <i>Quanta Magazine</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Quanta+Magazine&amp;rft.atitle=The+Unpredictable+Abilities+Emerging+From+Large+AI+Models&amp;rft.date=2023-03-16&amp;rft.aulast=Ornes&amp;rft.aufirst=Stephen&amp;rft_id=https%3A%2F%2Fwww.quantamagazine.org%2Fthe-unpredictable-abilities-emerging-from-large-ai-models-20230316%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-C775b-86"><span class="mw-cite-backlink"><b><a href="#cite_ref-C775b_86-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFSchaefferMirandaKoyejo2023" class="citation arxiv cs1">Schaeffer, Rylan; Miranda, Brando; Koyejo, Sanmi (2023-04-01). "Are Emergent Abilities of Large Language Models a Mirage?". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2304.15004">2304.15004</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AI">cs.AI</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Are+Emergent+Abilities+of+Large+Language+Models+a+Mirage%3F&amp;rft.date=2023-04-01&amp;rft_id=info%3Aarxiv%2F2304.15004&amp;rft.aulast=Schaeffer&amp;rft.aufirst=Rylan&amp;rft.au=Miranda%2C+Brando&amp;rft.au=Koyejo%2C+Sanmi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-IZSIr-87"><span class="mw-cite-backlink"><b><a href="#cite_ref-IZSIr_87-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLiHopkinsBauViégas2022" class="citation arxiv cs1">Li,
 Kenneth; Hopkins, Aspen K.; Bau, David; Viégas, Fernanda; Pfister, 
Hanspeter; Wattenberg, Martin (2022-10-01). "Emergent World 
Representations: Exploring a Sequence Model Trained on a Synthetic 
Task". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2210.13382">2210.13382</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Emergent+World+Representations%3A+Exploring+a+Sequence+Model+Trained+on+a+Synthetic+Task&amp;rft.date=2022-10-01&amp;rft_id=info%3Aarxiv%2F2210.13382&amp;rft.aulast=Li&amp;rft.aufirst=Kenneth&amp;rft.au=Hopkins%2C+Aspen+K.&amp;rft.au=Bau%2C+David&amp;rft.au=Vi%C3%A9gas%2C+Fernanda&amp;rft.au=Pfister%2C+Hanspeter&amp;rft.au=Wattenberg%2C+Martin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-RLik9-88"><span class="mw-cite-backlink"><b><a href="#cite_ref-RLik9_88-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://thegradient.pub/othello/">"Large Language Model: world models or surface statistics?"</a>. <i>The Gradient</i>. 2023-01-21<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-12</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Gradient&amp;rft.atitle=Large+Language+Model%3A+world+models+or+surface+statistics%3F&amp;rft.date=2023-01-21&amp;rft_id=https%3A%2F%2Fthegradient.pub%2Fothello%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Hln1l-89"><span class="mw-cite-backlink"><b><a href="#cite_ref-Hln1l_89-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFJinRinard2023" class="citation arxiv cs1">Jin, Charles; Rinard, Martin (2023-05-01). "Evidence of Meaning in Language Models Trained on Programs". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.11169">2305.11169</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Evidence+of+Meaning+in+Language+Models+Trained+on+Programs&amp;rft.date=2023-05-01&amp;rft_id=info%3Aarxiv%2F2305.11169&amp;rft.aulast=Jin&amp;rft.aufirst=Charles&amp;rft.au=Rinard%2C+Martin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-oYGlo-90"><span class="mw-cite-backlink"><b><a href="#cite_ref-oYGlo_90-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFNandaChanLieberumSmith2023" class="citation arxiv cs1">Nanda,
 Neel; Chan, Lawrence; Lieberum, Tom; Smith, Jess; Steinhardt, Jacob 
(2023-01-01). "Progress measures for grokking via mechanistic 
interpretability". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2301.05217">2301.05217</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Progress+measures+for+grokking+via+mechanistic+interpretability&amp;rft.date=2023-01-01&amp;rft_id=info%3Aarxiv%2F2301.05217&amp;rft.aulast=Nanda&amp;rft.aufirst=Neel&amp;rft.au=Chan%2C+Lawrence&amp;rft.au=Lieberum%2C+Tom&amp;rft.au=Smith%2C+Jess&amp;rft.au=Steinhardt%2C+Jacob&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-debate_understanding-91"><span class="mw-cite-backlink">^ <a href="#cite_ref-debate_understanding_91-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-debate_understanding_91-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-debate_understanding_91-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-debate_understanding_91-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-debate_understanding_91-4"><sup><i><b>e</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMitchellKrakauer2023" class="citation journal cs1">Mitchell, Melanie; Krakauer, David C. (28 March 2023). <a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10068812">"The debate over understanding in AI's large language models"</a>. <i>Proceedings of the National Academy of Sciences</i>. <b>120</b> (13): e2215907120. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2210.13966">2210.13966</a></span>. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2023PNAS..12015907M">2023PNAS..12015907M</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1073%2Fpnas.2215907120">10.1073/pnas.2215907120</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&nbsp;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10068812">10068812</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/36943882">36943882</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+National+Academy+of+Sciences&amp;rft.atitle=The+debate+over+understanding+in+AI%27s+large+language+models&amp;rft.volume=120&amp;rft.issue=13&amp;rft.pages=e2215907120&amp;rft.date=2023-03-28&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC10068812%23id-name%3DPMC&amp;rft_id=info%3Abibcode%2F2023PNAS..12015907M&amp;rft_id=info%3Aarxiv%2F2210.13966&amp;rft_id=info%3Apmid%2F36943882&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.2215907120&amp;rft.aulast=Mitchell&amp;rft.aufirst=Melanie&amp;rft.au=Krakauer%2C+David+C.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC10068812&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-O8Upd-92"><span class="mw-cite-backlink"><b><a href="#cite_ref-O8Upd_92-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMetz2023" class="citation news cs1">Metz, Cade (16 May 2023). <a rel="nofollow" class="external text" href="https://www.nytimes.com/2023/05/16/technology/microsoft-ai-human-reasoning.html">"Microsoft Says New A.I. Shows Signs of Human Reasoning"</a>. <i>The New York Times</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=Microsoft+Says+New+A.I.+Shows+Signs+of+Human+Reasoning&amp;rft.date=2023-05-16&amp;rft.aulast=Metz&amp;rft.aufirst=Cade&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2023%2F05%2F16%2Ftechnology%2Fmicrosoft-ai-human-reasoning.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-microsoft_sparks-93"><span class="mw-cite-backlink">^ <a href="#cite_ref-microsoft_sparks_93-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-microsoft_sparks_93-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBubeckChandrasekaranEldanGehrke2023" class="citation arxiv cs1">Bubeck,
 Sébastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; 
Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; 
Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; 
Zhang, Yi (2023). "Sparks of Artificial General Intelligence: Early 
experiments with GPT-4". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.12712">2303.12712</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Sparks+of+Artificial+General+Intelligence%3A+Early+experiments+with+GPT-4&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2303.12712&amp;rft.aulast=Bubeck&amp;rft.aufirst=S%C3%A9bastien&amp;rft.au=Chandrasekaran%2C+Varun&amp;rft.au=Eldan%2C+Ronen&amp;rft.au=Gehrke%2C+Johannes&amp;rft.au=Horvitz%2C+Eric&amp;rft.au=Kamar%2C+Ece&amp;rft.au=Lee%2C+Peter&amp;rft.au=Lee%2C+Yin+Tat&amp;rft.au=Li%2C+Yuanzhi&amp;rft.au=Lundberg%2C+Scott&amp;rft.au=Nori%2C+Harsha&amp;rft.au=Palangi%2C+Hamid&amp;rft.au=Ribeiro%2C+Marco+Tulio&amp;rft.au=Zhang%2C+Yi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-rEEmH-94"><span class="mw-cite-backlink"><b><a href="#cite_ref-rEEmH_94-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation news cs1"><a rel="nofollow" class="external text" href="https://www.zdnet.com/article/chatgpt-is-more-like-an-alien-intelligence-than-a-human-brain-says-futurist/">"ChatGPT is more like an 'alien intelligence' than a human brain, says futurist"</a>. <i>ZDNET</i>. 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">12 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ZDNET&amp;rft.atitle=ChatGPT+is+more+like+an+%27alien+intelligence%27+than+a+human+brain%2C+says+futurist&amp;rft.date=2023&amp;rft_id=https%3A%2F%2Fwww.zdnet.com%2Farticle%2Fchatgpt-is-more-like-an-alien-intelligence-than-a-human-brain-says-futurist%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-new_yorker_kind_of_mind-95"><span class="mw-cite-backlink">^ <a href="#cite_ref-new_yorker_kind_of_mind_95-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-new_yorker_kind_of_mind_95-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFNewport2023" class="citation magazine cs1">Newport, Cal (13 April 2023). <a rel="nofollow" class="external text" href="https://www.newyorker.com/science/annals-of-artificial-intelligence/what-kind-of-mind-does-chatgpt-have">"What Kind of Mind Does ChatGPT Have?"</a>. <i>The New Yorker</i><span class="reference-accessdate">. Retrieved <span class="nowrap">12 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+Yorker&amp;rft.atitle=What+Kind+of+Mind+Does+ChatGPT+Have%3F&amp;rft.date=2023-04-13&amp;rft.aulast=Newport&amp;rft.aufirst=Cal&amp;rft_id=https%3A%2F%2Fwww.newyorker.com%2Fscience%2Fannals-of-artificial-intelligence%2Fwhat-kind-of-mind-does-chatgpt-have&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-rAFIZ-96"><span class="mw-cite-backlink"><b><a href="#cite_ref-rAFIZ_96-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFRoose2023" class="citation news cs1">Roose, Kevin (30 May 2023). <a rel="nofollow" class="external text" href="https://www.nytimes.com/2023/05/30/technology/shoggoth-meme-ai.html">"Why an Octopus-like Creature Has Come to Symbolize the State of A.I."</a> <i>The New York Times</i><span class="reference-accessdate">. Retrieved <span class="nowrap">12 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=Why+an+Octopus-like+Creature+Has+Come+to+Symbolize+the+State+of+A.I.&amp;rft.date=2023-05-30&amp;rft.aulast=Roose&amp;rft.aufirst=Kevin&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2023%2F05%2F30%2Ftechnology%2Fshoggoth-meme-ai.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-4luKE-97"><span class="mw-cite-backlink"><b><a href="#cite_ref-4luKE_97-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation news cs1"><a rel="nofollow" class="external text" href="https://time.com/6271657/a-to-z-of-artificial-intelligence/">"The A to Z of Artificial Intelligence"</a>. <i>Time Magazine</i>. 13 April 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">12 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Time+Magazine&amp;rft.atitle=The+A+to+Z+of+Artificial+Intelligence&amp;rft.date=2023-04-13&amp;rft_id=https%3A%2F%2Ftime.com%2F6271657%2Fa-to-z-of-artificial-intelligence%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-hallucination-survey-98"><span class="mw-cite-backlink"><b><a href="#cite_ref-hallucination-survey_98-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFJiLeeFrieskeYu2022" class="citation journal cs1">Ji,
 Ziwei; Lee, Nayeon; Frieske, Rita; Yu, Tiezheng; Su, Dan; Xu, Yan; 
Ishii, Etsuko; Bang, Yejin; Dai, Wenliang; Madotto, Andrea; Fung, 
Pascale (November 2022). <a rel="nofollow" class="external text" href="https://dl.acm.org/doi/pdf/10.1145/3571730">"Survey of Hallucination in Natural Language Generation"</a> <span class="cs1-format">(pdf)</span>. <i>ACM Computing Surveys</i>. <b>55</b> (12). <a href="https://en.wikipedia.org/wiki/Association_for_Computing_Machinery" title="Association for Computing Machinery">Association for Computing Machinery</a>: 1–38. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2202.03629">2202.03629</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F3571730">10.1145/3571730</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:246652372">246652372</a><span class="reference-accessdate">. Retrieved <span class="nowrap">15 January</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+Computing+Surveys&amp;rft.atitle=Survey+of+Hallucination+in+Natural+Language+Generation&amp;rft.volume=55&amp;rft.issue=12&amp;rft.pages=1-38&amp;rft.date=2022-11&amp;rft_id=info%3Aarxiv%2F2202.03629&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A246652372%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1145%2F3571730&amp;rft.aulast=Ji&amp;rft.aufirst=Ziwei&amp;rft.au=Lee%2C+Nayeon&amp;rft.au=Frieske%2C+Rita&amp;rft.au=Yu%2C+Tiezheng&amp;rft.au=Su%2C+Dan&amp;rft.au=Xu%2C+Yan&amp;rft.au=Ishii%2C+Etsuko&amp;rft.au=Bang%2C+Yejin&amp;rft.au=Dai%2C+Wenliang&amp;rft.au=Madotto%2C+Andrea&amp;rft.au=Fung%2C+Pascale&amp;rft_id=https%3A%2F%2Fdl.acm.org%2Fdoi%2Fpdf%2F10.1145%2F3571730&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-99"><span class="mw-cite-backlink"><b><a href="#cite_ref-99" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFVarshneyYaoZhangChen2023" class="citation arxiv cs1">Varshney,
 Neeraj; Yao, Wenlin; Zhang, Hongming; Chen, Jianshu; Yu, Dong (2023). 
"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of
 LLMs by Validating Low-Confidence Generation". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2307.03987">2307.03987</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Stitch+in+Time+Saves+Nine%3A+Detecting+and+Mitigating+Hallucinations+of+LLMs+by+Validating+Low-Confidence+Generation&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2307.03987&amp;rft.aulast=Varshney&amp;rft.aufirst=Neeraj&amp;rft.au=Yao%2C+Wenlin&amp;rft.au=Zhang%2C+Hongming&amp;rft.au=Chen%2C+Jianshu&amp;rft.au=Yu%2C+Dong&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-100"><span class="mw-cite-backlink"><b><a href="#cite_ref-100" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLakoff1999" class="citation book cs1">Lakoff, George (1999). <i>Philosophy
 in the Flesh: The Embodied Mind and Its Challenge to Western 
Philosophy; Appendix: The Neural Theory of Language Paradigm</i>. New York Basic Books. pp.&nbsp;569–583. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-465-05674-3" title="Special:BookSources/978-0-465-05674-3"><bdi>978-0-465-05674-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Philosophy+in+the+Flesh%3A+The+Embodied+Mind+and+Its+Challenge+to+Western+Philosophy%3B+Appendix%3A+The+Neural+Theory+of+Language+Paradigm&amp;rft.pages=569-583&amp;rft.pub=New+York+Basic+Books&amp;rft.date=1999&amp;rft.isbn=978-0-465-05674-3&amp;rft.aulast=Lakoff&amp;rft.aufirst=George&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-101"><span class="mw-cite-backlink"><b><a href="#cite_ref-101" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFEvans2014" class="citation book cs1">Evans, Vyvyan. (2014). <i>The Language Myth</i>. Cambridge University Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-107-04396-1" title="Special:BookSources/978-1-107-04396-1"><bdi>978-1-107-04396-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Language+Myth&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2014&amp;rft.isbn=978-1-107-04396-1&amp;rft.aulast=Evans&amp;rft.aufirst=Vyvyan.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-102"><span class="mw-cite-backlink"><b><a href="#cite_ref-102" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFFriston2022" class="citation book cs1">Friston, Karl J. (2022). <i>Active Inference: The Free Energy Principle in Mind, Brain, and Behavior; Chapter 4 The Generative Models of Active Inference</i>. The MIT Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-262-36997-8" title="Special:BookSources/978-0-262-36997-8"><bdi>978-0-262-36997-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Active+Inference%3A+The+Free+Energy+Principle+in+Mind%2C+Brain%2C+and+Behavior%3B+Chapter+4+The+Generative+Models+of+Active+Inference&amp;rft.pub=The+MIT+Press&amp;rft.date=2022&amp;rft.isbn=978-0-262-36997-8&amp;rft.aulast=Friston&amp;rft.aufirst=Karl+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Huyen-103"><span class="mw-cite-backlink">^ <a href="#cite_ref-Huyen_103-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Huyen_103-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHuyen2019" class="citation web cs1">Huyen, Chip (October 18, 2019). <a rel="nofollow" class="external text" href="https://thegradient.pub/understanding-evaluation-metrics-for-language-models/">"Evaluation Metrics for Language Modeling"</a>. <i>The Gradient</i><span class="reference-accessdate">. Retrieved <span class="nowrap">January 14,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Gradient&amp;rft.atitle=Evaluation+Metrics+for+Language+Modeling&amp;rft.date=2019-10-18&amp;rft.aulast=Huyen&amp;rft.aufirst=Chip&amp;rft_id=https%3A%2F%2Fthegradient.pub%2Funderstanding-evaluation-metrics-for-language-models%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-boolq-104"><span class="mw-cite-backlink">^ <a href="#cite_ref-boolq_104-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-boolq_104-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFClarkLeeChangKwiatkowski2019" class="citation arxiv cs1">Clark,
 Christopher; Lee, Kenton; Chang, Ming-Wei; Kwiatkowski, Tom; Collins, 
Michael; Toutanova, Kristina (2019). "BoolQ: Exploring the Surprising 
Difficulty of Natural Yes/No Questions". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1905.10044">1905.10044</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=BoolQ%3A+Exploring+the+Surprising+Difficulty+of+Natural+Yes%2FNo+Questions&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1905.10044&amp;rft.aulast=Clark&amp;rft.aufirst=Christopher&amp;rft.au=Lee%2C+Kenton&amp;rft.au=Chang%2C+Ming-Wei&amp;rft.au=Kwiatkowski%2C+Tom&amp;rft.au=Collins%2C+Michael&amp;rft.au=Toutanova%2C+Kristina&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-survey-105"><span class="mw-cite-backlink">^ <a href="#cite_ref-survey_105-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-survey_105-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-survey_105-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWayne_Xin_ZhaoZhouLiTang2023" class="citation arxiv cs1">Wayne
 Xin Zhao; Zhou, Kun; Li, Junyi; Tang, Tianyi; Wang, Xiaolei; Hou, 
Yupeng; Min, Yingqian; Zhang, Beichen; Zhang, Junjie; Dong, Zican; Du, 
Yifan; Yang, Chen; Chen, Yushuo; Chen, Zhipeng; Jiang, Jinhao; Ren, 
Ruiyang; Li, Yifan; Tang, Xinyu; Liu, Zikang; Liu, Peiyu; Nie, Jian-Yun;
 Wen, Ji-Rong (2023). "A Survey of Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.18223">2303.18223</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Survey+of+Large+Language+Models&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2303.18223&amp;rft.au=Wayne+Xin+Zhao&amp;rft.au=Zhou%2C+Kun&amp;rft.au=Li%2C+Junyi&amp;rft.au=Tang%2C+Tianyi&amp;rft.au=Wang%2C+Xiaolei&amp;rft.au=Hou%2C+Yupeng&amp;rft.au=Min%2C+Yingqian&amp;rft.au=Zhang%2C+Beichen&amp;rft.au=Zhang%2C+Junjie&amp;rft.au=Dong%2C+Zican&amp;rft.au=Du%2C+Yifan&amp;rft.au=Yang%2C+Chen&amp;rft.au=Chen%2C+Yushuo&amp;rft.au=Chen%2C+Zhipeng&amp;rft.au=Jiang%2C+Jinhao&amp;rft.au=Ren%2C+Ruiyang&amp;rft.au=Li%2C+Yifan&amp;rft.au=Tang%2C+Xinyu&amp;rft.au=Liu%2C+Zikang&amp;rft.au=Liu%2C+Peiyu&amp;rft.au=Nie%2C+Jian-Yun&amp;rft.au=Wen%2C+Ji-Rong&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-bigbench-106"><span class="mw-cite-backlink"><b><a href="#cite_ref-bigbench_106-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFSrivastavaRastogiRaoAbu_Awal_Md_Shoeb2022" class="citation arxiv cs1">Srivastava,
 Aarohi; et&nbsp;al. (2022). "Beyond the Imitation Game: Quantifying and
 extrapolating the capabilities of language models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2206.04615">2206.04615</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Beyond+the+Imitation+Game%3A+Quantifying+and+extrapolating+the+capabilities+of+language+models&amp;rft.date=2022&amp;rft_id=info%3Aarxiv%2F2206.04615&amp;rft.aulast=Srivastava&amp;rft.aufirst=Aarohi&amp;rft.au=Rastogi%2C+Abhinav&amp;rft.au=Rao%2C+Abhishek&amp;rft.au=Abu+Awal+Md+Shoeb&amp;rft.au=Abid%2C+Abubakar&amp;rft.au=Fisch%2C+Adam&amp;rft.au=Brown%2C+Adam+R.&amp;rft.au=Santoro%2C+Adam&amp;rft.au=Gupta%2C+Aditya&amp;rft.au=Garriga-Alonso%2C+Adri%C3%A0&amp;rft.au=Kluska%2C+Agnieszka&amp;rft.au=Lewkowycz%2C+Aitor&amp;rft.au=Agarwal%2C+Akshat&amp;rft.au=Power%2C+Alethea&amp;rft.au=Ray%2C+Alex&amp;rft.au=Warstadt%2C+Alex&amp;rft.au=Kocurek%2C+Alexander+W.&amp;rft.au=Safaya%2C+Ali&amp;rft.au=Tazarv%2C+Ali&amp;rft.au=Xiang%2C+Alice&amp;rft.au=Parrish%2C+Alicia&amp;rft.au=Nie%2C+Allen&amp;rft.au=Hussain%2C+Aman&amp;rft.au=Askell%2C+Amanda&amp;rft.au=Dsouza%2C+Amanda&amp;rft.au=Slone%2C+Ambrose&amp;rft.au=Rahane%2C+Ameet&amp;rft.au=Iyer%2C+Anantharaman+S.&amp;rft.au=Andreassen%2C+Anders&amp;rft.au=Madotto%2C+Andrea&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-truthfulqa-107"><span class="mw-cite-backlink"><b><a href="#cite_ref-truthfulqa_107-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLinHiltonEvans2021" class="citation arxiv cs1">Lin, Stephanie; Hilton, Jacob; Evans, Owain (2021). "TruthfulQA: Measuring How Models Mimic Human Falsehoods". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2109.07958">2109.07958</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=TruthfulQA%3A+Measuring+How+Models+Mimic+Human+Falsehoods&amp;rft.date=2021&amp;rft_id=info%3Aarxiv%2F2109.07958&amp;rft.aulast=Lin&amp;rft.aufirst=Stephanie&amp;rft.au=Hilton%2C+Jacob&amp;rft.au=Evans%2C+Owain&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-hellaswag-108"><span class="mw-cite-backlink">^ <a href="#cite_ref-hellaswag_108-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-hellaswag_108-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZellersHoltzmanBiskFarhadi2019" class="citation arxiv cs1">Zellers,
 Rowan; Holtzman, Ari; Bisk, Yonatan; Farhadi, Ali; Choi, Yejin (2019). 
"HellaSwag: Can a Machine Really Finish Your Sentence?". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1905.07830">1905.07830</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=HellaSwag%3A+Can+a+Machine+Really+Finish+Your+Sentence%3F&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1905.07830&amp;rft.aulast=Zellers&amp;rft.aufirst=Rowan&amp;rft.au=Holtzman%2C+Ari&amp;rft.au=Bisk%2C+Yonatan&amp;rft.au=Farhadi%2C+Ali&amp;rft.au=Choi%2C+Yejin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-ZDTUM-109"><span class="mw-cite-backlink"><b><a href="#cite_ref-ZDTUM_109-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation journal cs1">"Prepare for truly useful large language models". <i>Nature Biomedical Engineering</i>. <b>7</b> (2): 85–86. 7 March 2023. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fs41551-023-01012-6">10.1038/s41551-023-01012-6</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/36882584">36882584</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:257403466">257403466</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature+Biomedical+Engineering&amp;rft.atitle=Prepare+for+truly+useful+large+language+models&amp;rft.volume=7&amp;rft.issue=2&amp;rft.pages=85-86&amp;rft.date=2023-03-07&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A257403466%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F36882584&amp;rft_id=info%3Adoi%2F10.1038%2Fs41551-023-01012-6&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-81w7x-110"><span class="mw-cite-backlink"><b><a href="#cite_ref-81w7x_110-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation news cs1"><a rel="nofollow" class="external text" href="https://www.economist.com/finance-and-economics/2023/05/07/your-job-is-probably-safe-from-artificial-intelligence">"Your job is (probably) safe from artificial intelligence"</a>. <i>The Economist</i>. 7 May 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">18 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Economist&amp;rft.atitle=Your+job+is+%28probably%29+safe+from+artificial+intelligence&amp;rft.date=2023-05-07&amp;rft_id=https%3A%2F%2Fwww.economist.com%2Ffinance-and-economics%2F2023%2F05%2F07%2Fyour-job-is-probably-safe-from-artificial-intelligence&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-zIM6Y-111"><span class="mw-cite-backlink"><b><a href="#cite_ref-zIM6Y_111-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html">"Generative AI Could Raise Global GDP by 7%"</a>. <i>Goldman Sachs</i><span class="reference-accessdate">. Retrieved <span class="nowrap">18 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Goldman+Sachs&amp;rft.atitle=Generative+AI+Could+Raise+Global+GDP+by+7%25&amp;rft_id=https%3A%2F%2Fwww.goldmansachs.com%2Fintelligence%2Fpages%2Fgenerative-ai-could-raise-global-gdp-by-7-percent.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-112"><span class="mw-cite-backlink"><b><a href="#cite_ref-112" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPengWangDeng2023" class="citation journal cs1">Peng, Zhencan; Wang, Zhizhi; Deng, Dong (13 June 2023). <a rel="nofollow" class="external text" href="https://people.cs.rutgers.edu/~dd903/assets/papers/sigmod23.pdf">"Near-Duplicate Sequence Search at Scale for Large Language Model Memorization Evaluation"</a> <span class="cs1-format">(PDF)</span>. <i>Proceedings of the ACM on Management of Data</i>. <b>1</b> (2): 1–18. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F3589324">10.1145/3589324</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:259213212">259213212</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2024-01-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+ACM+on+Management+of+Data&amp;rft.atitle=Near-Duplicate+Sequence+Search+at+Scale+for+Large+Language+Model+Memorization+Evaluation&amp;rft.volume=1&amp;rft.issue=2&amp;rft.pages=1-18&amp;rft.date=2023-06-13&amp;rft_id=info%3Adoi%2F10.1145%2F3589324&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A259213212%23id-name%3DS2CID&amp;rft.aulast=Peng&amp;rft.aufirst=Zhencan&amp;rft.au=Wang%2C+Zhizhi&amp;rft.au=Deng%2C+Dong&amp;rft_id=https%3A%2F%2Fpeople.cs.rutgers.edu%2F~dd903%2Fassets%2Fpapers%2Fsigmod23.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span> Citing Lee et al 2022.</span>
</li>
<li id="cite_note-113"><span class="mw-cite-backlink"><b><a href="#cite_ref-113" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><a href="#CITEREFPengWangDeng2023">Peng, Wang &amp; Deng 2023</a>, p.&nbsp;8.</span>
</li>
<li id="cite_note-nD6kH-114"><span class="mw-cite-backlink"><b><a href="#cite_ref-nD6kH_114-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAlba2023" class="citation news cs1">Alba, Davey (1 May 2023). <a rel="nofollow" class="external text" href="https://www.japantimes.co.jp/news/2023/05/01/business/tech/ai-fake-news-content-farms/">"AI chatbots have been used to create dozens of news content farms"</a>. <i>The Japan Times</i><span class="reference-accessdate">. Retrieved <span class="nowrap">18 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Japan+Times&amp;rft.atitle=AI+chatbots+have+been+used+to+create+dozens+of+news+content+farms&amp;rft.date=2023-05-01&amp;rft.aulast=Alba&amp;rft.aufirst=Davey&amp;rft_id=https%3A%2F%2Fwww.japantimes.co.jp%2Fnews%2F2023%2F05%2F01%2Fbusiness%2Ftech%2Fai-fake-news-content-farms%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-PKiPY-115"><span class="mw-cite-backlink"><b><a href="#cite_ref-PKiPY_115-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation journal cs1"><a rel="nofollow" class="external text" href="https://www.science.org/content/article/could-chatbots-help-devise-next-pandemic-virus">"Could chatbots help devise the next pandemic virus?"</a>. <i>Science</i>. 14 June 2023. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1126%2Fscience.adj2463">10.1126/science.adj2463</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Science&amp;rft.atitle=Could+chatbots+help+devise+the+next+pandemic+virus%3F&amp;rft.date=2023-06-14&amp;rft_id=info%3Adoi%2F10.1126%2Fscience.adj2463&amp;rft_id=https%3A%2F%2Fwww.science.org%2Fcontent%2Farticle%2Fcould-chatbots-help-devise-next-pandemic-virus&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-116"><span class="mw-cite-backlink"><b><a href="#cite_ref-116" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFStephen_Council2023" class="citation web cs1">Stephen Council (1 Dec 2023). <a rel="nofollow" class="external text" href="https://www.sfgate.com/tech/article/google-openai-chatgpt-break-model-18525445.php">"How Googlers cracked an SF rival's tech model with a single word"</a>. SFGATE.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=How+Googlers+cracked+an+SF+rival%27s+tech+model+with+a+single+word&amp;rft.pub=SFGATE&amp;rft.date=2023-12-01&amp;rft.au=Stephen+Council&amp;rft_id=https%3A%2F%2Fwww.sfgate.com%2Ftech%2Farticle%2Fgoogle-openai-chatgpt-break-model-18525445.php&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-117"><span class="mw-cite-backlink"><b><a href="#cite_ref-117" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHubinger2024" class="citation arxiv cs1">Hubinger, Evan (10 January 2024). "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2401.05566">2401.05566</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CR">cs.CR</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Sleeper+Agents%3A+Training+Deceptive+LLMs+that+Persist+Through+Safety+Training&amp;rft.date=2024-01-10&amp;rft_id=info%3Aarxiv%2F2401.05566&amp;rft.aulast=Hubinger&amp;rft.aufirst=Evan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:8-118"><span class="mw-cite-backlink">^ <a href="#cite_ref-:8_118-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:8_118-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFStokel-Walker2023" class="citation web cs1">Stokel-Walker, Chris (November 22, 2023). <a rel="nofollow" class="external text" href="https://www.scientificamerican.com/article/chatgpt-replicates-gender-bias-in-recommendation-letters/">"ChatGPT Replicates Gender Bias in Recommendation Letters"</a>. <i>Scientific American</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-12-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Scientific+American&amp;rft.atitle=ChatGPT+Replicates+Gender+Bias+in+Recommendation+Letters&amp;rft.date=2023-11-22&amp;rft.aulast=Stokel-Walker&amp;rft.aufirst=Chris&amp;rft_id=https%3A%2F%2Fwww.scientificamerican.com%2Farticle%2Fchatgpt-replicates-gender-bias-in-recommendation-letters%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:1-119"><span class="mw-cite-backlink"><b><a href="#cite_ref-:1_119-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLuoPuettSmith2023" class="citation arxiv cs1">Luo,
 Queenie; Puett, Michael J.; Smith, Michael D. (2023-03-28). "A 
Perspectival Mirror of the Elephant: Investigating Language Bias on 
Google, ChatGPT, Wikipedia, and YouTube". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.16281v2">2303.16281v2</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CY">cs.CY</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Perspectival+Mirror+of+the+Elephant%3A+Investigating+Language+Bias+on+Google%2C+ChatGPT%2C+Wikipedia%2C+and+YouTube&amp;rft.date=2023-03-28&amp;rft_id=info%3Aarxiv%2F2303.16281v2&amp;rft.aulast=Luo&amp;rft.aufirst=Queenie&amp;rft.au=Puett%2C+Michael+J.&amp;rft.au=Smith%2C+Michael+D.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-120"><span class="mw-cite-backlink"><b><a href="#cite_ref-120" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFChengDurmusJurafsky2023" class="citation cs2">Cheng, Myra; Durmus, Esin; Jurafsky, Dan (2023-05-29), <i>Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models</i>, <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2305.18189">2305.18189</a></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Marked+Personas%3A+Using+Natural+Language+Prompts+to+Measure+Stereotypes+in+Language+Models&amp;rft.date=2023-05-29&amp;rft_id=info%3Aarxiv%2F2305.18189&amp;rft.aulast=Cheng&amp;rft.aufirst=Myra&amp;rft.au=Durmus%2C+Esin&amp;rft.au=Jurafsky%2C+Dan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-121"><span class="mw-cite-backlink"><b><a href="#cite_ref-121" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKotekDockumSun2023" class="citation book cs1">Kotek, Hadas; Dockum, Rikker; Sun, David (2023-11-05). <a rel="nofollow" class="external text" href="https://dl.acm.org/doi/10.1145/3582269.3615599">"Gender bias and stereotypes in Large Language Models"</a>. <i>Proceedings of the ACM Collective Intelligence Conference</i>. CI '23. New York, NY, USA: Association for Computing Machinery. pp.&nbsp;12–24. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F3582269.3615599">10.1145/3582269.3615599</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/979-8-4007-0113-9" title="Special:BookSources/979-8-4007-0113-9"><bdi>979-8-4007-0113-9</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Gender+bias+and+stereotypes+in+Large+Language+Models&amp;rft.btitle=Proceedings+of+the+ACM+Collective+Intelligence+Conference&amp;rft.place=New+York%2C+NY%2C+USA&amp;rft.series=CI+%2723&amp;rft.pages=12-24&amp;rft.pub=Association+for+Computing+Machinery&amp;rft.date=2023-11-05&amp;rft_id=info%3Adoi%2F10.1145%2F3582269.3615599&amp;rft.isbn=979-8-4007-0113-9&amp;rft.aulast=Kotek&amp;rft.aufirst=Hadas&amp;rft.au=Dockum%2C+Rikker&amp;rft.au=Sun%2C+David&amp;rft_id=https%3A%2F%2Fdl.acm.org%2Fdoi%2F10.1145%2F3582269.3615599&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-122"><span class="mw-cite-backlink"><b><a href="#cite_ref-122" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHeikkilä2023" class="citation web cs1">Heikkilä, Melissa (August 7, 2023). <a rel="nofollow" class="external text" href="https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/">"AI language models are rife with different political biases"</a>. <i>MIT Technology Review</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-12-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=AI+language+models+are+rife+with+different+political+biases&amp;rft.date=2023-08-07&amp;rft.aulast=Heikkil%C3%A4&amp;rft.aufirst=Melissa&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2F2023%2F08%2F07%2F1077324%2Fai-language-models-are-rife-with-political-biases%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-oai-unsup-126"><span class="mw-cite-backlink"><b><a href="#cite_ref-oai-unsup_126-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://openai.com/research/language-unsupervised">"Improving language understanding with unsupervised learning"</a>. <i>openai.com</i>. June 11, 2018. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20230318210736/https://openai.com/research/language-unsupervised">Archived</a> from the original on 2023-03-18<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-03-18</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=openai.com&amp;rft.atitle=Improving+language+understanding+with+unsupervised+learning&amp;rft.date=2018-06-11&amp;rft_id=https%3A%2F%2Fopenai.com%2Fresearch%2Flanguage-unsupervised&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-gpt1-127"><span class="mw-cite-backlink"><b><a href="#cite_ref-gpt1_127-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/openai/finetune-transformer-lm">"finetune-transformer-lm"</a>. <i>GitHub</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2 January</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=finetune-transformer-lm&amp;rft_id=https%3A%2F%2Fgithub.com%2Fopenai%2Ffinetune-transformer-lm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-bert-paper-128"><span class="mw-cite-backlink">^ <a href="#cite_ref-bert-paper_128-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-bert-paper_128-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDevlinChangLeeToutanova2018" class="citation arxiv cs1">Devlin,
 Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (11 October 
2018). "BERT: Pre-training of Deep Bidirectional Transformers for 
Language Understanding". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1810.04805v2">1810.04805v2</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=BERT%3A+Pre-training+of+Deep+Bidirectional+Transformers+for+Language+Understanding&amp;rft.date=2018-10-11&amp;rft_id=info%3Aarxiv%2F1810.04805v2&amp;rft.aulast=Devlin&amp;rft.aufirst=Jacob&amp;rft.au=Chang%2C+Ming-Wei&amp;rft.au=Lee%2C+Kenton&amp;rft.au=Toutanova%2C+Kristina&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-bHZJ2-129"><span class="mw-cite-backlink"><b><a href="#cite_ref-bHZJ2_129-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPrickett2021" class="citation web cs1">Prickett, Nicole Hemsoth (2021-08-24). <a rel="nofollow" class="external text" href="https://www.nextplatform.com/2021/08/24/cerebras-shifts-architecture-to-meet-massive-ai-ml-models/">"Cerebras Shifts Architecture To Meet Massive AI/ML Models"</a>. <i>The Next Platform</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Next+Platform&amp;rft.atitle=Cerebras+Shifts+Architecture+To+Meet+Massive+AI%2FML+Models&amp;rft.date=2021-08-24&amp;rft.aulast=Prickett&amp;rft.aufirst=Nicole+Hemsoth&amp;rft_id=https%3A%2F%2Fwww.nextplatform.com%2F2021%2F08%2F24%2Fcerebras-shifts-architecture-to-meet-massive-ai-ml-models%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-bert-web-130"><span class="mw-cite-backlink"><b><a href="#cite_ref-bert-web_130-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/google-research/bert">"BERT"</a>. March 13, 2023 – via GitHub.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=BERT&amp;rft.date=2023-03-13&amp;rft_id=https%3A%2F%2Fgithub.com%2Fgoogle-research%2Fbert&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Ir545-131"><span class="mw-cite-backlink"><b><a href="#cite_ref-Ir545_131-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPatelLiRasooliConstant2022" class="citation arxiv cs1">Patel,
 Ajay; Li, Bryan; Rasooli, Mohammad Sadegh; Constant, Noah; Raffel, 
Colin; Callison-Burch, Chris (2022). "Bidirectional Language Models Are 
Also Few-shot Learners". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2209.14500">2209.14500</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Bidirectional+Language+Models+Are+Also+Few-shot+Learners&amp;rft.date=2022&amp;rft_id=info%3Aarxiv%2F2209.14500&amp;rft.aulast=Patel&amp;rft.aufirst=Ajay&amp;rft.au=Li%2C+Bryan&amp;rft.au=Rasooli%2C+Mohammad+Sadegh&amp;rft.au=Constant%2C+Noah&amp;rft.au=Raffel%2C+Colin&amp;rft.au=Callison-Burch%2C+Chris&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:6-132"><span class="mw-cite-backlink">^ <a href="#cite_ref-:6_132-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:6_132-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFRaffelShazeerRobertsLee2020" class="citation journal cs1">Raffel,
 Colin; Shazeer, Noam; Roberts, Adam; Lee, Katherine; Narang, Sharan; 
Matena, Michael; Zhou, Yanqi; Li, Wei; Liu, Peter J. (2020). <a rel="nofollow" class="external text" href="http://jmlr.org/papers/v21/20-074.html">"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"</a>. <i>Journal of Machine Learning Research</i>. <b>21</b> (140): 1–67. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1910.10683">1910.10683</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/1533-7928">1533-7928</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Exploring+the+Limits+of+Transfer+Learning+with+a+Unified+Text-to-Text+Transformer&amp;rft.volume=21&amp;rft.issue=140&amp;rft.pages=1-67&amp;rft.date=2020&amp;rft_id=info%3Aarxiv%2F1910.10683&amp;rft.issn=1533-7928&amp;rft.aulast=Raffel&amp;rft.aufirst=Colin&amp;rft.au=Shazeer%2C+Noam&amp;rft.au=Roberts%2C+Adam&amp;rft.au=Lee%2C+Katherine&amp;rft.au=Narang%2C+Sharan&amp;rft.au=Matena%2C+Michael&amp;rft.au=Zhou%2C+Yanqi&amp;rft.au=Li%2C+Wei&amp;rft.au=Liu%2C+Peter+J.&amp;rft_id=http%3A%2F%2Fjmlr.org%2Fpapers%2Fv21%2F20-074.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-133"><span class="mw-cite-backlink"><b><a href="#cite_ref-133" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation cs2"><a rel="nofollow" class="external text" href="https://github.com/google-research/text-to-text-transfer-transformer"><i>google-research/text-to-text-transfer-transformer</i></a>, Google Research, 2024-04-02<span class="reference-accessdate">, retrieved <span class="nowrap">2024-04-04</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=google-research%2Ftext-to-text-transfer-transformer&amp;rft.pub=Google+Research&amp;rft.date=2024-04-02&amp;rft_id=https%3A%2F%2Fgithub.com%2Fgoogle-research%2Ftext-to-text-transfer-transformer&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-134"><span class="mw-cite-backlink"><b><a href="#cite_ref-134" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://imagen.research.google/">"Imagen: Text-to-Image Diffusion Models"</a>. <i>imagen.research.google</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2024-04-04</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=imagen.research.google&amp;rft.atitle=Imagen%3A+Text-to-Image+Diffusion+Models&amp;rft_id=https%3A%2F%2Fimagen.research.google%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-45rAm-135"><span class="mw-cite-backlink"><b><a href="#cite_ref-45rAm_135-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.kdnuggets.com/bert-roberta-distilbert-xlnet-which-one-to-use.html">"BERT, RoBERTa, DistilBERT, XLNet: Which one to use?"</a>. <i>KDnuggets</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=KDnuggets&amp;rft.atitle=BERT%2C+RoBERTa%2C+DistilBERT%2C+XLNet%3A+Which+one+to+use%3F&amp;rft_id=https%3A%2F%2Fwww.kdnuggets.com%2Fbert-roberta-distilbert-xlnet-which-one-to-use.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-xlnet-136"><span class="mw-cite-backlink"><b><a href="#cite_ref-xlnet_136-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/zihangdai/xlnet/">"xlnet"</a>. <i>GitHub</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2 January</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=xlnet&amp;rft_id=https%3A%2F%2Fgithub.com%2Fzihangdai%2Fxlnet%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-gAbNO-137"><span class="mw-cite-backlink"><b><a href="#cite_ref-gAbNO_137-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFNaik2021" class="citation web cs1">Naik, Amit Raja (September 23, 2021). <a rel="nofollow" class="external text" href="https://analyticsindiamag.com/google-introduces-new-architecture-to-reduce-cost-of-transformers/">"Google Introduces New Architecture To Reduce Cost Of Transformers"</a>. <i>Analytics India Magazine</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Analytics+India+Magazine&amp;rft.atitle=Google+Introduces+New+Architecture+To+Reduce+Cost+Of+Transformers&amp;rft.date=2021-09-23&amp;rft.aulast=Naik&amp;rft.aufirst=Amit+Raja&amp;rft_id=https%3A%2F%2Fanalyticsindiamag.com%2Fgoogle-introduces-new-architecture-to-reduce-cost-of-transformers%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-LX3rI-138"><span class="mw-cite-backlink"><b><a href="#cite_ref-LX3rI_138-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFYangDaiYangCarbonell2020" class="citation arxiv cs1">Yang,
 Zhilin; Dai, Zihang; Yang, Yiming; Carbonell, Jaime; Salakhutdinov, 
Ruslan; Le, Quoc V. (2 January 2020). "XLNet: Generalized Autoregressive
 Pretraining for Language Understanding". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1906.08237">1906.08237</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=XLNet%3A+Generalized+Autoregressive+Pretraining+for+Language+Understanding&amp;rft.date=2020-01-02&amp;rft_id=info%3Aarxiv%2F1906.08237&amp;rft.aulast=Yang&amp;rft.aufirst=Zhilin&amp;rft.au=Dai%2C+Zihang&amp;rft.au=Yang%2C+Yiming&amp;rft.au=Carbonell%2C+Jaime&amp;rft.au=Salakhutdinov%2C+Ruslan&amp;rft.au=Le%2C+Quoc+V.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-15Brelease-139"><span class="mw-cite-backlink"><b><a href="#cite_ref-15Brelease_139-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://openai.com/blog/gpt-2-1-5b-release/">"GPT-2: 1.5B Release"</a>. <i>OpenAI</i>. 2019-11-05. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20191114074358/https://openai.com/blog/gpt-2-1-5b-release/">Archived</a> from the original on 2019-11-14<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-11-14</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=OpenAI&amp;rft.atitle=GPT-2%3A+1.5B+Release&amp;rft.date=2019-11-05&amp;rft_id=https%3A%2F%2Fopenai.com%2Fblog%2Fgpt-2-1-5b-release%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-5T8u5-140"><span class="mw-cite-backlink"><b><a href="#cite_ref-5T8u5_140-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://openai.com/research/better-language-models">"Better language models and their implications"</a>. <i>openai.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=openai.com&amp;rft.atitle=Better+language+models+and+their+implications&amp;rft_id=https%3A%2F%2Fopenai.com%2Fresearch%2Fbetter-language-models&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-LambdaLabs-141"><span class="mw-cite-backlink">^ <a href="#cite_ref-LambdaLabs_141-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-LambdaLabs_141-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://lambdalabs.com/blog/demystifying-gpt-3">"OpenAI's GPT-3 Language Model: A Technical Overview"</a>. <i>lambdalabs.com</i>. 3 June 2020.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=lambdalabs.com&amp;rft.atitle=OpenAI%27s+GPT-3+Language+Model%3A+A+Technical+Overview&amp;rft.date=2020-06-03&amp;rft_id=https%3A%2F%2Flambdalabs.com%2Fblog%2Fdemystifying-gpt-3&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Sudbe-142"><span class="mw-cite-backlink"><b><a href="#cite_ref-Sudbe_142-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/openai/gpt-2">"gpt-2"</a>. <i>GitHub</i><span class="reference-accessdate">. Retrieved <span class="nowrap">13 March</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=gpt-2&amp;rft_id=https%3A%2F%2Fgithub.com%2Fopenai%2Fgpt-2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:2-143"><span class="mw-cite-backlink"><b><a href="#cite_ref-:2_143-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">Table D.1 in <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBrownMannRyderSubbiah2020" class="citation arxiv cs1">Brown,
 Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; 
Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; 
Askell, Amanda; Agarwal, Sandhini; Herbert-Voss, Ariel; Krueger, 
Gretchen; Henighan, Tom; Child, Rewon; Ramesh, Aditya; Ziegler, Daniel 
M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark; 
Sigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, 
Jack; Berner, Christopher; McCandlish, Sam; Radford, Alec; Sutskever, 
Ilya; Amodei, Dario (May 28, 2020). "Language Models are Few-Shot 
Learners". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2005.14165v4">2005.14165v4</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Language+Models+are+Few-Shot+Learners&amp;rft.date=2020-05-28&amp;rft_id=info%3Aarxiv%2F2005.14165v4&amp;rft.aulast=Brown&amp;rft.aufirst=Tom+B.&amp;rft.au=Mann%2C+Benjamin&amp;rft.au=Ryder%2C+Nick&amp;rft.au=Subbiah%2C+Melanie&amp;rft.au=Kaplan%2C+Jared&amp;rft.au=Dhariwal%2C+Prafulla&amp;rft.au=Neelakantan%2C+Arvind&amp;rft.au=Shyam%2C+Pranav&amp;rft.au=Sastry%2C+Girish&amp;rft.au=Askell%2C+Amanda&amp;rft.au=Agarwal%2C+Sandhini&amp;rft.au=Herbert-Voss%2C+Ariel&amp;rft.au=Krueger%2C+Gretchen&amp;rft.au=Henighan%2C+Tom&amp;rft.au=Child%2C+Rewon&amp;rft.au=Ramesh%2C+Aditya&amp;rft.au=Ziegler%2C+Daniel+M.&amp;rft.au=Wu%2C+Jeffrey&amp;rft.au=Winter%2C+Clemens&amp;rft.au=Hesse%2C+Christopher&amp;rft.au=Chen%2C+Mark&amp;rft.au=Sigler%2C+Eric&amp;rft.au=Litwin%2C+Mateusz&amp;rft.au=Gray%2C+Scott&amp;rft.au=Chess%2C+Benjamin&amp;rft.au=Clark%2C+Jack&amp;rft.au=Berner%2C+Christopher&amp;rft.au=McCandlish%2C+Sam&amp;rft.au=Radford%2C+Alec&amp;rft.au=Sutskever%2C+Ilya&amp;rft.au=Amodei%2C+Dario&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-chatgpt-blog-144"><span class="mw-cite-backlink"><b><a href="#cite_ref-chatgpt-blog_144-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://openai.com/blog/chatgpt/">"ChatGPT: Optimizing Language Models for Dialogue"</a>. <i>OpenAI</i>. 2022-11-30<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-01-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=OpenAI&amp;rft.atitle=ChatGPT%3A+Optimizing+Language+Models+for+Dialogue&amp;rft.date=2022-11-30&amp;rft_id=https%3A%2F%2Fopenai.com%2Fblog%2Fchatgpt%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-gpt-neo-145"><span class="mw-cite-backlink"><b><a href="#cite_ref-gpt-neo_145-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/EleutherAI/gpt-neo">"GPT Neo"</a>. March 15, 2023 – via GitHub.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=GPT+Neo&amp;rft.date=2023-03-15&amp;rft_id=https%3A%2F%2Fgithub.com%2FEleutherAI%2Fgpt-neo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Pile-146"><span class="mw-cite-backlink">^ <a href="#cite_ref-Pile_146-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Pile_146-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Pile_146-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFGaoBidermanBlackGolding2020" class="citation arxiv cs1">Gao,
 Leo; Biderman, Stella; Black, Sid; Golding, Laurence; Hoppe, Travis; 
Foster, Charles; Phang, Jason; He, Horace; Thite, Anish; Nabeshima, Noa;
 Presser, Shawn; Leahy, Connor (31 December 2020). "The Pile: An 800GB 
Dataset of Diverse Text for Language Modeling". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2101.00027">2101.00027</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=The+Pile%3A+An+800GB+Dataset+of+Diverse+Text+for+Language+Modeling&amp;rft.date=2020-12-31&amp;rft_id=info%3Aarxiv%2F2101.00027&amp;rft.aulast=Gao&amp;rft.aufirst=Leo&amp;rft.au=Biderman%2C+Stella&amp;rft.au=Black%2C+Sid&amp;rft.au=Golding%2C+Laurence&amp;rft.au=Hoppe%2C+Travis&amp;rft.au=Foster%2C+Charles&amp;rft.au=Phang%2C+Jason&amp;rft.au=He%2C+Horace&amp;rft.au=Thite%2C+Anish&amp;rft.au=Nabeshima%2C+Noa&amp;rft.au=Presser%2C+Shawn&amp;rft.au=Leahy%2C+Connor&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-vb-gpt-neo-147"><span class="mw-cite-backlink">^ <a href="#cite_ref-vb-gpt-neo_147-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-vb-gpt-neo_147-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFIyer2021" class="citation web cs1">Iyer, Abhishek (15 May 2021). <a rel="nofollow" class="external text" href="https://venturebeat.com/ai/gpt-3s-free-alternative-gpt-neo-is-something-to-be-excited-about/">"GPT-3's free alternative GPT-Neo is something to be excited about"</a>. <i>VentureBeat</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=VentureBeat&amp;rft.atitle=GPT-3%27s+free+alternative+GPT-Neo+is+something+to+be+excited+about&amp;rft.date=2021-05-15&amp;rft.aulast=Iyer&amp;rft.aufirst=Abhishek&amp;rft_id=https%3A%2F%2Fventurebeat.com%2Fai%2Fgpt-3s-free-alternative-gpt-neo-is-something-to-be-excited-about%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-JxohJ-148"><span class="mw-cite-backlink"><b><a href="#cite_ref-JxohJ_148-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.forefront.ai/blog-posts/gpt-j-6b-an-introduction-to-the-largest-open-sourced-gpt-model">"GPT-J-6B: An Introduction to the Largest Open Source GPT Model | Forefront"</a>. <i>www.forefront.ai</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-02-28</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.forefront.ai&amp;rft.atitle=GPT-J-6B%3A+An+Introduction+to+the+Largest+Open+Source+GPT+Model+%7C+Forefront&amp;rft_id=https%3A%2F%2Fwww.forefront.ai%2Fblog-posts%2Fgpt-j-6b-an-introduction-to-the-largest-open-sourced-gpt-model&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:3-149"><span class="mw-cite-backlink">^ <a href="#cite_ref-:3_149-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:3_149-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:3_149-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-:3_149-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDeyGosalZhimingChen2023" class="citation arxiv cs1">Dey,
 Nolan; Gosal, Gurpreet; Zhiming; Chen; Khachane, Hemant; Marshall, 
William; Pathria, Ribhu; Tom, Marvin; Hestness, Joel (2023-04-01). 
"Cerebras-GPT: Open Compute-Optimal Language Models Trained on the 
Cerebras Wafer-Scale Cluster". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2304.03208">2304.03208</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Cerebras-GPT%3A+Open+Compute-Optimal+Language+Models+Trained+on+the+Cerebras+Wafer-Scale+Cluster&amp;rft.date=2023-04-01&amp;rft_id=info%3Aarxiv%2F2304.03208&amp;rft.aulast=Dey&amp;rft.aufirst=Nolan&amp;rft.au=Gosal%2C+Gurpreet&amp;rft.au=Zhiming&amp;rft.au=Chen&amp;rft.au=Khachane%2C+Hemant&amp;rft.au=Marshall%2C+William&amp;rft.au=Pathria%2C+Ribhu&amp;rft.au=Tom%2C+Marvin&amp;rft.au=Hestness%2C+Joel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-BwnW5-150"><span class="mw-cite-backlink"><b><a href="#cite_ref-BwnW5_150-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAlviKharya2021" class="citation web cs1">Alvi, Ali; Kharya, Paresh (11 October 2021). <a rel="nofollow" class="external text" href="https://www.microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/">"Using
 DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, the World's 
Largest and Most Powerful Generative Language Model"</a>. <i>Microsoft Research</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Microsoft+Research&amp;rft.atitle=Using+DeepSpeed+and+Megatron+to+Train+Megatron-Turing+NLG+530B%2C+the+World%27s+Largest+and+Most+Powerful+Generative+Language+Model&amp;rft.date=2021-10-11&amp;rft.aulast=Alvi&amp;rft.aufirst=Ali&amp;rft.au=Kharya%2C+Paresh&amp;rft_id=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fusing-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-mtnlg-preprint-151"><span class="mw-cite-backlink">^ <a href="#cite_ref-mtnlg-preprint_151-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-mtnlg-preprint_151-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFSmithPatwaryNorickLeGresley2022" class="citation arxiv cs1">Smith,
 Shaden; Patwary, Mostofa; Norick, Brandon; LeGresley, Patrick; 
Rajbhandari, Samyam; Casper, Jared; Liu, Zhun; Prabhumoye, Shrimai; 
Zerveas, George; Korthikanti, Vijay; Zhang, Elton; Child, Rewon; 
Aminabadi, Reza Yazdani; Bernauer, Julie; Song, Xia (2022-02-04). "Using
 DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale
 Generative Language Model". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2201.11990">2201.11990</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Using+DeepSpeed+and+Megatron+to+Train+Megatron-Turing+NLG+530B%2C+A+Large-Scale+Generative+Language+Model&amp;rft.date=2022-02-04&amp;rft_id=info%3Aarxiv%2F2201.11990&amp;rft.aulast=Smith&amp;rft.aufirst=Shaden&amp;rft.au=Patwary%2C+Mostofa&amp;rft.au=Norick%2C+Brandon&amp;rft.au=LeGresley%2C+Patrick&amp;rft.au=Rajbhandari%2C+Samyam&amp;rft.au=Casper%2C+Jared&amp;rft.au=Liu%2C+Zhun&amp;rft.au=Prabhumoye%2C+Shrimai&amp;rft.au=Zerveas%2C+George&amp;rft.au=Korthikanti%2C+Vijay&amp;rft.au=Zhang%2C+Elton&amp;rft.au=Child%2C+Rewon&amp;rft.au=Aminabadi%2C+Reza+Yazdani&amp;rft.au=Bernauer%2C+Julie&amp;rft.au=Song%2C+Xia&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-qeOB8-152"><span class="mw-cite-backlink"><b><a href="#cite_ref-qeOB8_152-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWangSunXiangWu2021" class="citation arxiv cs1">Wang,
 Shuohuan; Sun, Yu; Xiang, Yang; Wu, Zhihua; Ding, Siyu; Gong, Weibao; 
Feng, Shikun; Shang, Junyuan; Zhao, Yanbin; Pang, Chao; Liu, Jiaxiang; 
Chen, Xuyi; Lu, Yuxiang; Liu, Weixin; Wang, Xi; Bai, Yangfan; Chen, 
Qiuliang; Zhao, Li; Li, Shiyong; Sun, Peng; Yu, Dianhai; Ma, Yanjun; 
Tian, Hao; Wu, Hua; Wu, Tian; Zeng, Wei; Li, Ge; Gao, Wen; Wang, Haifeng
 (December 23, 2021). "ERNIE 3.0 Titan: Exploring Larger-scale Knowledge
 Enhanced Pre-training for Language Understanding and Generation". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2112.12731">2112.12731</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=ERNIE+3.0+Titan%3A+Exploring+Larger-scale+Knowledge+Enhanced+Pre-training+for+Language+Understanding+and+Generation&amp;rft.date=2021-12-23&amp;rft_id=info%3Aarxiv%2F2112.12731&amp;rft.aulast=Wang&amp;rft.aufirst=Shuohuan&amp;rft.au=Sun%2C+Yu&amp;rft.au=Xiang%2C+Yang&amp;rft.au=Wu%2C+Zhihua&amp;rft.au=Ding%2C+Siyu&amp;rft.au=Gong%2C+Weibao&amp;rft.au=Feng%2C+Shikun&amp;rft.au=Shang%2C+Junyuan&amp;rft.au=Zhao%2C+Yanbin&amp;rft.au=Pang%2C+Chao&amp;rft.au=Liu%2C+Jiaxiang&amp;rft.au=Chen%2C+Xuyi&amp;rft.au=Lu%2C+Yuxiang&amp;rft.au=Liu%2C+Weixin&amp;rft.au=Wang%2C+Xi&amp;rft.au=Bai%2C+Yangfan&amp;rft.au=Chen%2C+Qiuliang&amp;rft.au=Zhao%2C+Li&amp;rft.au=Li%2C+Shiyong&amp;rft.au=Sun%2C+Peng&amp;rft.au=Yu%2C+Dianhai&amp;rft.au=Ma%2C+Yanjun&amp;rft.au=Tian%2C+Hao&amp;rft.au=Wu%2C+Hua&amp;rft.au=Wu%2C+Tian&amp;rft.au=Zeng%2C+Wei&amp;rft.au=Li%2C+Ge&amp;rft.au=Gao%2C+Wen&amp;rft.au=Wang%2C+Haifeng&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-i8jc4-153"><span class="mw-cite-backlink"><b><a href="#cite_ref-i8jc4_153-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.anthropic.com/product">"Product"</a>. <i>Anthropic</i><span class="reference-accessdate">. Retrieved <span class="nowrap">14 March</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Anthropic&amp;rft.atitle=Product&amp;rft_id=https%3A%2F%2Fwww.anthropic.com%2Fproduct&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-AnthroArch-154"><span class="mw-cite-backlink">^ <a href="#cite_ref-AnthroArch_154-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-AnthroArch_154-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAskellBaiChenDrain2021" class="citation arxiv cs1">Askell,
 Amanda; Bai, Yuntao; Chen, Anna; et&nbsp;al. (9 December 2021). "A 
General Language Assistant as a Laboratory for Alignment". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2112.00861">2112.00861</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+General+Language+Assistant+as+a+Laboratory+for+Alignment&amp;rft.date=2021-12-09&amp;rft_id=info%3Aarxiv%2F2112.00861&amp;rft.aulast=Askell&amp;rft.aufirst=Amanda&amp;rft.au=Bai%2C+Yuntao&amp;rft.au=Chen%2C+Anna&amp;rft.au=Drain%2C+Dawn&amp;rft.au=Ganguli%2C+Deep&amp;rft.au=Henighan%2C+Tom&amp;rft.au=Jones%2C+Andy&amp;rft.au=Joseph%2C+Nicholas&amp;rft.au=Mann%2C+Ben&amp;rft.au=DasSarma%2C+Nova&amp;rft.au=Elhage%2C+Nelson&amp;rft.au=Hatfield-Dodds%2C+Zac&amp;rft.au=Hernandez%2C+Danny&amp;rft.au=Kernion%2C+Jackson&amp;rft.au=Ndousse%2C+Kamal&amp;rft.au=Olsson%2C+Catherine&amp;rft.au=Amodei%2C+Dario&amp;rft.au=Brown%2C+Tom&amp;rft.au=Clark%2C+Jack&amp;rft.au=McCandlish%2C+Sam&amp;rft.au=Olah%2C+Chris&amp;rft.au=Kaplan%2C+Jared&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-RZqhw-155"><span class="mw-cite-backlink"><b><a href="#cite_ref-RZqhw_155-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBaiKadavathKunduAskell2022" class="citation arxiv cs1">Bai,
 Yuntao; Kadavath, Saurav; Kundu, Sandipan; et&nbsp;al. (15 December 
2022). "Constitutional AI: Harmlessness from AI Feedback". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2212.08073">2212.08073</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Constitutional+AI%3A+Harmlessness+from+AI+Feedback&amp;rft.date=2022-12-15&amp;rft_id=info%3Aarxiv%2F2212.08073&amp;rft.aulast=Bai&amp;rft.aufirst=Yuntao&amp;rft.au=Kadavath%2C+Saurav&amp;rft.au=Kundu%2C+Sandipan&amp;rft.au=Askell%2C+Amanda&amp;rft.au=Kernion%2C+Jackson&amp;rft.au=Jones%2C+Andy&amp;rft.au=Chen%2C+Anna&amp;rft.au=Goldie%2C+Anna&amp;rft.au=Mirhoseini%2C+Azalia&amp;rft.au=McKinnon%2C+Cameron&amp;rft.au=Chen%2C+Carol&amp;rft.au=Olsson%2C+Catherine&amp;rft.au=Olah%2C+Christopher&amp;rft.au=Hernandez%2C+Danny&amp;rft.au=Drain%2C+Dawn&amp;rft.au=Ganguli%2C+Deep&amp;rft.au=Li%2C+Dustin&amp;rft.au=Tran-Johnson%2C+Eli&amp;rft.au=Perez%2C+Ethan&amp;rft.au=Kerr%2C+Jamie&amp;rft.au=Mueller%2C+Jared&amp;rft.au=Ladish%2C+Jeffrey&amp;rft.au=Landau%2C+Joshua&amp;rft.au=Ndousse%2C+Kamal&amp;rft.au=Lukosuite%2C+Kamile&amp;rft.au=Lovitt%2C+Liane&amp;rft.au=Sellitto%2C+Michael&amp;rft.au=Elhage%2C+Nelson&amp;rft.au=Schiefer%2C+Nicholas&amp;rft.au=Mercado%2C+Noemi&amp;rft.au=DasSarma%2C+Nova&amp;rft.au=Lasenby%2C+Robert&amp;rft.au=Larson%2C+Robin&amp;rft.au=Ringer%2C+Sam&amp;rft.au=Johnston%2C+Scott&amp;rft.au=Kravec%2C+Shauna&amp;rft.au=Showk%2C+Sheer+El&amp;rft.au=Fort%2C+Stanislav&amp;rft.au=Lanham%2C+Tamera&amp;rft.au=Telleen-Lawton%2C+Timothy&amp;rft.au=Conerly%2C+Tom&amp;rft.au=Henighan%2C+Tom&amp;rft.au=Hume%2C+Tristan&amp;rft.au=Bowman%2C+Samuel+R.&amp;rft.au=Hatfield-Dodds%2C+Zac&amp;rft.au=Mann%2C+Ben&amp;rft.au=Amodei%2C+Dario&amp;rft.au=Joseph%2C+Nicholas&amp;rft.au=McCandlish%2C+Sam&amp;rft.au=Brown%2C+Tom&amp;rft.au=Kaplan%2C+Jared&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-mD5eE-156"><span class="mw-cite-backlink"><b><a href="#cite_ref-mD5eE_156-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval">"Language modelling at scale: Gopher, ethical considerations, and retrieval"</a>. <i>www.deepmind.com</i>. 8 December 2021<span class="reference-accessdate">. Retrieved <span class="nowrap">20 March</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.deepmind.com&amp;rft.atitle=Language+modelling+at+scale%3A+Gopher%2C+ethical+considerations%2C+and+retrieval&amp;rft.date=2021-12-08&amp;rft_id=https%3A%2F%2Fwww.deepmind.com%2Fblog%2Flanguage-modelling-at-scale-gopher-ethical-considerations-and-retrieval&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-hoffman-157"><span class="mw-cite-backlink">^ <a href="#cite_ref-hoffman_157-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-hoffman_157-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-hoffman_157-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHoffmannBorgeaudMenschBuchatskaya2022" class="citation arxiv cs1">Hoffmann,
 Jordan; Borgeaud, Sebastian; Mensch, Arthur; et&nbsp;al. (29 March 
2022). "Training Compute-Optimal Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2203.15556">2203.15556</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Training+Compute-Optimal+Large+Language+Models&amp;rft.date=2022-03-29&amp;rft_id=info%3Aarxiv%2F2203.15556&amp;rft.aulast=Hoffmann&amp;rft.aufirst=Jordan&amp;rft.au=Borgeaud%2C+Sebastian&amp;rft.au=Mensch%2C+Arthur&amp;rft.au=Buchatskaya%2C+Elena&amp;rft.au=Cai%2C+Trevor&amp;rft.au=Rutherford%2C+Eliza&amp;rft.au=Casas%2C+Diego+de+Las&amp;rft.au=Hendricks%2C+Lisa+Anne&amp;rft.au=Welbl%2C+Johannes&amp;rft.au=Clark%2C+Aidan&amp;rft.au=Hennigan%2C+Tom&amp;rft.au=Noland%2C+Eric&amp;rft.au=Millican%2C+Katie&amp;rft.au=Driessche%2C+George+van+den&amp;rft.au=Damoc%2C+Bogdan&amp;rft.au=Guy%2C+Aurelia&amp;rft.au=Osindero%2C+Simon&amp;rft.au=Simonyan%2C+Karen&amp;rft.au=Elsen%2C+Erich&amp;rft.au=Rae%2C+Jack+W.&amp;rft.au=Vinyals%2C+Oriol&amp;rft.au=Sifre%2C+Laurent&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:4-158"><span class="mw-cite-backlink">^ <a href="#cite_ref-:4_158-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:4_158-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:4_158-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-:4_158-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text">Table 20 and page 66 of <i><a rel="nofollow" class="external text" href="https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf">PaLM: Scaling Language Modeling with Pathways</a></i></span>
</li>
<li id="cite_note-lamda-blog-159"><span class="mw-cite-backlink">^ <a href="#cite_ref-lamda-blog_159-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-lamda-blog_159-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFChengThoppilan2022" class="citation web cs1">Cheng, Heng-Tze; Thoppilan, Romal (January 21, 2022). <a rel="nofollow" class="external text" href="https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html">"LaMDA: Towards Safe, Grounded, and High-Quality Dialog Models for Everything"</a>. <i>ai.googleblog.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-03-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.googleblog.com&amp;rft.atitle=LaMDA%3A+Towards+Safe%2C+Grounded%2C+and+High-Quality+Dialog+Models+for+Everything&amp;rft.date=2022-01-21&amp;rft.aulast=Cheng&amp;rft.aufirst=Heng-Tze&amp;rft.au=Thoppilan%2C+Romal&amp;rft_id=https%3A%2F%2Fai.googleblog.com%2F2022%2F01%2Flamda-towards-safe-grounded-and-high.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-DMs9Z-160"><span class="mw-cite-backlink"><b><a href="#cite_ref-DMs9Z_160-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFThoppilanDe_FreitasHallShazeer2022" class="citation arxiv cs1">Thoppilan,
 Romal; De Freitas, Daniel; Hall, Jamie; Shazeer, Noam; Kulshreshtha, 
Apoorv; Cheng, Heng-Tze; Jin, Alicia; Bos, Taylor; Baker, Leslie; Du, 
Yu; Li, YaGuang; Lee, Hongrae; Zheng, Huaixiu Steven; Ghafouri, Amin; 
Menegali, Marcelo (2022-01-01). "LaMDA: Language Models for Dialog 
Applications". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2201.08239">2201.08239</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=LaMDA%3A+Language+Models+for+Dialog+Applications&amp;rft.date=2022-01-01&amp;rft_id=info%3Aarxiv%2F2201.08239&amp;rft.aulast=Thoppilan&amp;rft.aufirst=Romal&amp;rft.au=De+Freitas%2C+Daniel&amp;rft.au=Hall%2C+Jamie&amp;rft.au=Shazeer%2C+Noam&amp;rft.au=Kulshreshtha%2C+Apoorv&amp;rft.au=Cheng%2C+Heng-Tze&amp;rft.au=Jin%2C+Alicia&amp;rft.au=Bos%2C+Taylor&amp;rft.au=Baker%2C+Leslie&amp;rft.au=Du%2C+Yu&amp;rft.au=Li%2C+YaGuang&amp;rft.au=Lee%2C+Hongrae&amp;rft.au=Zheng%2C+Huaixiu+Steven&amp;rft.au=Ghafouri%2C+Amin&amp;rft.au=Menegali%2C+Marcelo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-gpt-neox-20b-161"><span class="mw-cite-backlink"><b><a href="#cite_ref-gpt-neox-20b_161-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBlackBidermanHallahan2022" class="citation conference cs1 cs1-prop-long-vol">Black, Sidney; Biderman, Stella; Hallahan, Eric; et&nbsp;al. (2022-05-01). <a rel="nofollow" class="external text" href="https://aclanthology.org/2022.bigscience-1.9/"><i>GPT-NeoX-20B: An Open-Source Autoregressive Language Model</i></a>.
 Proceedings of BigScience Episode #5 – Workshop on Challenges &amp; 
Perspectives in Creating Large Language Models. Vol.&nbsp;Proceedings of
 BigScience Episode #5 – Workshop on Challenges &amp; Perspectives in 
Creating Large Language Models. pp.&nbsp;95–136<span class="reference-accessdate">. Retrieved <span class="nowrap">2022-12-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=GPT-NeoX-20B%3A+An+Open-Source+Autoregressive+Language+Model&amp;rft.pages=95-136&amp;rft.date=2022-05-01&amp;rft.aulast=Black&amp;rft.aufirst=Sidney&amp;rft.au=Biderman%2C+Stella&amp;rft.au=Hallahan%2C+Eric&amp;rft_id=https%3A%2F%2Faclanthology.org%2F2022.bigscience-1.9%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-chinchilla-blog-162"><span class="mw-cite-backlink">^ <a href="#cite_ref-chinchilla-blog_162-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-chinchilla-blog_162-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-chinchilla-blog_162-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHoffmannBorgeaudMenschSifre2022" class="citation web cs1">Hoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; Sifre, Laurent (12 April 2022). <a rel="nofollow" class="external text" href="https://www.deepmind.com/blog/an-empirical-analysis-of-compute-optimal-large-language-model-training">"An empirical analysis of compute-optimal large language model training"</a>. <i>Deepmind Blog</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Deepmind+Blog&amp;rft.atitle=An+empirical+analysis+of+compute-optimal+large+language+model+training&amp;rft.date=2022-04-12&amp;rft.aulast=Hoffmann&amp;rft.aufirst=Jordan&amp;rft.au=Borgeaud%2C+Sebastian&amp;rft.au=Mensch%2C+Arthur&amp;rft.au=Sifre%2C+Laurent&amp;rft_id=https%3A%2F%2Fwww.deepmind.com%2Fblog%2Fan-empirical-analysis-of-compute-optimal-large-language-model-training&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-palm-blog-163"><span class="mw-cite-backlink"><b><a href="#cite_ref-palm-blog_163-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFNarangChowdhery2022" class="citation web cs1">Narang, Sharan; Chowdhery, Aakanksha (April 4, 2022). <a rel="nofollow" class="external text" href="https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html">"Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance"</a>. <i>ai.googleblog.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-03-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.googleblog.com&amp;rft.atitle=Pathways+Language+Model+%28PaLM%29%3A+Scaling+to+540+Billion+Parameters+for+Breakthrough+Performance&amp;rft.date=2022-04-04&amp;rft.aulast=Narang&amp;rft.aufirst=Sharan&amp;rft.au=Chowdhery%2C+Aakanksha&amp;rft_id=https%3A%2F%2Fai.googleblog.com%2F2022%2F04%2Fpathways-language-model-palm-scaling-to.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-jlof8-164"><span class="mw-cite-backlink"><b><a href="#cite_ref-jlof8_164-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/">"Democratizing access to large-scale language models with OPT-175B"</a>. <i>ai.facebook.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.facebook.com&amp;rft.atitle=Democratizing+access+to+large-scale+language+models+with+OPT-175B&amp;rft_id=https%3A%2F%2Fai.facebook.com%2Fblog%2Fdemocratizing-access-to-large-scale-language-models-with-opt-175b%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-QjTIc-165"><span class="mw-cite-backlink"><b><a href="#cite_ref-QjTIc_165-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZhangRollerGoyalArtetxe2022" class="citation arxiv cs1">Zhang,
 Susan; Roller, Stephen; Goyal, Naman; Artetxe, Mikel; Chen, Moya; Chen,
 Shuohui; Dewan, Christopher; Diab, Mona; Li, Xian; Lin, Xi Victoria; 
Mihaylov, Todor; Ott, Myle; Shleifer, Sam; Shuster, Kurt; Simig, Daniel;
 Koura, Punit Singh; Sridhar, Anjali; Wang, Tianlu; Zettlemoyer, Luke 
(21 June 2022). "OPT: Open Pre-trained Transformer Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2205.01068">2205.01068</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=OPT%3A+Open+Pre-trained+Transformer+Language+Models&amp;rft.date=2022-06-21&amp;rft_id=info%3Aarxiv%2F2205.01068&amp;rft.aulast=Zhang&amp;rft.aufirst=Susan&amp;rft.au=Roller%2C+Stephen&amp;rft.au=Goyal%2C+Naman&amp;rft.au=Artetxe%2C+Mikel&amp;rft.au=Chen%2C+Moya&amp;rft.au=Chen%2C+Shuohui&amp;rft.au=Dewan%2C+Christopher&amp;rft.au=Diab%2C+Mona&amp;rft.au=Li%2C+Xian&amp;rft.au=Lin%2C+Xi+Victoria&amp;rft.au=Mihaylov%2C+Todor&amp;rft.au=Ott%2C+Myle&amp;rft.au=Shleifer%2C+Sam&amp;rft.au=Shuster%2C+Kurt&amp;rft.au=Simig%2C+Daniel&amp;rft.au=Koura%2C+Punit+Singh&amp;rft.au=Sridhar%2C+Anjali&amp;rft.au=Wang%2C+Tianlu&amp;rft.au=Zettlemoyer%2C+Luke&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-yalm-repo-167"><span class="mw-cite-backlink">^ <a href="#cite_ref-yalm-repo_167-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-yalm-repo_167-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKhrushchevVasilevPetrovZinov2022" class="citation cs2">Khrushchev, Mikhail; Vasilev, Ruslan; Petrov, Alexey; Zinov, Nikolay (2022-06-22), <a rel="nofollow" class="external text" href="https://github.com/yandex/YaLM-100B"><i>YaLM 100B</i></a><span class="reference-accessdate">, retrieved <span class="nowrap">2023-03-18</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=YaLM+100B&amp;rft.date=2022-06-22&amp;rft.aulast=Khrushchev&amp;rft.aufirst=Mikhail&amp;rft.au=Vasilev%2C+Ruslan&amp;rft.au=Petrov%2C+Alexey&amp;rft.au=Zinov%2C+Nikolay&amp;rft_id=https%3A%2F%2Fgithub.com%2Fyandex%2FYaLM-100B&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-minerva-paper-168"><span class="mw-cite-backlink">^ <a href="#cite_ref-minerva-paper_168-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-minerva-paper_168-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLewkowyczAndreassenDohanDyer2022" class="citation arxiv cs1">Lewkowycz,
 Aitor; Andreassen, Anders; Dohan, David; Dyer, Ethan; Michalewski, 
Henryk; Ramasesh, Vinay; Slone, Ambrose; Anil, Cem; Schlag, Imanol; 
Gutman-Solo, Theo; Wu, Yuhuai; Neyshabur, Behnam; Gur-Ari, Guy; Misra, 
Vedant (30 June 2022). "Solving Quantitative Reasoning Problems with 
Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2206.14858">2206.14858</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Solving+Quantitative+Reasoning+Problems+with+Language+Models&amp;rft.date=2022-06-30&amp;rft_id=info%3Aarxiv%2F2206.14858&amp;rft.aulast=Lewkowycz&amp;rft.aufirst=Aitor&amp;rft.au=Andreassen%2C+Anders&amp;rft.au=Dohan%2C+David&amp;rft.au=Dyer%2C+Ethan&amp;rft.au=Michalewski%2C+Henryk&amp;rft.au=Ramasesh%2C+Vinay&amp;rft.au=Slone%2C+Ambrose&amp;rft.au=Anil%2C+Cem&amp;rft.au=Schlag%2C+Imanol&amp;rft.au=Gutman-Solo%2C+Theo&amp;rft.au=Wu%2C+Yuhuai&amp;rft.au=Neyshabur%2C+Behnam&amp;rft.au=Gur-Ari%2C+Guy&amp;rft.au=Misra%2C+Vedant&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-FfCNK-169"><span class="mw-cite-backlink"><b><a href="#cite_ref-FfCNK_169-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html">"Minerva: Solving Quantitative Reasoning Problems with Language Models"</a>. <i>ai.googleblog.com</i>. 30 June 2022<span class="reference-accessdate">. Retrieved <span class="nowrap">20 March</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.googleblog.com&amp;rft.atitle=Minerva%3A+Solving+Quantitative+Reasoning+Problems+with+Language+Models&amp;rft.date=2022-06-30&amp;rft_id=https%3A%2F%2Fai.googleblog.com%2F2022%2F06%2Fminerva-solving-quantitative-reasoning.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-bigger-better-170"><span class="mw-cite-backlink"><b><a href="#cite_ref-bigger-better_170-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAnanthaswamy2023" class="citation journal cs1">Ananthaswamy, Anil (8 March 2023). <a rel="nofollow" class="external text" href="https://www.nature.com/articles/d41586-023-00641-w">"In AI, is bigger always better?"</a>. <i>Nature</i>. <b>615</b> (7951): 202–205. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2023Natur.615..202A">2023Natur.615..202A</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fd41586-023-00641-w">10.1038/d41586-023-00641-w</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/36890378">36890378</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:257380916">257380916</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=In+AI%2C+is+bigger+always+better%3F&amp;rft.volume=615&amp;rft.issue=7951&amp;rft.pages=202-205&amp;rft.date=2023-03-08&amp;rft_id=info%3Adoi%2F10.1038%2Fd41586-023-00641-w&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A257380916%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F36890378&amp;rft_id=info%3Abibcode%2F2023Natur.615..202A&amp;rft.aulast=Ananthaswamy&amp;rft.aufirst=Anil&amp;rft_id=https%3A%2F%2Fwww.nature.com%2Farticles%2Fd41586-023-00641-w&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-B8wB2-171"><span class="mw-cite-backlink"><b><a href="#cite_ref-B8wB2_171-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://huggingface.co/bigscience/bloom">"bigscience/bloom · Hugging Face"</a>. <i>huggingface.co</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=huggingface.co&amp;rft.atitle=bigscience%2Fbloom+%C2%B7+Hugging+Face&amp;rft_id=https%3A%2F%2Fhuggingface.co%2Fbigscience%2Fbloom&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-37sY6-172"><span class="mw-cite-backlink"><b><a href="#cite_ref-37sY6_172-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFTaylorKardasCucurullScialom2022" class="citation arxiv cs1">Taylor,
 Ross; Kardas, Marcin; Cucurull, Guillem; Scialom, Thomas; Hartshorn, 
Anthony; Saravia, Elvis; Poulton, Andrew; Kerkez, Viktor; Stojnic, 
Robert (16 November 2022). "Galactica: A Large Language Model for 
Science". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2211.09085">2211.09085</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Galactica%3A+A+Large+Language+Model+for+Science&amp;rft.date=2022-11-16&amp;rft_id=info%3Aarxiv%2F2211.09085&amp;rft.aulast=Taylor&amp;rft.aufirst=Ross&amp;rft.au=Kardas%2C+Marcin&amp;rft.au=Cucurull%2C+Guillem&amp;rft.au=Scialom%2C+Thomas&amp;rft.au=Hartshorn%2C+Anthony&amp;rft.au=Saravia%2C+Elvis&amp;rft.au=Poulton%2C+Andrew&amp;rft.au=Kerkez%2C+Viktor&amp;rft.au=Stojnic%2C+Robert&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-u5szh-173"><span class="mw-cite-backlink"><b><a href="#cite_ref-u5szh_173-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.amazon.science/blog/20b-parameter-alexa-model-sets-new-marks-in-few-shot-learning">"20B-parameter Alexa model sets new marks in few-shot learning"</a>. <i>Amazon Science</i>. 2 August 2022.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Amazon+Science&amp;rft.atitle=20B-parameter+Alexa+model+sets+new+marks+in+few-shot+learning&amp;rft.date=2022-08-02&amp;rft_id=https%3A%2F%2Fwww.amazon.science%2Fblog%2F20b-parameter-alexa-model-sets-new-marks-in-few-shot-learning&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-HaA7l-174"><span class="mw-cite-backlink"><b><a href="#cite_ref-HaA7l_174-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFSoltanAnanthakrishnanFitzGeraldGupta2022" class="citation arxiv cs1">Soltan,
 Saleh; Ananthakrishnan, Shankar; FitzGerald, Jack; et&nbsp;al. (3 
August 2022). "AlexaTM 20B: Few-Shot Learning Using a Large-Scale 
Multilingual Seq2Seq Model". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2208.01448">2208.01448</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=AlexaTM+20B%3A+Few-Shot+Learning+Using+a+Large-Scale+Multilingual+Seq2Seq+Model&amp;rft.date=2022-08-03&amp;rft_id=info%3Aarxiv%2F2208.01448&amp;rft.aulast=Soltan&amp;rft.aufirst=Saleh&amp;rft.au=Ananthakrishnan%2C+Shankar&amp;rft.au=FitzGerald%2C+Jack&amp;rft.au=Gupta%2C+Rahul&amp;rft.au=Hamza%2C+Wael&amp;rft.au=Khan%2C+Haidar&amp;rft.au=Peris%2C+Charith&amp;rft.au=Rawls%2C+Stephen&amp;rft.au=Rosenbaum%2C+Andy&amp;rft.au=Rumshisky%2C+Anna&amp;rft.au=Prakash%2C+Chandana+Satya&amp;rft.au=Sridhar%2C+Mukund&amp;rft.au=Triefenbach%2C+Fabian&amp;rft.au=Verma%2C+Apurv&amp;rft.au=Tur%2C+Gokhan&amp;rft.au=Natarajan%2C+Prem&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-rpehM-175"><span class="mw-cite-backlink"><b><a href="#cite_ref-rpehM_175-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://aws.amazon.com/blogs/machine-learning/alexatm-20b-is-now-available-in-amazon-sagemaker-jumpstart/">"AlexaTM 20B is now available in Amazon SageMaker JumpStart | AWS Machine Learning Blog"</a>. <i>aws.amazon.com</i>. 17 November 2022<span class="reference-accessdate">. Retrieved <span class="nowrap">13 March</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=aws.amazon.com&amp;rft.atitle=AlexaTM+20B+is+now+available+in+Amazon+SageMaker+JumpStart+%7C+AWS+Machine+Learning+Blog&amp;rft.date=2022-11-17&amp;rft_id=https%3A%2F%2Faws.amazon.com%2Fblogs%2Fmachine-learning%2Falexatm-20b-is-now-available-in-amazon-sagemaker-jumpstart%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-llama-blog-176"><span class="mw-cite-backlink">^ <a href="#cite_ref-llama-blog_176-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-llama-blog_176-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-llama-blog_176-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">"Introducing LLaMA: A foundational, 65-billion-parameter large language model"</a>. <i>Meta AI</i>. 24 February 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Meta+AI&amp;rft.atitle=Introducing+LLaMA%3A+A+foundational%2C+65-billion-parameter+large+language+model&amp;rft.date=2023-02-24&amp;rft_id=https%3A%2F%2Fai.facebook.com%2Fblog%2Flarge-language-model-llama-meta-ai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-:5-177"><span class="mw-cite-backlink">^ <a href="#cite_ref-:5_177-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:5_177-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:5_177-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://huggingface.co/blog/falcon">"The Falcon has landed in the Hugging Face ecosystem"</a>. <i>huggingface.co</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=huggingface.co&amp;rft.atitle=The+Falcon+has+landed+in+the+Hugging+Face+ecosystem&amp;rft_id=https%3A%2F%2Fhuggingface.co%2Fblog%2Ffalcon&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-KBedq-179"><span class="mw-cite-backlink"><b><a href="#cite_ref-KBedq_179-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://crfm.stanford.edu/2023/03/13/alpaca.html">"Stanford CRFM"</a>. <i>crfm.stanford.edu</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=crfm.stanford.edu&amp;rft.atitle=Stanford+CRFM&amp;rft_id=https%3A%2F%2Fcrfm.stanford.edu%2F2023%2F03%2F13%2Falpaca.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-GPT4Tech-180"><span class="mw-cite-backlink"><b><a href="#cite_ref-GPT4Tech_180-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://cdn.openai.com/papers/gpt-4.pdf">"GPT-4 Technical Report"</a> <span class="cs1-format">(PDF)</span>. <i><a href="https://en.wikipedia.org/wiki/OpenAI" title="OpenAI">OpenAI</a></i>. 2023. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20230314190904/https://cdn.openai.com/papers/gpt-4.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on March 14, 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">March 14,</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=OpenAI&amp;rft.atitle=GPT-4+Technical+Report&amp;rft.date=2023&amp;rft_id=https%3A%2F%2Fcdn.openai.com%2Fpapers%2Fgpt-4.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-D0k2a-182"><span class="mw-cite-backlink"><b><a href="#cite_ref-D0k2a_182-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDey2023" class="citation web cs1">Dey, Nolan (March 28, 2023). <a rel="nofollow" class="external text" href="https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/">"Cerebras-GPT: A Family of Open, Compute-efficient, Large Language Models"</a>. <i>Cerebras</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Cerebras&amp;rft.atitle=Cerebras-GPT%3A+A+Family+of+Open%2C+Compute-efficient%2C+Large+Language+Models&amp;rft.date=2023-03-28&amp;rft.aulast=Dey&amp;rft.aufirst=Nolan&amp;rft_id=https%3A%2F%2Fwww.cerebras.net%2Fblog%2Fcerebras-gpt-a-family-of-open-compute-efficient-large-language-models%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-falcon-183"><span class="mw-cite-backlink"><b><a href="#cite_ref-falcon_183-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://fastcompanyme.com/news/abu-dhabi-based-tii-launches-its-own-version-of-chatgpt/">"Abu Dhabi-based TII launches its own version of ChatGPT"</a>. <i>tii.ae</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=tii.ae&amp;rft.atitle=Abu+Dhabi-based+TII+launches+its+own+version+of+ChatGPT&amp;rft_id=https%3A%2F%2Ffastcompanyme.com%2Fnews%2Fabu-dhabi-based-tii-launches-its-own-version-of-chatgpt%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Xb1gq-184"><span class="mw-cite-backlink"><b><a href="#cite_ref-Xb1gq_184-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPenedoMalarticHesslowCojocaru2023" class="citation arxiv cs1">Penedo,
 Guilherme; Malartic, Quentin; Hesslow, Daniel; Cojocaru, Ruxandra; 
Cappelli, Alessandro; Alobeidli, Hamza; Pannier, Baptiste; Almazrouei, 
Ebtesam; Launay, Julien (2023-06-01). "The RefinedWeb Dataset for Falcon
 LLM: Outperforming Curated Corpora with Web Data, and Web Data Only". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2306.01116">2306.01116</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=The+RefinedWeb+Dataset+for+Falcon+LLM%3A+Outperforming+Curated+Corpora+with+Web+Data%2C+and+Web+Data+Only&amp;rft.date=2023-06-01&amp;rft_id=info%3Aarxiv%2F2306.01116&amp;rft.aulast=Penedo&amp;rft.aufirst=Guilherme&amp;rft.au=Malartic%2C+Quentin&amp;rft.au=Hesslow%2C+Daniel&amp;rft.au=Cojocaru%2C+Ruxandra&amp;rft.au=Cappelli%2C+Alessandro&amp;rft.au=Alobeidli%2C+Hamza&amp;rft.au=Pannier%2C+Baptiste&amp;rft.au=Almazrouei%2C+Ebtesam&amp;rft.au=Launay%2C+Julien&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-gzTNw-185"><span class="mw-cite-backlink"><b><a href="#cite_ref-gzTNw_185-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://huggingface.co/tiiuae/falcon-40b">"tiiuae/falcon-40b · Hugging Face"</a>. <i>huggingface.co</i>. 2023-06-09<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-06-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=huggingface.co&amp;rft.atitle=tiiuae%2Ffalcon-40b+%C2%B7+Hugging+Face&amp;rft.date=2023-06-09&amp;rft_id=https%3A%2F%2Fhuggingface.co%2Ftiiuae%2Ffalcon-40b&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-Wmlcs-186"><span class="mw-cite-backlink"><b><a href="#cite_ref-Wmlcs_186-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.businesswire.com/news/home/20230531005608/en/UAE's-Falcon-40B-World's-Top-Ranked-AI-Model-from-Technology-Innovation-Institute-is-Now-Royalty-Free">UAE's Falcon 40B, World's Top-Ranked AI Model from Technology Innovation Institute, is Now Royalty-Free</a>, 31 May 2023</span>
</li>
<li id="cite_note-nGOSu-187"><span class="mw-cite-backlink"><b><a href="#cite_ref-nGOSu_187-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWuIrsoyLuDabravolski2023" class="citation arxiv cs1">Wu,
 Shijie; Irsoy, Ozan; Lu, Steven; Dabravolski, Vadim; Dredze, Mark; 
Gehrmann, Sebastian; Kambadur, Prabhanjan; Rosenberg, David; Mann, 
Gideon (March 30, 2023). "BloombergGPT: A Large Language Model for 
Finance". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.17564">2303.17564</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=BloombergGPT%3A+A+Large+Language+Model+for+Finance&amp;rft.date=2023-03-30&amp;rft_id=info%3Aarxiv%2F2303.17564&amp;rft.aulast=Wu&amp;rft.aufirst=Shijie&amp;rft.au=Irsoy%2C+Ozan&amp;rft.au=Lu%2C+Steven&amp;rft.au=Dabravolski%2C+Vadim&amp;rft.au=Dredze%2C+Mark&amp;rft.au=Gehrmann%2C+Sebastian&amp;rft.au=Kambadur%2C+Prabhanjan&amp;rft.au=Rosenberg%2C+David&amp;rft.au=Mann%2C+Gideon&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-9WSFw-188"><span class="mw-cite-backlink"><b><a href="#cite_ref-9WSFw_188-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFRenZhouMengHuang2023" class="citation arxiv cs1">Ren,
 Xiaozhe; Zhou, Pingyi; Meng, Xinfan; Huang, Xinjing; Wang, Yadao; Wang,
 Weichao; Li, Pengfei; Zhang, Xiaoda; Podolskiy, Alexander; Arshinov, 
Grigory; Bout, Andrey; Piontkovskaya, Irina; Wei, Jiansheng; Jiang, Xin;
 Su, Teng; Liu, Qun; Yao, Jun (March 19, 2023). "PanGu-Σ: Towards 
Trillion Parameter Language Model with Sparse Heterogeneous Computing". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.10845">2303.10845</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=PanGu-%CE%A3%3A+Towards+Trillion+Parameter+Language+Model+with+Sparse+Heterogeneous+Computing&amp;rft.date=2023-03-19&amp;rft_id=info%3Aarxiv%2F2303.10845&amp;rft.aulast=Ren&amp;rft.aufirst=Xiaozhe&amp;rft.au=Zhou%2C+Pingyi&amp;rft.au=Meng%2C+Xinfan&amp;rft.au=Huang%2C+Xinjing&amp;rft.au=Wang%2C+Yadao&amp;rft.au=Wang%2C+Weichao&amp;rft.au=Li%2C+Pengfei&amp;rft.au=Zhang%2C+Xiaoda&amp;rft.au=Podolskiy%2C+Alexander&amp;rft.au=Arshinov%2C+Grigory&amp;rft.au=Bout%2C+Andrey&amp;rft.au=Piontkovskaya%2C+Irina&amp;rft.au=Wei%2C+Jiansheng&amp;rft.au=Jiang%2C+Xin&amp;rft.au=Su%2C+Teng&amp;rft.au=Liu%2C+Qun&amp;rft.au=Yao%2C+Jun&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-JiOl8-189"><span class="mw-cite-backlink"><b><a href="#cite_ref-JiOl8_189-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKöpfKilchervon_RütteAnagnostidis2023" class="citation arxiv cs1">Köpf,
 Andreas; Kilcher, Yannic; von Rütte, Dimitri; Anagnostidis, Sotiris; 
Tam, Zhi-Rui; Stevens, Keith; Barhoum, Abdullah; Duc, Nguyen Minh; 
Stanley, Oliver; Nagyfi, Richárd; ES, Shahul; Suri, Sameer; Glushkov, 
David; Dantuluri, Arnav; Maguire, Andrew (2023-04-14). "OpenAssistant 
Conversations – Democratizing Large Language Model Alignment". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2304.07327">2304.07327</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=OpenAssistant+Conversations+%E2%80%93+Democratizing+Large+Language+Model+Alignment&amp;rft.date=2023-04-14&amp;rft_id=info%3Aarxiv%2F2304.07327&amp;rft.aulast=K%C3%B6pf&amp;rft.aufirst=Andreas&amp;rft.au=Kilcher%2C+Yannic&amp;rft.au=von+R%C3%BCtte%2C+Dimitri&amp;rft.au=Anagnostidis%2C+Sotiris&amp;rft.au=Tam%2C+Zhi-Rui&amp;rft.au=Stevens%2C+Keith&amp;rft.au=Barhoum%2C+Abdullah&amp;rft.au=Duc%2C+Nguyen+Minh&amp;rft.au=Stanley%2C+Oliver&amp;rft.au=Nagyfi%2C+Rich%C3%A1rd&amp;rft.au=ES%2C+Shahul&amp;rft.au=Suri%2C+Sameer&amp;rft.au=Glushkov%2C+David&amp;rft.au=Dantuluri%2C+Arnav&amp;rft.au=Maguire%2C+Andrew&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-190"><span class="mw-cite-backlink"><b><a href="#cite_ref-190" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWrobel" class="citation web cs1">Wrobel, Sharon. <a rel="nofollow" class="external text" href="https://www.timesofisrael.com/ai21-labs-rolls-out-new-advanced-ai-language-model-to-rival-openai/">"Tel Aviv startup rolls out new advanced AI language model to rival OpenAI"</a>. <i>www.timesofisrael.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-07-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.timesofisrael.com&amp;rft.atitle=Tel+Aviv+startup+rolls+out+new+advanced+AI+language+model+to+rival+OpenAI&amp;rft.aulast=Wrobel&amp;rft.aufirst=Sharon&amp;rft_id=https%3A%2F%2Fwww.timesofisrael.com%2Fai21-labs-rolls-out-new-advanced-ai-language-model-to-rival-openai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-191"><span class="mw-cite-backlink"><b><a href="#cite_ref-191" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWiggers2023" class="citation web cs1">Wiggers, Kyle (2023-04-13). <a rel="nofollow" class="external text" href="https://techcrunch.com/2023/04/13/with-bedrock-amazon-enters-the-generative-ai-race/">"With Bedrock, Amazon enters the generative AI race"</a>. <i>TechCrunch</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2023-07-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=TechCrunch&amp;rft.atitle=With+Bedrock%2C+Amazon+enters+the+generative+AI+race&amp;rft.date=2023-04-13&amp;rft.aulast=Wiggers&amp;rft.aufirst=Kyle&amp;rft_id=https%3A%2F%2Ftechcrunch.com%2F2023%2F04%2F13%2Fwith-bedrock-amazon-enters-the-generative-ai-race%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-cnbc-20230516-192"><span class="mw-cite-backlink">^ <a href="#cite_ref-cnbc-20230516_192-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-cnbc-20230516_192-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFElias2023" class="citation web cs1">Elias, Jennifer (16 May 2023). <a rel="nofollow" class="external text" href="https://www.cnbc.com/2023/05/16/googles-palm-2-uses-nearly-five-times-more-text-data-than-predecessor.html">"Google's newest A.I. model uses nearly five times more text data for training than its predecessor"</a>. <i><a href="https://en.wikipedia.org/wiki/CNBC" title="CNBC">CNBC</a></i><span class="reference-accessdate">. Retrieved <span class="nowrap">18 May</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=CNBC&amp;rft.atitle=Google%27s+newest+A.I.+model+uses+nearly+five+times+more+text+data+for+training+than+its+predecessor&amp;rft.date=2023-05-16&amp;rft.aulast=Elias&amp;rft.aufirst=Jennifer&amp;rft_id=https%3A%2F%2Fwww.cnbc.com%2F2023%2F05%2F16%2Fgoogles-palm-2-uses-nearly-five-times-more-text-data-than-predecessor.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-pWyLA-193"><span class="mw-cite-backlink"><b><a href="#cite_ref-pWyLA_193-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://blog.google/technology/ai/google-palm-2-ai-large-language-model/">"Introducing PaLM 2"</a>. <i>Google</i>. May 10, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google&amp;rft.atitle=Introducing+PaLM+2&amp;rft.date=2023-05-10&amp;rft_id=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-palm-2-ai-large-language-model%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-meta-20230719-194"><span class="mw-cite-backlink">^ <a href="#cite_ref-meta-20230719_194-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-meta-20230719_194-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://ai.meta.com/llama/">"Introducing Llama 2: The Next Generation of Our Open Source Large Language Model"</a>. <i>Meta AI</i>. 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-07-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Meta+AI&amp;rft.atitle=Introducing+Llama+2%3A+The+Next+Generation+of+Our+Open+Source+Large+Language+Model&amp;rft.date=2023&amp;rft_id=https%3A%2F%2Fai.meta.com%2Fllama%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-195"><span class="mw-cite-backlink"><b><a href="#cite_ref-195" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.anthropic.com/index/claude-2">"Claude 2"</a>. <i>anthropic.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">12 December</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=anthropic.com&amp;rft.atitle=Claude+2&amp;rft_id=https%3A%2F%2Fwww.anthropic.com%2Findex%2Fclaude-2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-tii-20230921-196"><span class="mw-cite-backlink">^ <a href="#cite_ref-tii-20230921_196-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-tii-20230921_196-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://falconllm.tii.ae/falcon-180b.html">"Falcon 180B"</a>. <i>Technology Innovation Institute</i>. 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-09-21</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Technology+Innovation+Institute&amp;rft.atitle=Falcon+180B&amp;rft.date=2023&amp;rft_id=https%3A%2F%2Ffalconllm.tii.ae%2Ffalcon-180b.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-mistral-20230927-197"><span class="mw-cite-backlink"><b><a href="#cite_ref-mistral-20230927_197-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://mistral.ai/news/announcing-mistral-7b/">"Announcing Mistral 7B"</a>. <i>Mistral</i>. 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-10-06</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Mistral&amp;rft.atitle=Announcing+Mistral+7B&amp;rft.date=2023&amp;rft_id=https%3A%2F%2Fmistral.ai%2Fnews%2Fannouncing-mistral-7b%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-198"><span class="mw-cite-backlink"><b><a href="#cite_ref-198" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.anthropic.com/index/claude-2-1">"Introducing Claude 2.1"</a>. <i>anthropic.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">12 December</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=anthropic.com&amp;rft.atitle=Introducing+Claude+2.1&amp;rft_id=https%3A%2F%2Fwww.anthropic.com%2Findex%2Fclaude-2-1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-199"><span class="mw-cite-backlink"><b><a href="#cite_ref-199" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation cs2"><a rel="nofollow" class="external text" href="https://github.com/xai-org/grok-1"><i>xai-org/grok-1</i></a>, xai-org, 2024-03-19<span class="reference-accessdate">, retrieved <span class="nowrap">2024-03-19</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=xai-org%2Fgrok-1&amp;rft.pub=xai-org&amp;rft.date=2024-03-19&amp;rft_id=https%3A%2F%2Fgithub.com%2Fxai-org%2Fgrok-1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-200"><span class="mw-cite-backlink"><b><a href="#cite_ref-200" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://x.ai/model-card/">"Grok-1 model card"</a>. <i>x.ai</i><span class="reference-accessdate">. Retrieved <span class="nowrap">12 December</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=x.ai&amp;rft.atitle=Grok-1+model+card&amp;rft_id=https%3A%2F%2Fx.ai%2Fmodel-card%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-201"><span class="mw-cite-backlink"><b><a href="#cite_ref-201" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://deepmind.google/technologies/gemini/#capabilities">"Gemini – Google DeepMind"</a>. <i>deepmind.google</i><span class="reference-accessdate">. Retrieved <span class="nowrap">12 December</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=deepmind.google&amp;rft.atitle=Gemini+%E2%80%93+Google+DeepMind&amp;rft_id=https%3A%2F%2Fdeepmind.google%2Ftechnologies%2Fgemini%2F%23capabilities&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-202"><span class="mw-cite-backlink"><b><a href="#cite_ref-202" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFFranzen2023" class="citation web cs1">Franzen, Carl (11 December 2023). <a rel="nofollow" class="external text" href="https://venturebeat.com/ai/mistral-shocks-ai-community-as-latest-open-source-model-eclipses-gpt-3-5-performance/">"Mistral shocks AI community as latest open source model eclipses GPT-3.5 performance"</a>. <i>VentureBeat</i><span class="reference-accessdate">. Retrieved <span class="nowrap">12 December</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=VentureBeat&amp;rft.atitle=Mistral+shocks+AI+community+as+latest+open+source+model+eclipses+GPT-3.5+performance&amp;rft.date=2023-12-11&amp;rft.aulast=Franzen&amp;rft.aufirst=Carl&amp;rft_id=https%3A%2F%2Fventurebeat.com%2Fai%2Fmistral-shocks-ai-community-as-latest-open-source-model-eclipses-gpt-3-5-performance%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-203"><span class="mw-cite-backlink"><b><a href="#cite_ref-203" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://mistral.ai/news/mixtral-of-experts/">"Mixtral of experts"</a>. <i>mistral.ai</i>. 11 December 2023<span class="reference-accessdate">. Retrieved <span class="nowrap">12 December</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=mistral.ai&amp;rft.atitle=Mixtral+of+experts&amp;rft.date=2023-12-11&amp;rft_id=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-of-experts%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-204"><span class="mw-cite-backlink"><b><a href="#cite_ref-204" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFAI2024" class="citation web cs1">AI, Mistral (2024-04-17). <a rel="nofollow" class="external text" href="https://mistral.ai/news/mixtral-8x22b/">"Cheaper, Better, Faster, Stronger"</a>. <i>mistral.ai</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2024-05-05</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=mistral.ai&amp;rft.atitle=Cheaper%2C+Better%2C+Faster%2C+Stronger&amp;rft.date=2024-04-17&amp;rft.aulast=AI&amp;rft.aufirst=Mistral&amp;rft_id=https%3A%2F%2Fmistral.ai%2Fnews%2Fmixtral-8x22b%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-205"><span class="mw-cite-backlink"><b><a href="#cite_ref-205" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHughes2023" class="citation web cs1">Hughes, Alyssa (12 December 2023). <a rel="nofollow" class="external text" href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">"Phi-2: The surprising power of small language models"</a>. <i>Microsoft Research</i><span class="reference-accessdate">. Retrieved <span class="nowrap">13 December</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Microsoft+Research&amp;rft.atitle=Phi-2%3A+The+surprising+power+of+small+language+models&amp;rft.date=2023-12-12&amp;rft.aulast=Hughes&amp;rft.aufirst=Alyssa&amp;rft_id=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fblog%2Fphi-2-the-surprising-power-of-small-language-models%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-206"><span class="mw-cite-backlink"><b><a href="#cite_ref-206" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFCheah" class="citation web cs1">Cheah, Eugene. <a rel="nofollow" class="external text" href="https://blog.rwkv.com/p/eagle-7b-soaring-past-transformers">"🦅 Eagle 7B&nbsp;: Soaring past Transformers with 1 Trillion Tokens Across 100+ Languages (RWKV-v5)"</a>. <i>blog.rwkv.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">31 January</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=blog.rwkv.com&amp;rft.atitle=%F0%9F%A6%85+Eagle+7B+%3A+Soaring+past+Transformers+with+1+Trillion+Tokens+Across+100%2B+Languages+%28RWKV-v5%29&amp;rft.aulast=Cheah&amp;rft.aufirst=Eugene&amp;rft_id=https%3A%2F%2Fblog.rwkv.com%2Fp%2Feagle-7b-soaring-past-transformers&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-207"><span class="mw-cite-backlink"><b><a href="#cite_ref-207" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#context-window">"Our next-generation model: Gemini 1.5"</a>. <i>Google</i>. 15 February 2024<span class="reference-accessdate">. Retrieved <span class="nowrap">16 February</span> 2024</span>. <q>This
 means 1.5 Pro can process vast amounts of information in one go — 
including 1 hour of video, 11 hours of audio, codebases with over 30,000
 lines of code or over 700,000 words. In our research, we've also 
successfully tested up to 10 million tokens.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google&amp;rft.atitle=Our+next-generation+model%3A+Gemini+1.5&amp;rft.date=2024-02-15&amp;rft_id=https%3A%2F%2Fblog.google%2Ftechnology%2Fai%2Fgoogle-gemini-next-generation-model-february-2024%2F%23context-window&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-gemma-208"><span class="mw-cite-backlink"><b><a href="#cite_ref-gemma_208-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/google-deepmind/gemma/blob/main/README.md">"Gemma"</a> – via GitHub.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Gemma&amp;rft_id=https%3A%2F%2Fgithub.com%2Fgoogle-deepmind%2Fgemma%2Fblob%2Fmain%2FREADME.md&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
<li id="cite_note-209"><span class="mw-cite-backlink"><b><a href="#cite_ref-209" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.anthropic.com/news/claude-3-family">"Introducing the next generation of Claude"</a>. <i>www.anthropic.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2024-03-04</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.anthropic.com&amp;rft.atitle=Introducing+the+next+generation+of+Claude&amp;rft_id=https%3A%2F%2Fwww.anthropic.com%2Fnews%2Fclaude-3-family&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;action=edit&amp;section=37" title="Edit section: Further reading"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Dan_Jurafsky" title="Dan Jurafsky">Jurafsky, Dan</a>, Martin, James. H. <a rel="nofollow" class="external text" href="https://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf"><i>Speech
 and Language Processing: An Introduction to Natural Language 
Processing, Computational Linguistics, and Speech Recognition</i></a>, 3rd Edition draft, 2023.</li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZhaoZhouLi2023" class="citation arxiv cs1">Zhao, Wayne Xin; et&nbsp;al. (2023). "A Survey of Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2303.18223">2303.18223</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Survey+of+Large+Language+Models&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2303.18223&amp;rft.aulast=Zhao&amp;rft.aufirst=Wayne+Xin&amp;rft.au=Zhou%2C+Kun&amp;rft.au=Li%2C+Junyi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKaddour2023" class="citation arxiv cs1">Kaddour, Jean; et&nbsp;al. (2023). "Challenges and Applications of Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2307.10169">2307.10169</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Challenges+and+Applications+of+Large+Language+Models&amp;rft.date=2023&amp;rft_id=info%3Aarxiv%2F2307.10169&amp;rft.aulast=Kaddour&amp;rft.aufirst=Jean&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFYinFuZhaoLi2023" class="citation arxiv cs1">Yin,
 Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, 
Enhong (2023-06-01). "A Survey on Multimodal Large Language Models". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2306.13549">2306.13549</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CV">cs.CV</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Survey+on+Multimodal+Large+Language+Models&amp;rft.date=2023-06-01&amp;rft_id=info%3Aarxiv%2F2306.13549&amp;rft.aulast=Yin&amp;rft.aufirst=Shukang&amp;rft.au=Fu%2C+Chaoyou&amp;rft.au=Zhao%2C+Sirui&amp;rft.au=Li%2C+Ke&amp;rft.au=Sun%2C+Xing&amp;rft.au=Xu%2C+Tong&amp;rft.au=Chen%2C+Enhong&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></li>
<li><a rel="nofollow" class="external text" href="https://github.com/eugeneyan/open-llms">Open LLMs repository</a> on <a href="https://en.wikipedia.org/wiki/GitHub" title="GitHub">GitHub</a>.</li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://aiindex.stanford.edu/report/">"AI Index Report 2024 – Artificial Intelligence Index"</a>. <i>aiindex.stanford.edu</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2024-05-05</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=aiindex.stanford.edu&amp;rft.atitle=AI+Index+Report+2024+%E2%80%93+Artificial+Intelligence+Index&amp;rft_id=https%3A%2F%2Faiindex.stanford.edu%2Freport%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFFrank2023" class="citation journal cs1">Frank, Michael C. (27 June 2023). <a rel="nofollow" class="external text" href="https://www.nature.com/articles/s44159-023-00211-x">"Baby steps in evaluating the capacities of large language models"</a>. <i>Nature Reviews Psychology</i>. <b>2</b> (8): 451–452. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fs44159-023-00211-x">10.1038/s44159-023-00211-x</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/2731-0574">2731-0574</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:259713140">259713140</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2 July</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature+Reviews+Psychology&amp;rft.atitle=Baby+steps+in+evaluating+the+capacities+of+large+language+models&amp;rft.volume=2&amp;rft.issue=8&amp;rft.pages=451-452&amp;rft.date=2023-06-27&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A259713140%23id-name%3DS2CID&amp;rft.issn=2731-0574&amp;rft_id=info%3Adoi%2F10.1038%2Fs44159-023-00211-x&amp;rft.aulast=Frank&amp;rft.aufirst=Michael+C.&amp;rft_id=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs44159-023-00211-x&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALarge+language+model" class="Z3988"></span></li></ul>
<div class="navbox-styles"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><style data-mw-deduplicate="TemplateStyles:r1061467846">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}</style><style class="darkreader darkreader--sync" media="screen"></style></div><div role="navigation" class="navbox" aria-labelledby="Natural_language_processing" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner mw-made-collapsible mw-collapsed" style="border-spacing: 0px; background: transparent; color: inherit; --darkreader-inline-bgcolor: transparent; --darkreader-inline-bgimage: none; --darkreader-inline-color: inherit;" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="" data-darkreader-inline-color=""><tbody><tr><th scope="col" class="navbox-title" colspan="2"><button type="button" class="mw-collapsible-toggle mw-collapsible-toggle-default mw-collapsible-toggle-collapsed" aria-expanded="false" tabindex="0"><span class="mw-collapsible-text">show</span></button><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1063604349"><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="https://en.wikipedia.org/wiki/Template:Natural_language_processing" title="Template:Natural language processing"><abbr title="View this template" style="background: transparent; border: medium; box-shadow: none; padding: 0px; --darkreader-inline-bgcolor: transparent; --darkreader-inline-bgimage: none; --darkreader-inline-border-top: currentcolor; --darkreader-inline-border-right: currentcolor; --darkreader-inline-border-bottom: currentcolor; --darkreader-inline-border-left: currentcolor; --darkreader-inline-boxshadow: none;" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left="" data-darkreader-inline-boxshadow="">v</abbr></a></li><li class="nv-talk"><a href="https://en.wikipedia.org/wiki/Template_talk:Natural_language_processing" title="Template talk:Natural language processing"><abbr title="Discuss this template" style="background: transparent; border: medium; box-shadow: none; padding: 0px; --darkreader-inline-bgcolor: transparent; --darkreader-inline-bgimage: none; --darkreader-inline-border-top: currentcolor; --darkreader-inline-border-right: currentcolor; --darkreader-inline-border-bottom: currentcolor; --darkreader-inline-border-left: currentcolor; --darkreader-inline-boxshadow: none;" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left="" data-darkreader-inline-boxshadow="">t</abbr></a></li><li class="nv-edit"><a href="https://en.wikipedia.org/wiki/Special:EditPage/Template:Natural_language_processing" title="Special:EditPage/Template:Natural language processing"><abbr title="Edit this template" style="background: transparent; border: medium; box-shadow: none; padding: 0px; --darkreader-inline-bgcolor: transparent; --darkreader-inline-bgimage: none; --darkreader-inline-border-top: currentcolor; --darkreader-inline-border-right: currentcolor; --darkreader-inline-border-bottom: currentcolor; --darkreader-inline-border-left: currentcolor; --darkreader-inline-boxshadow: none;" data-darkreader-inline-bgcolor="" data-darkreader-inline-bgimage="" data-darkreader-inline-border-top="" data-darkreader-inline-border-right="" data-darkreader-inline-border-bottom="" data-darkreader-inline-border-left="" data-darkreader-inline-boxshadow="">e</abbr></a></li></ul></div><div id="Natural_language_processing" style="font-size:114%;margin:0 4em"><a href="https://en.wikipedia.org/wiki/Natural_language_processing" title="Natural language processing">Natural language processing</a></div></th></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%">General terms</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/AI-complete" title="AI-complete">AI-complete</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bag-of-words_model" title="Bag-of-words model">Bag-of-words</a></li>
<li><a href="https://en.wikipedia.org/wiki/N-gram" title="N-gram">n-gram</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Bigram" title="Bigram">Bigram</a></li>
<li><a href="https://en.wikipedia.org/wiki/Trigram" title="Trigram">Trigram</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Computational_linguistics" title="Computational linguistics">Computational linguistics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Natural-language_understanding" title="Natural-language understanding">Natural-language understanding</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stop_word" title="Stop word">Stop words</a></li>
<li><a href="https://en.wikipedia.org/wiki/Text_processing" title="Text processing">Text processing</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Text_mining" title="Text mining">Text analysis</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Argument_mining" title="Argument mining">Argument mining</a></li>
<li><a href="https://en.wikipedia.org/wiki/Collocation_extraction" title="Collocation extraction">Collocation extraction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Concept_mining" title="Concept mining">Concept mining</a></li>
<li><a href="https://en.wikipedia.org/wiki/Coreference#Coreference_resolution" title="Coreference">Coreference resolution</a></li>
<li><a href="https://en.wikipedia.org/wiki/Deep_linguistic_processing" title="Deep linguistic processing">Deep linguistic processing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Distant_reading" title="Distant reading">Distant reading</a></li>
<li><a href="https://en.wikipedia.org/wiki/Information_extraction" title="Information extraction">Information extraction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Named-entity_recognition" title="Named-entity recognition">Named-entity recognition</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ontology_learning" title="Ontology learning">Ontology learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Parsing" title="Parsing">Parsing</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Semantic_parsing" title="Semantic parsing">Semantic parsing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Syntactic_parsing_(computational_linguistics)" title="Syntactic parsing (computational linguistics)">Syntactic parsing</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging" title="Part-of-speech tagging">Part-of-speech tagging</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semantic_analysis_(machine_learning)" title="Semantic analysis (machine learning)">Semantic analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semantic_role_labeling" title="Semantic role labeling">Semantic role labeling</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semantic_decomposition_(natural_language_processing)" title="Semantic decomposition (natural language processing)">Semantic decomposition</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semantic_similarity" title="Semantic similarity">Semantic similarity</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sentiment_analysis" title="Sentiment analysis">Sentiment analysis</a></li></ul>
<ul><li><a href="https://en.wikipedia.org/wiki/Terminology_extraction" title="Terminology extraction">Terminology extraction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Text_mining" title="Text mining">Text mining</a></li>
<li><a href="https://en.wikipedia.org/wiki/Textual_entailment" title="Textual entailment">Textual entailment</a></li>
<li><a href="https://en.wikipedia.org/wiki/Truecasing" title="Truecasing">Truecasing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation" title="Word-sense disambiguation">Word-sense disambiguation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Word-sense_induction" title="Word-sense induction">Word-sense induction</a></li></ul>
</div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th id="Text_segmentation" scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Text_segmentation" title="Text segmentation">Text segmentation</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Compound-term_processing" title="Compound-term processing">Compound-term processing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Lemmatisation" class="mw-redirect" title="Lemmatisation">Lemmatisation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Lexical_analysis" title="Lexical analysis">Lexical analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Shallow_parsing" title="Shallow parsing">Text chunking</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stemming" title="Stemming">Stemming</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation" title="Sentence boundary disambiguation">Sentence segmentation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Word#Word_boundaries" title="Word">Word segmentation</a></li></ul>
</div></td></tr></tbody></table><div>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Automatic_summarization" title="Automatic summarization">Automatic summarization</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Multi-document_summarization" title="Multi-document summarization">Multi-document summarization</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sentence_extraction" title="Sentence extraction">Sentence extraction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Text_simplification" title="Text simplification">Text simplification</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Machine_translation" title="Machine translation">Machine translation</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Computer-assisted_translation" title="Computer-assisted translation">Computer-assisted</a></li>
<li><a href="https://en.wikipedia.org/wiki/Example-based_machine_translation" title="Example-based machine translation">Example-based</a></li>
<li><a href="https://en.wikipedia.org/wiki/Rule-based_machine_translation" title="Rule-based machine translation">Rule-based</a></li>
<li><a href="https://en.wikipedia.org/wiki/Statistical_machine_translation" title="Statistical machine translation">Statistical</a></li>
<li><a href="https://en.wikipedia.org/wiki/Transfer-based_machine_translation" title="Transfer-based machine translation">Transfer-based</a></li>
<li><a href="https://en.wikipedia.org/wiki/Neural_machine_translation" title="Neural machine translation">Neural</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Distributional_semantics" title="Distributional semantics">Distributional semantics</a> models</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/BERT_(language_model)" title="BERT (language model)">BERT</a></li>
<li><a href="https://en.wikipedia.org/wiki/Document-term_matrix" title="Document-term matrix">Document-term matrix</a></li>
<li><a href="https://en.wikipedia.org/wiki/Explicit_semantic_analysis" title="Explicit semantic analysis">Explicit semantic analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/FastText" title="FastText">fastText</a></li>
<li><a href="https://en.wikipedia.org/wiki/GloVe" title="GloVe">GloVe</a></li>
<li><a href="https://en.wikipedia.org/wiki/Language_model" title="Language model">Language model</a> (<a class="mw-selflink selflink">large</a>)</li>
<li><a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" title="Latent semantic analysis">Latent semantic analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Seq2seq" title="Seq2seq">Seq2seq</a></li>
<li><a href="https://en.wikipedia.org/wiki/Word_embedding" title="Word embedding">Word embedding</a></li>
<li><a href="https://en.wikipedia.org/wiki/Word2vec" title="Word2vec">Word2vec</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Language_resource" title="Language resource">Language resources</a>,<br>datasets and corpora</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%">Types and<br>standards</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Corpus_linguistics" title="Corpus linguistics">Corpus linguistics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Lexical_resource" title="Lexical resource">Lexical resource</a></li>
<li><a href="https://en.wikipedia.org/wiki/Linguistic_Linked_Open_Data" title="Linguistic Linked Open Data">Linguistic Linked Open Data</a></li>
<li><a href="https://en.wikipedia.org/wiki/Machine-readable_dictionary" title="Machine-readable dictionary">Machine-readable dictionary</a></li>
<li><a href="https://en.wikipedia.org/wiki/Parallel_text" title="Parallel text">Parallel text</a></li>
<li><a href="https://en.wikipedia.org/wiki/PropBank" title="PropBank">PropBank</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semantic_network" title="Semantic network">Semantic network</a></li>
<li><a href="https://en.wikipedia.org/wiki/Simple_Knowledge_Organization_System" title="Simple Knowledge Organization System">Simple Knowledge Organization System</a></li>
<li><a href="https://en.wikipedia.org/wiki/Speech_corpus" title="Speech corpus">Speech corpus</a></li>
<li><a href="https://en.wikipedia.org/wiki/Text_corpus" title="Text corpus">Text corpus</a></li>
<li><a href="https://en.wikipedia.org/wiki/Thesaurus_(information_retrieval)" title="Thesaurus (information retrieval)">Thesaurus (information retrieval)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Treebank" title="Treebank">Treebank</a></li>
<li><a href="https://en.wikipedia.org/wiki/Universal_Dependencies" title="Universal Dependencies">Universal Dependencies</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Data</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/BabelNet" title="BabelNet">BabelNet</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bank_of_English" title="Bank of English">Bank of English</a></li>
<li><a href="https://en.wikipedia.org/wiki/DBpedia" title="DBpedia">DBpedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/FrameNet" title="FrameNet">FrameNet</a></li>
<li><a href="https://en.wikipedia.org/wiki/Google_Ngram_Viewer" title="Google Ngram Viewer">Google Ngram Viewer</a></li>
<li><a href="https://en.wikipedia.org/wiki/UBY" title="UBY">UBY</a></li>
<li><a href="https://en.wikipedia.org/wiki/WordNet" title="WordNet">WordNet</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Automatic_identification_and_data_capture" title="Automatic identification and data capture">Automatic identification<br>and data capture</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Speech_recognition" title="Speech recognition">Speech recognition</a></li>
<li><a href="https://en.wikipedia.org/wiki/Speech_segmentation" title="Speech segmentation">Speech segmentation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Speech_synthesis" title="Speech synthesis">Speech synthesis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Natural_language_generation" title="Natural language generation">Natural language generation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Optical_character_recognition" title="Optical character recognition">Optical character recognition</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Topic_model" title="Topic model">Topic model</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Document_classification" title="Document classification">Document classification</a></li>
<li><a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" title="Latent Dirichlet allocation">Latent Dirichlet allocation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pachinko_allocation" title="Pachinko allocation">Pachinko allocation</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Computer-assisted_reviewing" title="Computer-assisted reviewing">Computer-assisted<br>reviewing</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Automated_essay_scoring" title="Automated essay scoring">Automated essay scoring</a></li>
<li><a href="https://en.wikipedia.org/wiki/Concordancer" title="Concordancer">Concordancer</a></li>
<li><a href="https://en.wikipedia.org/wiki/Grammar_checker" title="Grammar checker">Grammar checker</a></li>
<li><a href="https://en.wikipedia.org/wiki/Predictive_text" title="Predictive text">Predictive text</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pronunciation_assessment" title="Pronunciation assessment">Pronunciation assessment</a></li>
<li><a href="https://en.wikipedia.org/wiki/Spell_checker" title="Spell checker">Spell checker</a></li>
<li><a href="https://en.wikipedia.org/wiki/Syntax_guessing" class="mw-redirect" title="Syntax guessing">Syntax guessing</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Natural_language_user_interface" class="mw-redirect" title="Natural language user interface">Natural language<br>user interface</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Chatbot" title="Chatbot">Chatbot</a></li>
<li><a href="https://en.wikipedia.org/wiki/Interactive_fiction" title="Interactive fiction">Interactive fiction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Question_answering" title="Question answering">Question answering</a></li>
<li><a href="https://en.wikipedia.org/wiki/Virtual_assistant" title="Virtual assistant">Virtual assistant</a></li>
<li><a href="https://en.wikipedia.org/wiki/Voice_user_interface" title="Voice user interface">Voice user interface</a></li></ul>
</div></td></tr><tr style="display: none;"><th scope="row" class="navbox-group" style="width:1%">Related</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Formal_semantics_(natural_language)" title="Formal semantics (natural language)">Formal semantics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)" title="Hallucination (artificial intelligence)">Hallucination</a></li>
<li><a href="https://en.wikipedia.org/wiki/Natural_Language_Toolkit" title="Natural Language Toolkit">Natural Language Toolkit</a></li>
<li><a href="https://en.wikipedia.org/wiki/SpaCy" title="SpaCy">spaCy</a></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐55b8c76fd7‐4tx5t
Cached time: 20240506090251
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 2.452 seconds
Real time usage: 2.705 seconds
Preprocessor visited node count: 16562/1000000
Post‐expand include size: 549649/2097152 bytes
Template argument size: 14311/2097152 bytes
Highest expansion depth: 23/100
Expensive parser function count: 16/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 805863/5000000 bytes
Lua time usage: 1.684/10.000 seconds
Lua memory usage: 8173022/52428800 bytes
Lua Profile:
    ?                                                                240 ms       14.1%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::gsub      160 ms        9.4%
    recursiveClone <mwInit.lua:41>                                   120 ms        7.1%
    type                                                             120 ms        7.1%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::find      120 ms        7.1%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::callParserFunction      120 ms        7.1%
    dataWrapper <mw.lua:672>                                         100 ms        5.9%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::plain       80 ms        4.7%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::preprocess       60 ms        3.5%
    <mw.lua:694>                                                      60 ms        3.5%
    [others]                                                         520 ms       30.6%
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 2337.100      1 -total
 71.53% 1671.614      2 Template:Reflist
 25.36%  592.644     72 Template:Cite_arXiv
 18.91%  441.847     83 Template:Cite_web
  7.93%  185.336     24 Template:Cite_journal
  6.95%  162.433      1 Template:Harvnb
  4.25%   99.239      1 Template:Short_description
  4.04%   94.393      1 Template:Machine_learning
  3.93%   91.846      1 Template:Sidebar_with_collapsible_lists
  2.93%   68.526     10 Template:Citation
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:73248112-0!canonical and timestamp 20240506090251 and revision id 1222500509. Rendering was triggered because: page-view
 -->
</div><!--esi <esi:include src="/esitest-fa8a495983347898/content" /> --><noscript><img src="https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" width="1" height="1" style="border: none; position: absolute;"></noscript>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;oldid=1222500509">https://en.wikipedia.org/w/index.php?title=Large_language_model&amp;oldid=1222500509</a>"</div></div>
					<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="https://en.wikipedia.org/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="https://en.wikipedia.org/wiki/Category:Large_language_models" title="Category:Large language models">Large language models</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Deep_learning" title="Category:Deep learning">Deep learning</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Natural_language_processing" title="Category:Natural language processing">Natural language processing</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="https://en.wikipedia.org/wiki/Category:CS1:_long_volume_value" title="Category:CS1: long volume value">CS1: long volume value</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_containing_potentially_dated_statements_from_March_2024" title="Category:Articles containing potentially dated statements from March 2024">Articles containing potentially dated statements from March 2024</a></li><li><a href="https://en.wikipedia.org/wiki/Category:All_articles_containing_potentially_dated_statements" title="Category:All articles containing potentially dated statements">All articles containing potentially dated statements</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_containing_potentially_dated_statements_from_2024" title="Category:Articles containing potentially dated statements from 2024">Articles containing potentially dated statements from 2024</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_containing_potentially_dated_statements_from_January_2024" title="Category:Articles containing potentially dated statements from January 2024">Articles containing potentially dated statements from January 2024</a></li><li><a href="https://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_February_2024" title="Category:Articles with unsourced statements from February 2024">Articles with unsourced statements from February 2024</a></li></ul></div></div>
				</div>
			</main>
			
		</div>
		<div class="mw-footer-container">
			
<footer id="footer" class="mw-footer" role="contentinfo">
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 6 May 2024, at 09:02<span class="anonymous-show">&nbsp;(UTC)</span>.</li>
	<li id="footer-info-copyright">Text is available under the <a rel="license" href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License">Creative Commons Attribution-ShareAlike License 4.0</a><a rel="license" href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License" style="display:none;"></a>;
additional terms may apply. By using this site, you agree to the <a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use">Terms of Use</a> and <a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="https://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="https://en.wikipedia.org/wiki/Wikipedia:About">About Wikipedia</a></li>
	<li id="footer-places-disclaimers"><a href="https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-contact"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
	<li id="footer-places-wm-codeofconduct"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct">Code of Conduct</a></li>
	<li id="footer-places-developers"><a href="https://developer.wikimedia.org/">Developers</a></li>
	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement">Cookie statement</a></li>
	<li id="footer-places-mobileview"><a href="https://en.m.wikipedia.org/w/index.php?title=Large_language_model&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
<li style="display: none;"><a href="#">Edit preview settings</a></li></ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="Large%20language%20model%20-%20Wikipedia_files/wikimedia-button.png" srcset="Large%20language%20model%20-%20Wikipedia_files/wikimedia-button-1.5x.png 1.5x, Large%20language%20model%20-%20Wikipedia_files/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy"></a></li>
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="Large%20language%20model%20-%20Wikipedia_files/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="Large%20language%20model%20-%20Wikipedia_files/poweredby_mediawiki_132x47.png 1.5x, Large%20language%20model%20-%20Wikipedia_files/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"></a></li>
</ul>

</footer>

		</div>
	</div> 
</div> 
<div class="vector-settings" id="p-dock-bottom">
	<ul>
		<li>
		<button class="cdx-button cdx-button--icon-only vector-limited-width-toggle" id="" data-event-name="limited-width-toggle-off"><span class="vector-icon mw-ui-icon-fullScreen mw-ui-icon-wikimedia-fullScreen"></span>

<span>Toggle limited content width</span>
</button>
</li>
	</ul>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgHostname":"mw-web.eqiad.main-55b8c76fd7-jnmm7","wgBackendResponseTime":274,"wgPageParseReport":{"limitreport":{"cputime":"2.452","walltime":"2.705","ppvisitednodes":{"value":16562,"limit":1000000},"postexpandincludesize":{"value":549649,"limit":2097152},"templateargumentsize":{"value":14311,"limit":2097152},"expansiondepth":{"value":23,"limit":100},"expensivefunctioncount":{"value":16,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":805863,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00% 2337.100      1 -total"," 71.53% 1671.614      2 Template:Reflist"," 25.36%  592.644     72 Template:Cite_arXiv"," 18.91%  441.847     83 Template:Cite_web","  7.93%  185.336     24 Template:Cite_journal","  6.95%  162.433      1 Template:Harvnb","  4.25%   99.239      1 Template:Short_description","  4.04%   94.393      1 Template:Machine_learning","  3.93%   91.846      1 Template:Sidebar_with_collapsible_lists","  2.93%   68.526     10 Template:Citation"]},"scribunto":{"limitreport-timeusage":{"value":"1.684","limit":"10.000"},"limitreport-memusage":{"value":8173022,"limit":52428800},"limitreport-logs":"anchor_id_list = table#1 {\n    [\"CITEREFAI2024\"] = 1,\n    [\"CITEREFAbdinJacobsAwanAneja2024\"] = 1,\n    [\"CITEREFAlayracDonahueLucMiech2022\"] = 1,\n    [\"CITEREFAlba2023\"] = 1,\n    [\"CITEREFAllamar\"] = 2,\n    [\"CITEREFAlviKharya2021\"] = 1,\n    [\"CITEREFAnanthaswamy2023\"] = 1,\n    [\"CITEREFAntolAgrawalLuMitchell2015\"] = 1,\n    [\"CITEREFAskellBaiChenDrain2021\"] = 1,\n    [\"CITEREFBahdanauChoBengio2014\"] = 1,\n    [\"CITEREFBaiKadavathKunduAskell2022\"] = 1,\n    [\"CITEREFBidermanSchoelkopfAnthonyBradley2023\"] = 1,\n    [\"CITEREFBlackBidermanHallahan2022\"] = 1,\n    [\"CITEREFBowman2023\"] = 1,\n    [\"CITEREFBrownMannRyderSubbiah2020\"] = 3,\n    [\"CITEREFBubeckChandrasekaranEldanGehrke2023\"] = 1,\n    [\"CITEREFCaballeroGuptaRishKrueger2022\"] = 1,\n    [\"CITEREFCheah\"] = 1,\n    [\"CITEREFChengDurmusJurafsky2023\"] = 1,\n    [\"CITEREFChengThoppilan2022\"] = 1,\n    [\"CITEREFClarkLeeChangKwiatkowski2019\"] = 1,\n    [\"CITEREFDaiDu2021\"] = 1,\n    [\"CITEREFDettmersPagnoniHoltzmanZettlemoyer2023\"] = 1,\n    [\"CITEREFDettmersSvirschevskiEgiazarianKuznedelev2023\"] = 1,\n    [\"CITEREFDevlinChangLeeToutanova2018\"] = 1,\n    [\"CITEREFDey2023\"] = 1,\n    [\"CITEREFDeyGosalZhimingChen2023\"] = 1,\n    [\"CITEREFDodgeSapMarasovićAgnew2021\"] = 1,\n    [\"CITEREFDriessXiaSajjadiLynch2023\"] = 1,\n    [\"CITEREFElias2023\"] = 1,\n    [\"CITEREFEvans2014\"] = 1,\n    [\"CITEREFFrank2023\"] = 1,\n    [\"CITEREFFrantarAshkboosHoeflerAlistarh2022\"] = 1,\n    [\"CITEREFFranzen2023\"] = 1,\n    [\"CITEREFFriston2022\"] = 1,\n    [\"CITEREFGaoBidermanBlackGolding2020\"] = 1,\n    [\"CITEREFGaoMadaanZhouAlon2022\"] = 1,\n    [\"CITEREFGuDao2023\"] = 1,\n    [\"CITEREFHahnGoyal2023\"] = 1,\n    [\"CITEREFHaoGuMaJiahua_Hong2023\"] = 1,\n    [\"CITEREFHeaven2023\"] = 1,\n    [\"CITEREFHeikkilä2023\"] = 1,\n    [\"CITEREFHern2019\"] = 1,\n    [\"CITEREFHoffmannBorgeaudMenschBuchatskaya2022\"] = 2,\n    [\"CITEREFHoffmannBorgeaudMenschSifre2022\"] = 1,\n    [\"CITEREFHuangAbbeelPathakMordatch2022\"] = 1,\n    [\"CITEREFHubinger2024\"] = 1,\n    [\"CITEREFHughes2023\"] = 1,\n    [\"CITEREFHuyen2019\"] = 1,\n    [\"CITEREFIyer2021\"] = 1,\n    [\"CITEREFJiLeeFrieskeYu2022\"] = 1,\n    [\"CITEREFJinRinard2023\"] = 1,\n    [\"CITEREFJurafskyMartin2023\"] = 1,\n    [\"CITEREFKaddour2023\"] = 1,\n    [\"CITEREFKaplanMcCandlishHenighanBrown2020\"] = 1,\n    [\"CITEREFKhrushchevVasilevPetrovZinov2022\"] = 1,\n    [\"CITEREFKirosSalakhutdinovZemel2014\"] = 1,\n    [\"CITEREFKotekDockumSun2023\"] = 1,\n    [\"CITEREFKrizhevskySutskeverHinton2012\"] = 1,\n    [\"CITEREFKöpfKilchervon_RütteAnagnostidis2023\"] = 1,\n    [\"CITEREFLakoff1999\"] = 1,\n    [\"CITEREFLeeIppolitoNystromZhang2022\"] = 1,\n    [\"CITEREFLepikhinLeeXuChen2021\"] = 1,\n    [\"CITEREFLewisPerezPiktusPetroni2020\"] = 1,\n    [\"CITEREFLewkowyczAndreassenDohanDyer2022\"] = 1,\n    [\"CITEREFLiBubeckEldanDel_Giorno2023\"] = 1,\n    [\"CITEREFLiHopkinsBauViégas2022\"] = 1,\n    [\"CITEREFLiLiSavareseHoi2023\"] = 1,\n    [\"CITEREFLiangWuSongWu2023\"] = 1,\n    [\"CITEREFLinGouGongLiu2024\"] = 1,\n    [\"CITEREFLinHiltonEvans2021\"] = 1,\n    [\"CITEREFLiuLiWuLee2023\"] = 1,\n    [\"CITEREFLuoPuettSmith2023\"] = 1,\n    [\"CITEREFManning2022\"] = 1,\n    [\"CITEREFMaslejFattoriniBrynjolfssonEtchemendy2023\"] = 1,\n    [\"CITEREFMerritt2022\"] = 1,\n    [\"CITEREFMetz2023\"] = 1,\n    [\"CITEREFMitchellKrakauer2023\"] = 1,\n    [\"CITEREFNagelAmjadBaalenLouizos2020\"] = 1,\n    [\"CITEREFNaik2021\"] = 1,\n    [\"CITEREFNandaChanLieberumSmith2023\"] = 1,\n    [\"CITEREFNarangChowdhery2022\"] = 1,\n    [\"CITEREFNewport2023\"] = 1,\n    [\"CITEREFOpenAI2023\"] = 2,\n    [\"CITEREFOrnes2023\"] = 1,\n    [\"CITEREFOuyangWuJiangAlmeida2022\"] = 1,\n    [\"CITEREFPaaßGiesselbach2022\"] = 1,\n    [\"CITEREFParanjapeLundbergSinghHajishirzi2023\"] = 1,\n    [\"CITEREFParkO\u0026#039;BrienCaiRingel_Morris2023\"] = 1,\n    [\"CITEREFPatelLiRasooliConstant2022\"] = 1,\n    [\"CITEREFPatelPavlick2021\"] = 1,\n    [\"CITEREFPatilZhangWangGonzalez2023\"] = 1,\n    [\"CITEREFPenedoMalarticHesslowCojocaru2023\"] = 1,\n    [\"CITEREFPengAlcaideAnthonyAlbalak2023\"] = 1,\n    [\"CITEREFPengWangDeng2023\"] = 1,\n    [\"CITEREFPetrovEmanuele_La_MalfaTorrBibi2023\"] = 1,\n    [\"CITEREFPetrovMalfaTorrBibi2023\"] = 1,\n    [\"CITEREFPichai\"] = 1,\n    [\"CITEREFPilehvarCamacho-Collados2019\"] = 1,\n    [\"CITEREFPolinoPascanuAlistarh2018\"] = 1,\n    [\"CITEREFPrickett2021\"] = 1,\n    [\"CITEREFRaffelShazeerRobertsLee2020\"] = 1,\n    [\"CITEREFRenZhouMengHuang2023\"] = 1,\n    [\"CITEREFRogersKovalevaRumshisky2020\"] = 1,\n    [\"CITEREFRoose2023\"] = 1,\n    [\"CITEREFSchaefferMirandaKoyejo2023\"] = 1,\n    [\"CITEREFSharirPelegShoham2020\"] = 1,\n    [\"CITEREFShazeerMirhoseiniMaziarzDavis2017\"] = 1,\n    [\"CITEREFShinnCassanoLabashGopinath2023\"] = 1,\n    [\"CITEREFSmithPatwaryNorickLeGresley2022\"] = 1,\n    [\"CITEREFSoltanAnanthakrishnanFitzGeraldGupta2022\"] = 1,\n    [\"CITEREFSrivastavaRastogiRaoAbu_Awal_Md_Shoeb2022\"] = 1,\n    [\"CITEREFStephen_Council2023\"] = 1,\n    [\"CITEREFStokel-Walker2023\"] = 1,\n    [\"CITEREFTaylorKardasCucurullScialom2022\"] = 1,\n    [\"CITEREFThoppilanDe_FreitasHallShazeer2022\"] = 1,\n    [\"CITEREFVarshneyYaoZhangChen2023\"] = 1,\n    [\"CITEREFVaswaniShazeerParmarUszkoreit2017\"] = 1,\n    [\"CITEREFWangCaiLiuMa2023\"] = 1,\n    [\"CITEREFWangKordiMishraLiu2022\"] = 1,\n    [\"CITEREFWangSunXiangWu2021\"] = 1,\n    [\"CITEREFWayne_Xin_ZhaoZhouLiTang2023\"] = 1,\n    [\"CITEREFWeiTayBommasaniRaffel2022\"] = 1,\n    [\"CITEREFWiggers2022\"] = 1,\n    [\"CITEREFWiggers2023\"] = 1,\n    [\"CITEREFWrobel\"] = 1,\n    [\"CITEREFWuIrsoyLuDabravolski2023\"] = 1,\n    [\"CITEREFWuPrabhumoyeMin2023\"] = 1,\n    [\"CITEREFYangDaiYangCarbonell2020\"] = 1,\n    [\"CITEREFYaoZhaoYuDu2022\"] = 1,\n    [\"CITEREFYennie_Jun2023\"] = 1,\n    [\"CITEREFYinFuZhaoLi2023\"] = 1,\n    [\"CITEREFZaibShengEmma_Zhang2020\"] = 1,\n    [\"CITEREFZellersHoltzmanBiskFarhadi2019\"] = 1,\n    [\"CITEREFZhangLehmanStanleyClune2023\"] = 1,\n    [\"CITEREFZhangLiBing2023\"] = 1,\n    [\"CITEREFZhangRollerGoyalArtetxe2022\"] = 1,\n    [\"CITEREFZhaoZhouLi2023\"] = 1,\n    [\"Emergent_abilities\"] = 1,\n}\ntemplate_list = table#1 {\n    [\"!\"] = 3,\n    [\"Anchor\"] = 1,\n    [\"As of\"] = 2,\n    [\"Asof\"] = 1,\n    [\"Br\"] = 4,\n    [\"Citation\"] = 10,\n    [\"Cite arXiv\"] = 72,\n    [\"Cite book\"] = 7,\n    [\"Cite conference\"] = 1,\n    [\"Cite journal\"] = 24,\n    [\"Cite magazine\"] = 1,\n    [\"Cite news\"] = 6,\n    [\"Cite web\"] = 83,\n    [\"Cn\"] = 3,\n    [\"Dts\"] = 45,\n    [\"Efn\"] = 6,\n    [\"Harvnb\"] = 1,\n    [\"Machine learning\"] = 1,\n    [\"Main\"] = 4,\n    [\"Main article\"] = 1,\n    [\"Natural language processing\"] = 1,\n    [\"No\"] = 21,\n    [\"Notelist\"] = 1,\n    [\"Partial success\"] = 7,\n    [\"Reflist\"] = 1,\n    [\"See\"] = 1,\n    [\"See also\"] = 4,\n    [\"Short description\"] = 1,\n    [\"Smalldiv\"] = 1,\n    [\"Sort\"] = 53,\n    [\"Yes\"] = 20,\n}\narticle_whitelist = table#1 {\n}\n","limitreport-profile":[["?","240","14.1"],["MediaWiki\\Extension\\Scribunto\\Engines\\LuaSandbox\\LuaSandboxCallback::gsub","160","9.4"],["recursiveClone \u003CmwInit.lua:41\u003E","120","7.1"],["type","120","7.1"],["MediaWiki\\Extension\\Scribunto\\Engines\\LuaSandbox\\LuaSandboxCallback::find","120","7.1"],["MediaWiki\\Extension\\Scribunto\\Engines\\LuaSandbox\\LuaSandboxCallback::callParserFunction","120","7.1"],["dataWrapper \u003Cmw.lua:672\u003E","100","5.9"],["MediaWiki\\Extension\\Scribunto\\Engines\\LuaSandbox\\LuaSandboxCallback::plain","80","4.7"],["MediaWiki\\Extension\\Scribunto\\Engines\\LuaSandbox\\LuaSandboxCallback::preprocess","60","3.5"],["\u003Cmw.lua:694\u003E","60","3.5"],["[others]","520","30.6"]]},"cachereport":{"origin":"mw-web.eqiad.main-55b8c76fd7-4tx5t","timestamp":"20240506090251","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Large language model","url":"https:\/\/en.wikipedia.org\/wiki\/Large_language_model","sameAs":"http:\/\/www.wikidata.org\/entity\/Q115305900","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q115305900","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2023-03-09T15:43:17Z","dateModified":"2024-05-06T09:02:45Z","headline":"language model built with large amounts of texts"}</script>

<div id="mw-teleport-target" class="vector-body"></div><a accesskey="v" href="https://en.wikipedia.org/wiki/Large_language_model?action=edit" class="oo-ui-element-hidden"></a></body></html>